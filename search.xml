<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>MybatisPlus</title>
      <link href="/2024/11/12/MybatisPlus/"/>
      <url>/2024/11/12/MybatisPlus/</url>
      
        <content type="html"><![CDATA[<h1 id="MybatisPlus"><a href="#MybatisPlus" class="headerlink" title="MybatisPlus"></a>MybatisPlus</h1><h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h2><p>1.引入依赖</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;com.baomidou&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;3.5.3.1&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>2.定义Mapper</p><p>自定义的mapper需要继承MybatisPlus提供的BaseMapper接口</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">UserMapper</span> <span class="keyword">extends</span> <span class="title class_">BaseMapper</span>&lt;User&gt;&#123;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/../img/java/springboot/6.png" alt="6"></p><h2 id="常见注解"><a href="#常见注解" class="headerlink" title="常见注解"></a>常见注解</h2><p>MyBatisPlus通过扫描实体类。并基于<strong>反射</strong>获取实体类信息作为数据库表信息</p><p>这个过程遵循一些约定俗成：</p><ul><li>驼峰转下划线</li><li>名为id发字段作为主键</li></ul><p>若不符合约定，则通过注解来得到数据库表信息</p><ul><li>@TableName:用来指定表名</li><li>@TableId:用来指定表中的主键字段信息</li><li>@TableField:用来指定表中的普通字段信息</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@TableName(&quot;tb_user&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span>&#123;</span><br><span class="line"><span class="meta">@TableId(value=&quot;id&quot;,type=Idtype.AUTO)</span>   <span class="comment">//一定要指定type为自增长，否则默认为雪花算法</span></span><br><span class="line"><span class="keyword">private</span> Long id;</span><br><span class="line"><span class="meta">@TableField(&quot;username&quot;)</span></span><br><span class="line"><span class="keyword">private</span> String name;</span><br><span class="line"><span class="meta">@TableField(&quot;is_married&quot;)</span>           <span class="comment">//使用is开头的字段，mp在反射的时候会自动将is去掉，所以一定要加@TableField</span></span><br><span class="line"><span class="keyword">private</span> Boolean isMarried;</span><br><span class="line">    <span class="meta">@TableField(&quot;&#x27;order&#x27;&quot;)</span>              <span class="comment">//名称与数据库关键字冲突，使用@TableField并加&#x27;&#x27;转译字符</span></span><br><span class="line">    <span class="keyword">private</span> Integer order;</span><br><span class="line">    <span class="meta">@TableField(exist=false)</span></span><br><span class="line">    <span class="keyword">private</span> String address;             <span class="comment">//说明数据库中没有这个字段</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="常见配置"><a href="#常见配置" class="headerlink" title="常见配置"></a>常见配置</h2><p>MyBatisPlus的配置项继承了MyBatis原生配置和一些自己特有的配置。例如:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">mybatis-plus:</span></span><br><span class="line"><span class="string">type-aliases-package:com.itheima.mp.domain.po</span> <span class="comment">#别名扫描包</span></span><br><span class="line"><span class="string">mapper-locations:&quot;classpath*:/mapper/**/*.xml&quot;</span>   <span class="comment"># Mapper.xml文件地址，默认值</span></span><br><span class="line"><span class="attr">configuration:</span></span><br><span class="line"><span class="string">map-underscore-to-camel-case:true</span> <span class="comment">#是否开启下划线和驼峰的映射</span></span><br><span class="line"><span class="string">cache-enabled:false</span> <span class="comment">#是否开启二级缓存</span></span><br><span class="line"><span class="attr">global-config:</span></span><br><span class="line"><span class="attr">db-config:</span></span><br><span class="line"><span class="string">id-type:assign_id</span> <span class="comment"># id为雪花算法生成</span></span><br><span class="line"><span class="string">update-strategy:not_null</span> <span class="comment">#更新策略:只更新非空字段</span></span><br></pre></td></tr></table></figure><h2 id="条件构造器"><a href="#条件构造器" class="headerlink" title="条件构造器"></a>条件构造器</h2><p>mp支持各种复杂的where条件</p><p><img src="/../img/java/springboot/7.png" alt="7"></p><p>QueryWrapper拓展了查询相关的功能</p><p>UpdateWrapper拓展了更新相关的功能</p><h3 id="基于QueryWrapper的查询"><a href="#基于QueryWrapper的查询" class="headerlink" title="基于QueryWrapper的查询"></a>基于QueryWrapper的查询</h3><p><img src="/../img/java/springboot/9.png" alt="9"></p><p>Mybatis-plus实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">testQueryWrapper</span><span class="params">()</span>&#123;</span><br><span class="line"><span class="comment">//1.构建查询条件</span></span><br><span class="line">QueryWrapper&lt;User&gt; wrapper = <span class="keyword">new</span> <span class="title class_">QueryWrapper</span>&lt;User&gt;()</span><br><span class="line">.select(<span class="string">&quot;id&quot;</span>,<span class="string">&quot;username&quot;</span>,<span class="string">&quot;info&quot;</span>,<span class="string">&quot;balance&quot;</span>)</span><br><span class="line">.like(<span class="string">&quot;username&quot;</span>,<span class="string">&quot;o&quot;</span>)</span><br><span class="line">.ge(<span class="string">&quot;balance&quot;</span>,<span class="number">1000</span>);</span><br><span class="line"><span class="comment">//2.查询</span></span><br><span class="line">    List&lt;User&gt; users = userMapper.selectList(wrapper);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">testUpdateByQueryMapper</span><span class="params">()</span>&#123;</span><br><span class="line"><span class="comment">//1.需要更新的数据</span></span><br><span class="line"><span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">User</span>();</span><br><span class="line">user.setBalance(<span class="number">2000</span>);</span><br><span class="line"><span class="comment">//2.更新的条件</span></span><br><span class="line">QueryWrapper&lt;User&gt; wrapper = <span class="keyword">new</span> <span class="title class_">QueryWrapper</span>&lt;User&gt;().eq(<span class="string">&quot;username&quot;</span>,<span class="string">&quot;jack&quot;</span>);</span><br><span class="line"><span class="comment">//3.执行更新</span></span><br><span class="line">userMapper.update(user,wrapper);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="基于UpdateWrapperd的更新"><a href="#基于UpdateWrapperd的更新" class="headerlink" title="基于UpdateWrapperd的更新"></a>基于UpdateWrapperd的更新</h3><p><img src="/../img/java/springboot/8.png" alt="8"></p><p>Mybatis-plus实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">testUpdateWrapper</span><span class="params">()</span>&#123;</span><br><span class="line">    List&lt;Long&gt; id = LIst.of(<span class="number">1L</span>,<span class="number">2L</span>,<span class="number">4L</span>);</span><br><span class="line">UpdateWrapper&lt;User&gt; wrapper = <span class="keyword">new</span> <span class="title class_">UpdateWrapper</span>&lt;User&gt;()</span><br><span class="line">.setSql(<span class="string">&quot;balance = balance - 200&quot;</span>)</span><br><span class="line">.in(<span class="string">&quot;id&quot;</span>,ids);</span><br><span class="line">iserWrapper.update(<span class="literal">null</span>,wrapper);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="LambdaQueryWrapper"><a href="#LambdaQueryWrapper" class="headerlink" title="LambdaQueryWrapper"></a>LambdaQueryWrapper</h3><p>区别：通过反射防止了字符串硬编码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">testLambdaQueryWrapper</span><span class="params">()</span>&#123;</span><br><span class="line"><span class="comment">//1.构建查询条件</span></span><br><span class="line">LambdaQueryWrapper&lt;User&gt; wrapper = <span class="keyword">new</span> <span class="title class_">LambdaQueryWrapper</span>&lt;User&gt;()</span><br><span class="line">.select(User::getId,User::getUsername,User::getInfo,User::getBalance)</span><br><span class="line">.like(User::getUsername,<span class="string">&quot;o&quot;</span>)</span><br><span class="line">.ge(User::getBalance,<span class="number">1000</span>);</span><br><span class="line"><span class="comment">//2.查询</span></span><br><span class="line">    List&lt;User&gt; users = userMapper.selectList(wrapper);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="自定义SQL"><a href="#自定义SQL" class="headerlink" title="自定义SQL"></a>自定义SQL</h2><p>利用MYbatisPlus的wrapper来构建复杂的Where条件，然后自定义SQL语句中剩下的部分</p><p>example:</p><p><img src="/../img/java/springboot/10.png" alt="10"></p><p>我们可以利用MybatisPlus的Wrapper来构建复杂的Where条件，然后自定义SQL语句中剩下的部分</p><p><img src="/../img/java/springboot/11.png" alt="11"></p><h2 id="Service接口"><a href="#Service接口" class="headerlink" title="Service接口"></a>Service接口</h2><p><img src="/../img/java/springboot/12.jpg" alt="12"></p><p><strong>你的Servicr接口需要继承IService,ServicrImpl需要继承Mybatis-plus的ServiceImpl类</strong></p>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring微信支付实现</title>
      <link href="/2024/11/12/Spring%E5%BE%AE%E4%BF%A1%E6%94%AF%E4%BB%98%E5%AE%9E%E7%8E%B0/"/>
      <url>/2024/11/12/Spring%E5%BE%AE%E4%BF%A1%E6%94%AF%E4%BB%98%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="Spring微信支付实现"><a href="#Spring微信支付实现" class="headerlink" title="Spring微信支付实现"></a>Spring微信支付实现</h1><p>时序图：</p><p><img src="/../img/java/springboot/5.png" alt="5"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Springboot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring Cache</title>
      <link href="/2024/11/11/Spring-Cache/"/>
      <url>/2024/11/11/Spring-Cache/</url>
      
        <content type="html"><![CDATA[<h1 id="Spring-Cache"><a href="#Spring-Cache" class="headerlink" title="Spring Cache"></a>Spring Cache</h1><p>Spring从3.1开始定义了org.springframework.cache.Cache和org.springframework.cache.CacheManager接口来统一不同的缓存技术；并支持使用JCache（JSR-107）注解简化我们开发</p><p>Spring Cache 是一个框架，实现了了基于注解的缓存功能，只需要简单地添加一个注解，就能实现缓存功能。</p><p>Spring Cache提供了一层抽象，底层可以<strong>切换</strong>不同的缓存实现，例如：</p><ul><li>EHCache</li><li>Caffeine</li><li>Redis</li></ul><p>导入cache的maven坐标：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;2.7.3&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>若你想通过Redis来作为具体的缓存实现，只需在pom文件中导入Reids的java客户端</p><p>想使用Spring Cache，主要就是使用它的一系列注解</p><p>常用注解:</p><table><thead><tr><th>注解</th><th>说明</th></tr></thead><tbody><tr><td>@EnableCaching</td><td>开启缓存功能，通常加在启动类上</td></tr><tr><td>@Cacheable</td><td>在方法执行前先查询缓存中是否有数据，若有：则直接返回缓存数据：若无，调用方法并将方法返回值放到缓存中</td></tr><tr><td>@CachePut</td><td>将方法的返回值放到缓存中</td></tr><tr><td>@CacheEvict</td><td>将一条或多条数据从缓存中删除</td></tr></tbody></table><p>@CachePut使用说明:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@PostMapping</span></span><br><span class="line"><span class="meta">@CachePut(cacheNames = &quot;userCache&quot;,key = &quot;#user.id&quot;)</span>    <span class="comment">//这将会以cacheNames::key为键存到redis中，这里的#user.id为spring的表达式语言，将会动态地取到形参user的id值</span></span><br><span class="line"><span class="keyword">public</span> User <span class="title function_">save</span><span class="params">(<span class="meta">@RequestBody</span> User user)</span>&#123;</span><br><span class="line">userMapper.insert(user);</span><br><span class="line"><span class="keyword">return</span> user;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的#user.id可以改为<strong>result.id</strong>，result在这里是固定的表达，指的是返回值</p><p>key &#x3D; “#user.id”  也可以换为key &#x3D; “#p0.id”，p0在这里指的是第一个参数</p><p>.  ：对象导航</p><p>@Cacheable使用说明：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMaping</span></span><br><span class="line"><span class="meta">@Cacheable(cacheNames =&quot;userCache&quot;,key=&quot;#id&quot;)</span></span><br><span class="line"><span class="keyword">public</span> User <span class="title function_">getById</span><span class="params">(Long id)</span>&#123;</span><br><span class="line"><span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> userMapper.getById(id);</span><br><span class="line"><span class="keyword">return</span> user;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>@CacheEvict使用说明：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@DeletMapping</span></span><br><span class="line"><span class="meta">@CacheEvict(cacheName=&quot;userCache&quot;,key=&quot;#id&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">deldteById</span><span class="params">(LOng id)</span>&#123;</span><br><span class="line">userMapper.deleteById(id);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Springboot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法学习笔记-动态规划</title>
      <link href="/2024/11/09/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-01%E8%83%8C%E5%8C%85/"/>
      <url>/2024/11/09/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-01%E8%83%8C%E5%8C%85/</url>
      
        <content type="html"><![CDATA[<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h1><p>本质：空间换时间</p><p>求解步骤：</p><ol><li>设计状态</li><li>确定状态转移方程</li><li>确定初始状态</li><li>执行状态转移</li><li>计算最终的解</li></ol><h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><h3 id="递推"><a href="#递推" class="headerlink" title="递推"></a>递推</h3><h4 id="力扣第70题-爬楼梯"><a href="#力扣第70题-爬楼梯" class="headerlink" title="力扣第70题-爬楼梯"></a>力扣第70题-爬楼梯</h4><p>假设你正在爬楼梯。需要 <code>n</code> 阶你才能到达楼顶。</p><p>每次你可以爬 <code>1</code> 或 <code>2</code> 个台阶。你有多少种不同的方法可以爬到楼顶呢？</p><p><strong>示例 1：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">输入：n = 2</span><br><span class="line">输出：2</span><br><span class="line">解释：有两种方法可以爬到楼顶。</span><br><span class="line">1. 1 阶 + 1 阶</span><br><span class="line">2. 2 阶</span><br></pre></td></tr></table></figure><p><strong>示例 2：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">输入：n = 3</span><br><span class="line">输出：3</span><br><span class="line">解释：有三种方法可以爬到楼顶。</span><br><span class="line">1. 1 阶 + 1 阶 + 1 阶</span><br><span class="line">2. 1 阶 + 2 阶</span><br><span class="line">3. 2 阶 + 1 阶</span><br></pre></td></tr></table></figure><p>解答：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">climbStairs</span><span class="params">(<span class="type">int</span> n)</span> &#123;</span><br><span class="line">        <span class="type">int</span>[] F=<span class="keyword">new</span> <span class="title class_">int</span>[<span class="number">46</span>];</span><br><span class="line">        F[<span class="number">0</span>]=F[<span class="number">1</span>]=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">2</span>;i&lt;=n;i++)&#123;</span><br><span class="line">            F[i]=F[i-<span class="number">1</span>]+F[i-<span class="number">2</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> F[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="力扣第509题-斐波那契数列"><a href="#力扣第509题-斐波那契数列" class="headerlink" title="力扣第509题-斐波那契数列"></a>力扣第509题-斐波那契数列</h4><p>解答：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">fib</span><span class="params">(<span class="type">int</span> n)</span> &#123;</span><br><span class="line">        <span class="type">int</span>[] F=<span class="keyword">new</span> <span class="title class_">int</span>[<span class="number">32</span>];</span><br><span class="line">        F[<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">        F[<span class="number">1</span>]=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">2</span>;i&lt;=n;i++)&#123;</span><br><span class="line">            F[i]=F[i-<span class="number">1</span>]+F[i-<span class="number">2</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> F[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="力扣第1137题-第-N-个泰波那契数"><a href="#力扣第1137题-第-N-个泰波那契数" class="headerlink" title="力扣第1137题-第 N 个泰波那契数"></a>力扣第1137题-第 N 个泰波那契数</h4><p>解答：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">tribonacci</span><span class="params">(<span class="type">int</span> n)</span> &#123;</span><br><span class="line">        <span class="type">int</span>[] F=<span class="keyword">new</span> <span class="title class_">int</span>[<span class="number">38</span>];</span><br><span class="line">        F[<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">        F[<span class="number">1</span>]=<span class="number">1</span>;</span><br><span class="line">        F[<span class="number">2</span>]=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">3</span>;i&lt;=n;i++)&#123;</span><br><span class="line">            F[i]=F[i-<span class="number">1</span>]+F[i-<span class="number">2</span>]+F[i-<span class="number">3</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> F[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="力扣第746题-使用最小花费爬楼梯"><a href="#力扣第746题-使用最小花费爬楼梯" class="headerlink" title="力扣第746题-使用最小花费爬楼梯"></a>力扣第746题-使用最小花费爬楼梯</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">minCostClimbingStairs</span><span class="params">(<span class="type">int</span>[] cost)</span> &#123;</span><br><span class="line">        <span class="type">int</span> n=cost.length;</span><br><span class="line">        <span class="type">int</span>[] F=<span class="keyword">new</span> <span class="title class_">int</span>[n+<span class="number">1</span>];</span><br><span class="line">        F[<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">        F[<span class="number">1</span>]=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">2</span>;i&lt;=n;i++)&#123;</span><br><span class="line">            F[i] = Math.min(F[i - <span class="number">1</span>] + cost[i - <span class="number">1</span>], F[i - <span class="number">2</span>] + cost[i - <span class="number">2</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> F[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="力扣第198题-打家劫舍"><a href="#力扣第198题-打家劫舍" class="headerlink" title="力扣第198题-打家劫舍"></a>力扣第198题-打家劫舍</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">rob</span><span class="params">(<span class="type">int</span>[] nums)</span> &#123;</span><br><span class="line">        <span class="type">int</span> n=nums.length;</span><br><span class="line">        <span class="keyword">if</span>(n==<span class="number">1</span>) <span class="keyword">return</span> nums[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">if</span>(n==<span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span>[] F=<span class="keyword">new</span> <span class="title class_">int</span>[n+<span class="number">1</span>];</span><br><span class="line">        F[<span class="number">0</span>]=nums[<span class="number">0</span>];</span><br><span class="line">        F[<span class="number">1</span>]=Math.max(nums[<span class="number">0</span>],nums[<span class="number">1</span>]);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">2</span>;i&lt;n;i++)&#123;</span><br><span class="line">            F[i]=Math.max(F[i-<span class="number">2</span>]+nums[i],F[i-<span class="number">1</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> F[n-<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="力扣第53题-最大子数组和"><a href="#力扣第53题-最大子数组和" class="headerlink" title="力扣第53题-最大子数组和"></a>力扣第53题-最大子数组和</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">maxSubArray</span><span class="params">(<span class="type">int</span>[] nums)</span> &#123;</span><br><span class="line">        <span class="type">int</span> n=nums.length;</span><br><span class="line">        <span class="type">int</span>[] f=<span class="keyword">new</span> <span class="title class_">int</span>[n];</span><br><span class="line">        f[<span class="number">0</span>] = nums[<span class="number">0</span>];</span><br><span class="line">        <span class="type">int</span> ans=f[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;n;i++)&#123;</span><br><span class="line">            f[i]=Math.max(f[i-<span class="number">1</span>],<span class="number">0</span>)+nums[i];</span><br><span class="line">            ans=Math.max(ans,f[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h3><h4 id="力扣第62题-不同路径"><a href="#力扣第62题-不同路径" class="headerlink" title="力扣第62题-不同路径"></a>力扣第62题-不同路径</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">uniquePaths</span><span class="params">(<span class="type">int</span> m, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">        <span class="type">int</span>[][] dp=<span class="keyword">new</span> <span class="title class_">int</span>[m+<span class="number">1</span>][n+<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">            dp[<span class="number">0</span>][i]=<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;m;i++)&#123;</span><br><span class="line">            dp[i][<span class="number">0</span>]=<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;m;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;n;j++)&#123;</span><br><span class="line">                dp[i][j]=dp[i-<span class="number">1</span>][j]+dp[i][j-<span class="number">1</span>];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[m-<span class="number">1</span>][n-<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="力扣第64题-最小路径和"><a href="#力扣第64题-最小路径和" class="headerlink" title="力扣第64题-最小路径和"></a>力扣第64题-最小路径和</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">minPathSum</span><span class="params">(<span class="type">int</span>[][] grid)</span> &#123;</span><br><span class="line">        <span class="type">int</span> m=grid.length;</span><br><span class="line">        <span class="type">int</span> n=grid[<span class="number">0</span>].length;</span><br><span class="line">        <span class="type">int</span>[][] dp=<span class="keyword">new</span> <span class="title class_">int</span>[m+<span class="number">1</span>][n+<span class="number">1</span>];</span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">0</span>]=grid[<span class="number">0</span>][<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;m;i++)&#123;</span><br><span class="line">            dp[i][<span class="number">0</span>]=grid[i][<span class="number">0</span>]+dp[i-<span class="number">1</span>][<span class="number">0</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;n;j++)&#123;</span><br><span class="line">            dp[<span class="number">0</span>][j]=grid[<span class="number">0</span>][j]+dp[<span class="number">0</span>][j-<span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;m;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;n;j++)&#123;</span><br><span class="line">                dp[i][j]=Math.min(dp[i-<span class="number">1</span>][j]+grid[i][j],dp[i][j-<span class="number">1</span>]+grid[i][j]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[m-<span class="number">1</span>][n-<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="力扣第63题-不同路径-II"><a href="#力扣第63题-不同路径-II" class="headerlink" title="力扣第63题-不同路径 II"></a>力扣第63题-不同路径 II</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">uniquePathsWithObstacles</span><span class="params">(<span class="type">int</span>[][] obstacleGrid)</span> &#123;</span><br><span class="line">        <span class="type">int</span> m=obstacleGrid.length;</span><br><span class="line">        <span class="type">int</span> n=obstacleGrid[<span class="number">0</span>].length;</span><br><span class="line">        <span class="type">int</span>[][] dp=<span class="keyword">new</span> <span class="title class_">int</span>[m][n];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; m; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>; j &lt;n; j++) &#123;</span><br><span class="line">                dp[i][j] = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">            dp[<span class="number">0</span>][i]=<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span>(obstacleGrid[<span class="number">0</span>][i]==<span class="number">1</span>)&#123;</span><br><span class="line">                dp[<span class="number">0</span>][i]=<span class="number">0</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;m;i++)&#123;</span><br><span class="line">            dp[i][<span class="number">0</span>]=<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span>(obstacleGrid[i][<span class="number">0</span>]==<span class="number">1</span>)&#123;</span><br><span class="line">                dp[i][<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;m;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;n;j++)&#123;</span><br><span class="line">                dp[i][j]=dp[i-<span class="number">1</span>][j]+dp[i][j-<span class="number">1</span>];</span><br><span class="line">                <span class="keyword">if</span>(obstacleGrid[i][j]==<span class="number">1</span>)&#123;</span><br><span class="line">                    dp[i][j]=<span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[m-<span class="number">1</span>][n-<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="力扣第1594题-矩阵的最大面积"><a href="#力扣第1594题-矩阵的最大面积" class="headerlink" title="力扣第1594题-矩阵的最大面积"></a>力扣第1594题-矩阵的最大面积</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">maxProductPath</span><span class="params">(<span class="type">int</span>[][] grid)</span> &#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="type">int</span> <span class="variable">MOD</span> <span class="operator">=</span> <span class="number">1000000000</span> + <span class="number">7</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">m</span> <span class="operator">=</span> grid.length, n = grid[<span class="number">0</span>].length;</span><br><span class="line">        <span class="type">long</span>[][] maxgt = <span class="keyword">new</span> <span class="title class_">long</span>[m][n];</span><br><span class="line">        <span class="type">long</span>[][] minlt = <span class="keyword">new</span> <span class="title class_">long</span>[m][n];</span><br><span class="line"></span><br><span class="line">        maxgt[<span class="number">0</span>][<span class="number">0</span>] = minlt[<span class="number">0</span>][<span class="number">0</span>] = grid[<span class="number">0</span>][<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt; n; i++) &#123;</span><br><span class="line">            maxgt[<span class="number">0</span>][i] = minlt[<span class="number">0</span>][i] = maxgt[<span class="number">0</span>][i - <span class="number">1</span>] * grid[<span class="number">0</span>][i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt; m; i++) &#123;</span><br><span class="line">            maxgt[i][<span class="number">0</span>] = minlt[i][<span class="number">0</span>] = maxgt[i - <span class="number">1</span>][<span class="number">0</span>] * grid[i][<span class="number">0</span>];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt; m; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">1</span>; j &lt; n; j++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (grid[i][j] &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">                    maxgt[i][j] = Math.max(maxgt[i][j - <span class="number">1</span>], maxgt[i - <span class="number">1</span>][j]) * grid[i][j];</span><br><span class="line">                    minlt[i][j] = Math.min(minlt[i][j - <span class="number">1</span>], minlt[i - <span class="number">1</span>][j]) * grid[i][j];</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    maxgt[i][j] = Math.min(minlt[i][j - <span class="number">1</span>], minlt[i - <span class="number">1</span>][j]) * grid[i][j];</span><br><span class="line">                    minlt[i][j] = Math.max(maxgt[i][j - <span class="number">1</span>], maxgt[i - <span class="number">1</span>][j]) * grid[i][j];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (maxgt[m - <span class="number">1</span>][n - <span class="number">1</span>] &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> (<span class="type">int</span>) (maxgt[m - <span class="number">1</span>][n - <span class="number">1</span>] % MOD);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="01背包"><a href="#01背包" class="headerlink" title="01背包"></a>01背包</h3><h4 id="洛谷P1048题-采药"><a href="#洛谷P1048题-采药" class="headerlink" title="洛谷P1048题-采药"></a>洛谷P1048题-采药</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Scanner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Main</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Scanner</span> <span class="variable">scanner</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scanner</span>(System.in);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 读入总时间 T 和草药数量 M</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">T</span> <span class="operator">=</span> scanner.nextInt();</span><br><span class="line">        <span class="type">int</span> <span class="variable">M</span> <span class="operator">=</span> scanner.nextInt();</span><br><span class="line">        </span><br><span class="line">        <span class="type">int</span>[] times = <span class="keyword">new</span> <span class="title class_">int</span>[M];</span><br><span class="line">        <span class="type">int</span>[] values = <span class="keyword">new</span> <span class="title class_">int</span>[M];</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 读入每株草药的采集时间和价值</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; M; i++) &#123;</span><br><span class="line">            times[i] = scanner.nextInt();</span><br><span class="line">            values[i] = scanner.nextInt();</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 定义 dp 数组，dp[j] 表示在时间 j 内能够采集的最大价值</span></span><br><span class="line">        <span class="type">int</span>[] dp = <span class="keyword">new</span> <span class="title class_">int</span>[T + <span class="number">1</span>];</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 遍历每一株草药</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; M; i++) &#123;</span><br><span class="line">            <span class="comment">// 从 T 到 times[i] 倒序遍历</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> T; j &gt;= times[i]; j--) &#123;</span><br><span class="line">                dp[j] = Math.max(dp[j], dp[j - times[i]] + values[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 输出在规定时间内可以采集到的最大总价值</span></span><br><span class="line">        System.out.println(dp[T]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>springboot常用注解整理</title>
      <link href="/2024/10/27/springboot%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%95%B4%E7%90%86/"/>
      <url>/2024/10/27/springboot%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="Springboot常用注解整理"><a href="#Springboot常用注解整理" class="headerlink" title="Springboot常用注解整理"></a>Springboot常用注解整理</h1><h2 id="通用"><a href="#通用" class="headerlink" title="通用"></a>通用</h2><h3 id="1-Autowired"><a href="#1-Autowired" class="headerlink" title="1.@Autowired"></a>1.@Autowired</h3><p><strong>作用</strong>：自动注入 Spring 容器中的 bean。</p><p><strong>用途</strong>：可以用于构造函数、字段或 setter 方法，简化依赖注入的过程。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> UserRepository userRepository;</span><br></pre></td></tr></table></figure><h3 id="2-Component"><a href="#2-Component" class="headerlink" title="2. @Component"></a>2. @Component</h3><p><strong>作用</strong>：将类标识为 Spring 组件，使其可以被 Spring 管理。</p><p><strong>用途</strong>：用于任何 Spring 管理的类，如果不适用更特定的注解（如 <code>@Service</code>、<code>@Controller</code>、<code>@Repository</code>），可以使用这个注解。</p><p>是一个类级别的注解，通常用于标记一个类作为 Spring 管理的组件。Spring 会自动扫描带有 <code>@Component</code> 注解的类，并将其实例化为 bean。</p><p>更常用于自动扫描的组件，适合用于标记服务层、控制器层、数据访问层等。可以与其他注解（如 <code>@Service</code>、<code>@Controller</code>、<code>@Repository</code>）结合使用，以便在语义上更清晰。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyComponent</span> &#123;</span><br><span class="line">    <span class="comment">// 业务逻辑</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-Value"><a href="#3-Value" class="headerlink" title="3.@Value"></a>3.@Value</h3><p><strong>作用</strong>：用于注入配置属性。</p><p><strong>用途</strong>：从 <code>application.properties</code> 或 <code>application.yml</code> 中获取值并注入到字段中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Value(&quot;$&#123;app.name&#125;&quot;)</span></span><br><span class="line"><span class="keyword">private</span> String appName;</span><br></pre></td></tr></table></figure><h3 id="4-Configuration"><a href="#4-Configuration" class="headerlink" title="4.@Configuration"></a>4.@Configuration</h3><p><strong>作用</strong>：标识一个类为配置类，通常用于定义 Spring bean。</p><p><strong>用途</strong>：替代 XML 配置，使用 Java 代码来配置 bean。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AppConfig</span> &#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> MyService <span class="title function_">myService</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">MyService</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="5-Bean"><a href="#5-Bean" class="headerlink" title="5.@Bean"></a>5.@Bean</h3><p><strong>作用</strong>：用于定义一个 bean 方法。</p><p><strong>用途</strong>：在 <code>@Configuration</code> 类中使用，返回的对象将被 Spring 容器管理。</p><p>是一个方法级别的注解，通常用于在配置类中定义一个 bean。返回值将被注册为 Spring 的 bean。</p><p>更常用于手动定义 bean，适合在需要更复杂配置或控制 bean 实例化过程时使用。可以在 Java 配置类中使用，也可以通过工厂方法创建 bean。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="keyword">public</span> MyService <span class="title function_">myService</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">MyService</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="6-Scope"><a href="#6-Scope" class="headerlink" title="6.@Scope"></a>6.@Scope</h3><p><strong>作用</strong>：指定 bean 的作用域。</p><p><strong>用途</strong>：可以设置为单例（singleton）、原型（prototype）、请求（request）、会话（session）等。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Scope(&quot;prototype&quot;)</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyPrototypeBean</span> &#123;</span><br><span class="line">    <span class="comment">// 逻辑</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="7-PostConstruct"><a href="#7-PostConstruct" class="headerlink" title="7.@PostConstruct"></a>7.@PostConstruct</h3><p><strong>作用</strong>：在 bean 初始化完成后执行的方法。</p><p><strong>用途</strong>：用于进行一些初始化操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@PostConstruct</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 初始化逻辑</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="8-PreDestroy"><a href="#8-PreDestroy" class="headerlink" title="8.@PreDestroy"></a>8.@PreDestroy</h3><p><strong>作用</strong>：在 bean 销毁之前执行的方法。</p><p><strong>用途</strong>：用于释放资源或进行清理操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@PreDestroy</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">cleanup</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 清理逻辑</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Controller层"><a href="#Controller层" class="headerlink" title="Controller层"></a>Controller层</h2><h3 id="1-Controller"><a href="#1-Controller" class="headerlink" title="1. @Controller"></a>1. @Controller</h3><p><strong>作用</strong>：标识一个类为控制器，用于处理请求。</p><p><strong>用途</strong>：通常与视图（如 JSP、Thymeleaf）结合使用。</p><p>通常返回视图名（如 JSP 页面），需要通过视图解析器来渲染视图。如果需要返回 JSON 或其他数据格式，必须在每个处理方法上添加 <code>@ResponseBody</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyController</span> &#123;</span><br><span class="line">    <span class="comment">// 方法定义</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="2-RestController"><a href="#2-RestController" class="headerlink" title="2. @RestController"></a>2. @RestController</h3><p><strong>作用</strong>：是 <code>@Controller</code> 的组合注解，默认返回 JSON 或 XML 格式的数据。</p><p><strong>用途</strong>：适用于 RESTful Web 服务。</p><p>默认将方法的返回值直接作为 HTTP 响应体返回，通常用于返回 JSON 或 XML 数据。所有方法返回的对象会自动被转换为 JSON 格式（如果使用了 Jackson 等库）。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyRestController</span> &#123;</span><br><span class="line">    <span class="comment">// 方法定义</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-RequestMapping"><a href="#3-RequestMapping" class="headerlink" title="3.@RequestMapping"></a>3.@RequestMapping</h3><p><strong>作用</strong>：用于将 HTTP 请求映射到处理方法。</p><p><strong>用途</strong>：可以在类级别或方法级别使用，支持设置请求类型（GET、POST 等）、路径、参数等。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RequestMapping(&quot;/api&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyApiController</span> &#123;</span><br><span class="line">    <span class="meta">@RequestMapping(&quot;/hello&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">hello</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Hello, World!&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-GetMapping-PostMapping-PutMapping-DeleteMapping"><a href="#4-GetMapping-PostMapping-PutMapping-DeleteMapping" class="headerlink" title="4. @GetMapping, @PostMapping, @PutMapping, @DeleteMapping"></a>4. @GetMapping, @PostMapping, @PutMapping, @DeleteMapping</h3><p><strong>作用</strong>：是 <code>@RequestMapping</code> 的快捷方式，分别用于处理 GET、POST、PUT 和 DELETE 请求。</p><p><strong>用途</strong>：使代码更简洁明了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyController</span> &#123;</span><br><span class="line">    <span class="meta">@GetMapping(&quot;/hello&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getHello</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Hello, GET!&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostMapping(&quot;/hello&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">postHello</span><span class="params">(<span class="meta">@RequestBody</span> String name)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Hello, &quot;</span> + name + <span class="string">&quot;!&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="5-PathVariable"><a href="#5-PathVariable" class="headerlink" title="5.@PathVariable"></a>5.@PathVariable</h3><p><strong>作用</strong>：用于从 URL 模板中提取变量。</p><p><strong>用途</strong>：通常用于 RESTful API 中，允许将 URL 中的动态部分映射到方法参数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/user/&#123;id&#125;&quot;)</span></span><br><span class="line"><span class="keyword">public</span> User <span class="title function_">getUserById</span><span class="params">(<span class="meta">@PathVariable</span> String id)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> userService.findById(id);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="6-RequestParam"><a href="#6-RequestParam" class="headerlink" title="6.@RequestParam"></a>6.@RequestParam</h3><p><strong>作用</strong>：用于提取请求参数。</p><p><strong>用途</strong>：可以从查询字符串或表单数据中获取参数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/greet&quot;)</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">greet</span><span class="params">(<span class="meta">@RequestParam</span> String name)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Hello, &quot;</span> + name + <span class="string">&quot;!&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="7-RequestBody"><a href="#7-RequestBody" class="headerlink" title="7.@RequestBody"></a>7.@RequestBody</h3><p><strong>作用</strong>：用于将请求体中的 JSON 或 XML 数据转换为 Java 对象。</p><p><strong>用途</strong>：在处理 POST 和 PUT 请求时，常用于接收客户端发送的数据。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@PostMapping(&quot;/user&quot;)</span></span><br><span class="line"><span class="keyword">public</span> User <span class="title function_">createUser</span><span class="params">(<span class="meta">@RequestBody</span> User user)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> userService.save(user);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="8-ResponseBody"><a href="#8-ResponseBody" class="headerlink" title="8.@ResponseBody"></a>8.@ResponseBody</h3><p><strong>作用</strong>：指示方法的返回值应直接写入 HTTP 响应体。</p><p><strong>用途</strong>：通常与 <code>@Controller</code> 结合使用，以便返回 JSON 或其他数据格式。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyController</span> &#123;</span><br><span class="line">    <span class="meta">@ResponseBody</span></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/data&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> Data <span class="title function_">getData</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Data</span>(<span class="string">&quot;example&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="9-CrossOrigin"><a href="#9-CrossOrigin" class="headerlink" title="9.@CrossOrigin"></a>9.@CrossOrigin</h3><p><strong>作用</strong>：用于处理跨源请求。</p><p><strong>用途</strong>：允许特定来源的客户端访问控制器的方法，适用于 RESTful API。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@CrossOrigin(origins = &quot;http://example.com&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyController</span> &#123;</span><br><span class="line">    <span class="meta">@GetMapping(&quot;/data&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> Data <span class="title function_">getData</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Data</span>(<span class="string">&quot;example&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="10-Valid-和-Validated"><a href="#10-Valid-和-Validated" class="headerlink" title="10. @Valid 和 @Validated"></a>10. @Valid 和 @Validated</h3><p><strong>作用</strong>：用于启用方法参数的验证。</p><p><strong>用途</strong>：常与 <code>@RequestBody</code> 一起使用，确保传入的数据符合要求。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@PostMapping(&quot;/user&quot;)</span></span><br><span class="line"><span class="keyword">public</span> User <span class="title function_">createUser</span><span class="params">(<span class="meta">@Valid</span> <span class="meta">@RequestBody</span> User user)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> userService.save(user);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Service层"><a href="#Service层" class="headerlink" title="Service层"></a>Service层</h2><h3 id="1-Service"><a href="#1-Service" class="headerlink" title="1.@Service"></a>1.@Service</h3><p><strong>作用</strong>：标识一个类为服务组件，是 Spring 的标记注解之一。</p><p><strong>用途</strong>：用于标识业务逻辑层的组件，Spring 会自动扫描并管理这些类。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserService</span> &#123;</span><br><span class="line">    <span class="comment">// 业务逻辑方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-Transactional"><a href="#2-Transactional" class="headerlink" title="2.@Transactional"></a>2.@Transactional</h3><p><strong>作用</strong>：用于标记一个方法或类为事务性，确保在执行方法时的一致性。</p><p><strong>用途</strong>：在处理数据库操作时，通常会将这个注解应用于 Service 层，以确保操作的原子性和一致性。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.transaction.annotation.Transactional;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserService</span> &#123;</span><br><span class="line">    <span class="meta">@Transactional</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">createUser</span><span class="params">(User user)</span> &#123;</span><br><span class="line">        <span class="comment">// 业务逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-Cacheable-CachePut-CacheEvict"><a href="#3-Cacheable-CachePut-CacheEvict" class="headerlink" title="3.@Cacheable, @CachePut, @CacheEvict"></a>3.@Cacheable, @CachePut, @CacheEvict</h3><p><strong>作用</strong>：用于缓存管理。</p><ul><li><code>@Cacheable</code>：用于标记方法的结果应被缓存。</li><li><code>@CachePut</code>：用于更新缓存。</li><li><code>@CacheEvict</code>：用于清除缓存。</li></ul><p><strong>用途</strong>：通过缓存提高系统性能，减少数据库查询。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.cache.annotation.Cacheable;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserService</span> &#123;</span><br><span class="line">    <span class="meta">@Cacheable(&quot;users&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> User <span class="title function_">getUserById</span><span class="params">(String id)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> userRepository.findById(id);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="4-Profile"><a href="#4-Profile" class="headerlink" title="4.@Profile"></a>4.@Profile</h3><p><strong>作用</strong>：用于根据当前环境激活特定的 Bean。</p><p><strong>用途</strong>：可以在开发、测试和生产环境中使用不同的实现类。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Profile;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="meta">@Profile(&quot;dev&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DevUserService</span> <span class="keyword">implements</span> <span class="title class_">UserService</span> &#123;</span><br><span class="line">    <span class="comment">// 开发环境中的实现</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Mapper层"><a href="#Mapper层" class="headerlink" title="Mapper层"></a>Mapper层</h2><h3 id="1-Repository"><a href="#1-Repository" class="headerlink" title="1.@Repository"></a>1.@Repository</h3><p><strong>作用</strong>：标识一个类为数据访问层组件。</p><p><strong>用途</strong>：通常与 Spring Data JPA 和 MyBatis 一起使用，用于表示该类是用于数据操作的组件。</p><p>属于 Spring 框架，用于标识一个类为数据访问层的组件。主要用于 Spring 的依赖注入和 AOP（面向切面编程）。</p><p>用于标记数据访问层的类，通常与 Spring Data JPA 或其他数据访问技术一起使用。可以通过 <code>@Autowired</code> 注入到服务层，支持 Spring 的事务管理。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Repository;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Repository</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">UserMapper</span> &#123;</span><br><span class="line">    User <span class="title function_">findById</span><span class="params">(Long id)</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="2-Mapper"><a href="#2-Mapper" class="headerlink" title="2.@Mapper"></a>2.@Mapper</h3><p><strong>作用</strong>：标识一个接口为 MyBatis 的 Mapper 接口。</p><p><strong>用途</strong>：将该接口与 XML 映射文件或注解 SQL 语句关联，允许 MyBatis 自动扫描并生成实现类。</p><p>属于 MyBatis 框架，用于标识一个接口为 MyBatis 的 Mapper 接口。主要用于将 SQL 操作与 Java 方法进行映射。</p><p>用于标识 MyBatis 的 Mapper 接口，使得 MyBatis 能够自动生成实现类。可以直接定义 SQL 操作，并与数据库表进行映射。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.ibatis.annotations.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Mapper</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">UserMapper</span> &#123;</span><br><span class="line">    User <span class="title function_">findById</span><span class="params">(Long id)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-Select-Insert-Update-Delete"><a href="#3-Select-Insert-Update-Delete" class="headerlink" title="3.@Select, @Insert, @Update, @Delete"></a>3.@Select, @Insert, @Update, @Delete</h3><p><strong>作用</strong>：这些注解用于定义 SQL 操作。</p><p><strong>用途</strong>：可以直接在 Mapper 接口中编写 SQL 语句，而不需要 XML 映射文件。</p><ul><li><p><strong>@Select</strong>：执行 SELECT 查询。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Select(&quot;SELECT * FROM users WHERE id = #&#123;id&#125;&quot;)</span></span><br><span class="line">User <span class="title function_">findById</span><span class="params">(Long id)</span>;</span><br></pre></td></tr></table></figure></li><li><p><strong>@Insert</strong>：执行 INSERT 操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Insert(&quot;INSERT INTO users(name, email) VALUES(#&#123;name&#125;, #&#123;email&#125;)&quot;)</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">insertUser</span><span class="params">(User user)</span>;</span><br></pre></td></tr></table></figure></li><li><p><strong>@Update</strong>：执行 UPDATE 操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Update(&quot;UPDATE users SET name = #&#123;name&#125; WHERE id = #&#123;id&#125;&quot;)</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">updateUser</span><span class="params">(User user)</span>;</span><br></pre></td></tr></table></figure></li><li><p><strong>@Delete</strong>：执行 DELETE 操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Delete(&quot;DELETE FROM users WHERE id = #&#123;id&#125;&quot;)</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">deleteUser</span><span class="params">(Long id)</span>;</span><br></pre></td></tr></table></figure></li></ul><h3 id="4-Param"><a href="#4-Param" class="headerlink" title="4.@Param"></a>4.@Param</h3><p><strong>作用</strong>：用于在方法参数中指定参数名。</p><p><strong>用途</strong>：在使用注解 SQL 语句时，可以通过这个注解来明确指定参数名，尤其在多个参数时。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Select(&quot;SELECT * FROM users WHERE name = #&#123;name&#125; AND age = #&#123;age&#125;&quot;)</span></span><br><span class="line">User <span class="title function_">findByNameAndAge</span><span class="params">(<span class="meta">@Param(&quot;name&quot;)</span> String name, <span class="meta">@Param(&quot;age&quot;)</span> <span class="type">int</span> age)</span>;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Springboot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MongoDB快速入门整理</title>
      <link href="/2024/10/26/MongoDB%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%B4%E7%90%86/"/>
      <url>/2024/10/26/MongoDB%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="MongoDB学习整理"><a href="#MongoDB学习整理" class="headerlink" title="MongoDB学习整理"></a>MongoDB学习整理</h1><p>基础认识:mongoDB是文档型数据库</p><p>在mongoDB中，数据库是由一个个集合组成的，每个集合又包含多个文档（文档在使用BSON的格式来组织和存储数据）</p><h2 id="基础操作"><a href="#基础操作" class="headerlink" title="基础操作"></a>基础操作</h2><h3 id="1-连接MongoDB"><a href="#1-连接MongoDB" class="headerlink" title="1. 连接MongoDB"></a>1. 连接MongoDB</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mongo</span><br></pre></td></tr></table></figure><p>如果 MongoDB 在其他主机或端口上运行，可以指定地址，例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mongo --host your_host --port your_port</span><br></pre></td></tr></table></figure><h3 id="2-显示数据库列表"><a href="#2-显示数据库列表" class="headerlink" title="2. 显示数据库列表"></a>2. 显示数据库列表</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show databases</span><br></pre></td></tr></table></figure><h3 id="3-创建-切换数据库"><a href="#3-创建-切换数据库" class="headerlink" title="3.  创建&#x2F;切换数据库"></a>3.  创建&#x2F;切换数据库</h3><p>使用 <code>use</code> 命令切换到某个数据库，如果该数据库不存在会自动创建：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">use myDatabase</span><br></pre></td></tr></table></figure><h3 id="4-清屏"><a href="#4-清屏" class="headerlink" title="4. 清屏"></a>4. 清屏</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cls</span><br></pre></td></tr></table></figure><h3 id="5-退出"><a href="#5-退出" class="headerlink" title="5. 退出"></a>5. 退出</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exit</span><br></pre></td></tr></table></figure><h2 id="CRUD"><a href="#CRUD" class="headerlink" title="CRUD"></a>CRUD</h2><h3 id="创建操作"><a href="#创建操作" class="headerlink" title="创建操作"></a>创建操作</h3><p>创建或插入操作用于将新<a href="https://www.mongodb.com/zh-cn/docs/manual/core/document/#std-label-bson-document-format">文档</a>添加到<a href="https://www.mongodb.com/zh-cn/docs/manual/core/databases-and-collections/#std-label-collections">集合</a>中。如果集合当前不存在，插入操作会创建集合。</p><p>MongoDB 提供以下方法将文档插入到集合中：</p><ul><li><code>db.collection.insertOne()</code></li><li><code>db.collection.insertMany()</code></li></ul><p><img src="/../img/java/MongoDB/1.png" alt="1"></p><h3 id="读取操作"><a href="#读取操作" class="headerlink" title="读取操作"></a>读取操作</h3><p>读取操作用于从<a href="https://www.mongodb.com/zh-cn/docs/manual/core/document/#std-label-bson-document-format">集合</a>中检索<a href="https://www.mongodb.com/zh-cn/docs/manual/core/databases-and-collections/#std-label-collections">文档</a>，即查询集合中的文档。MongoDB 提供以下方法来从集合中读取文档：</p><ul><li><code>db.collection.find()</code></li></ul><p><img src="/../img/java/MongoDB/2.png" alt="2"></p><h3 id="读取操作-1"><a href="#读取操作-1" class="headerlink" title="读取操作"></a>读取操作</h3><p>读取操作用于从<a href="https://www.mongodb.com/zh-cn/docs/manual/core/document/#std-label-bson-document-format">集合</a>中检索<a href="https://www.mongodb.com/zh-cn/docs/manual/core/databases-and-collections/#std-label-collections">文档</a>，即查询集合中的文档。</p><ul><li><code>db.collection.find()</code></li></ul><h3 id="删除操作"><a href="#删除操作" class="headerlink" title="删除操作"></a>删除操作</h3><ul><li><code>db.collection.deleteOne()</code></li><li><code>db.collection.deleteMany()</code></li></ul><h2 id="常用函数汇总"><a href="#常用函数汇总" class="headerlink" title="常用函数汇总"></a>常用函数汇总</h2><table><thead><tr><th>函数</th><th>用途</th><th>example</th></tr></thead><tbody><tr><td>limit()</td><td>限制返回的数据数量</td><td>db.user.find().limit(1)</td></tr><tr><td>sort()</td><td>排序查询结果(1：升序；-1：降序)</td><td>db.user.finnd().sort({level:1})     #按照level的属性大小进行排序</td></tr><tr><td>skip()</td><td>跳过一些查询结果</td><td>db.user.find().skip(1)</td></tr><tr><td>find({field:value}，{name:1,email:1})</td><td>条件查询</td><td>db.user.fing({level:3}，{name:1,email:1})              #查询level为3的用户，并返回他们的name和email两个字段，1为返回，0为不返回  （_id字段自动返回）</td></tr></tbody></table><ul><li>$gt :大于</li><li>$gte : 大于等于</li><li>$lt : 小于</li><li>$eq :等于</li><li>$in :在数组中</li><li>$nin : 不在数组中</li><li>$exist : 查询某个字段是否存在</li><li>$and : [{条件1},{条件2}]</li><li>$not : {条件} </li><li>$regex: &#x2F;expression&#x2F;,$options:’i’   : 正则表达式</li></ul><h2 id="在Springboot中使用MongoDB"><a href="#在Springboot中使用MongoDB" class="headerlink" title="在Springboot中使用MongoDB"></a>在Springboot中使用MongoDB</h2><h3 id="1-添加-MongoDB-Java-驱动依赖"><a href="#1-添加-MongoDB-Java-驱动依赖" class="headerlink" title="1. 添加 MongoDB Java 驱动依赖"></a>1. 添加 MongoDB Java 驱动依赖</h3><p>使用 Maven 管理依赖时，在 <code>pom.xml</code> 文件中添加 MongoDB Java 驱动依赖：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><h3 id="2-在-application-yml-中建立连接"><a href="#2-在-application-yml-中建立连接" class="headerlink" title="2. 在 application.yml 中建立连接"></a>2. 在 <code>application.yml</code> 中建立连接</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">mongodb:</span></span><br><span class="line">    <span class="attr">uri:</span> <span class="string">mongodb://localhost:27017/yourDatabase</span></span><br></pre></td></tr></table></figure><p>或在 <code>application.properties</code> 中：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spring.data.mongodb.uri=mongodb://localhost:27017/yourDatabase</span><br></pre></td></tr></table></figure><h3 id="3-创建-MongoDB-实体类"><a href="#3-创建-MongoDB-实体类" class="headerlink" title="3. 创建 MongoDB 实体类"></a>3. 创建 MongoDB 实体类</h3><p>为 MongoDB 集合创建一个实体类。使用 <code>@Document</code> 注解将类映射到 MongoDB 集合。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import org.springframework.data.annotation.Id;</span><br><span class="line">import org.springframework.data.mongodb.core.mapping.Document;</span><br><span class="line"></span><br><span class="line">@Document(collection = &quot;yourCollectionName&quot;)</span><br><span class="line">public class YourEntity &#123;</span><br><span class="line">    </span><br><span class="line">    @Id</span><br><span class="line">    private String id;</span><br><span class="line">    private String name;</span><br><span class="line">    private int age;</span><br><span class="line"></span><br><span class="line">    // 省略构造函数、Getter 和 Setter</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> MongoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于物联网实验室后端部门的一些常见疑惑解答</title>
      <link href="/2024/10/18/%E5%85%B3%E4%BA%8E%E7%89%A9%E8%81%94%E7%BD%91%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%90%8E%E7%AB%AF%E9%83%A8%E9%97%A8%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E7%96%91%E6%83%91%E8%A7%A3%E7%AD%94/"/>
      <url>/2024/10/18/%E5%85%B3%E4%BA%8E%E7%89%A9%E8%81%94%E7%BD%91%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%90%8E%E7%AB%AF%E9%83%A8%E9%97%A8%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E7%96%91%E6%83%91%E8%A7%A3%E7%AD%94/</url>
      
        <content type="html"><![CDATA[<h1 id="关于物联网实验室后端部门的一些常见疑惑解答"><a href="#关于物联网实验室后端部门的一些常见疑惑解答" class="headerlink" title="关于物联网实验室后端部门的一些常见疑惑解答"></a>关于物联网实验室后端部门的一些常见疑惑解答</h1><p>首先，我们物联网实验室是一个和谐欢乐，积极向上的大家庭，作为厂里的传统著名实验室，不少实验室的学长学姐都进入到了大厂或考研到92。在实验室里，我们会发布一些学习的路线和方法带着大家学习，但我们不会有非常硬性的任务要求，我们主张一起学习进步。同时，实验室会经常发布各类比赛的信息，实验室成员可以自由组队拿奖，并通过比赛来促进学习。</p><p>接下来解答一下大家一些对后端的常见疑惑。</p><h2 id="一、什么是后端开发？"><a href="#一、什么是后端开发？" class="headerlink" title="一、什么是后端开发？"></a>一、什么是后端开发？</h2><p>后端开发是指开发计算机程序的后端部分，也称为服务器端或应用程序服务器。后端开发通常涉及使用编程语言 (如 Java、Python、Ruby、PHP 等) 和数据库管理系统 (如 MySQL、Redis、Oracle 等) 来构建和维护服务器端应用程序。后端开发的主要任务是处理来自客户端的请求，并将处理结果返回给客户端。后端开发人员需要考虑如何优化应用程序的性能和可扩展性，同时需要确保应用程序的安全性和可靠性。此外，我们还需要随时处理服务器可能发生的问题。</p><p>说人话就是主要的是对一个网页的后台逻辑处理，和对数据库进行操作。</p><p>举一个最简单的例子，你点开一个新的网站，首先你要登录吧，你这时候在网页上输入了账号密码，我们后端就是要根据输入的账号，去数据库里查找这个账号对应的密码是多少，若匹配的上就输出登录成功，若匹配不上就输出登录失败；而如果你是第一次打开这个网站，你要注册，那么我们后端就要将前端输入的账号密码存到数据库中。</p><p>当然，后端不可能都是这么简单的业务需求，随着你们学习的深入，也会遇到更加复杂的业务逻辑，这些都需要我们后端来处理。</p><h2 id="二、后端开发的发展"><a href="#二、后端开发的发展" class="headerlink" title="二、后端开发的发展"></a>二、后端开发的发展</h2><p>在现在整体的就业大环境不佳的情况下，后端依旧算是一个香饽饽，相信大家也都在网上看到过互联网的高薪传奇，咱们后端在其中占了很大一部分。当然，这是一个看技术吃饭的行业，只要你技术过硬，你也能向那些学长学姐一样进入字节，滴滴。。。当然你也可以选择考研保研，继续精进。</p><p>行业的整体薪资情况大家可以了解一下<a href="https://blog.csdn.net/techforward/article/details/139960908">24 年程序员各岗位薪资待遇汇总（最新）_程序员相关的岗位-CSDN博客</a></p><h2 id="三、需要掌握的技能（仅以java方向举例）"><a href="#三、需要掌握的技能（仅以java方向举例）" class="headerlink" title="三、需要掌握的技能（仅以java方向举例）"></a>三、需要掌握的技能（仅以java方向举例）</h2><p>阶段一：</p><ul><li><p>java基础语法：面向过程编程、面向对象编程、集合、异常、反射。</p></li><li><p>操作系统相关：多线程、IO流。</p></li><li><p>数据结构与算法：表、树、哈希算法、KMP算法、动态规划入门。</p></li></ul><p>阶段二：</p><ul><li><p>计算机网络相关：TCP通信、HTTP协议、Cookie等。</p></li><li><p>数据库基础：MySQL数据库、JDBC框架、Mybatis框架。</p></li><li><p>前端基础：HTML页面、CSS样式、JavaScript脚本。</p></li><li><p>后端基础：Tomcat服务器、Servlet基础、图书管理系统实战。</p></li></ul><p>阶段三：</p><ul><li>Spring系列框架：Spring、SpringMVC、SpringSecurity。</li><li>数据库高级：存储过程、函数、锁、索引。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>外卖项目-Springboot回顾Day4</title>
      <link href="/2024/10/13/%E5%A4%96%E5%8D%96%E9%A1%B9%E7%9B%AE-Springboot%E5%9B%9E%E9%A1%BEDay4/"/>
      <url>/2024/10/13/%E5%A4%96%E5%8D%96%E9%A1%B9%E7%9B%AE-Springboot%E5%9B%9E%E9%A1%BEDay4/</url>
      
        <content type="html"><![CDATA[<h1 id="外卖项目–Springboot回顾Day4"><a href="#外卖项目–Springboot回顾Day4" class="headerlink" title="外卖项目–Springboot回顾Day4"></a>外卖项目–Springboot回顾Day4</h1><h2 id="httpclient使用示例"><a href="#httpclient使用示例" class="headerlink" title="httpclient使用示例"></a>httpclient使用示例</h2><p>HttpClient是Apache的一个子项目，是高效的、功能丰富的支持HTTP协议的客户端编程工具包。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootTest(classes = SkyApplication.class)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HttpClientTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 测试通过htttpclient来发送GET请求</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testGET</span><span class="params">()</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建httpclient对象</span></span><br><span class="line">        <span class="type">CloseableHttpClient</span> <span class="variable">httpClient</span> <span class="operator">=</span> HttpClients.createDefault();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建请求对象</span></span><br><span class="line">        <span class="type">HttpGet</span> <span class="variable">httpGet</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HttpGet</span>(<span class="string">&quot;http://localhost:8080/user/shop/status&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//发送请求，接受响应结果</span></span><br><span class="line">        <span class="type">CloseableHttpResponse</span> <span class="variable">response</span> <span class="operator">=</span> httpClient.execute(httpGet);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取服务端返回状态码</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">statusCode</span> <span class="operator">=</span> response.getStatusLine().getStatusCode();</span><br><span class="line">        System.out.println(<span class="string">&quot;服务端返回的状态码为:&quot;</span> + statusCode);</span><br><span class="line"></span><br><span class="line">        <span class="type">HttpEntity</span> <span class="variable">entity</span> <span class="operator">=</span> response.getEntity();</span><br><span class="line">        <span class="type">String</span> <span class="variable">body</span> <span class="operator">=</span> EntityUtils.toString(entity);</span><br><span class="line">        System.out.println(<span class="string">&quot;服务端返回的数据为:&quot;</span> + body);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//关闭资源</span></span><br><span class="line">        response.close();</span><br><span class="line">        httpClient.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 测试通过htttpclient来发送GET请求</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testPOST</span><span class="params">()</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">        <span class="comment">//创建httpclient对象</span></span><br><span class="line">        <span class="type">CloseableHttpClient</span> <span class="variable">httpClient</span> <span class="operator">=</span> HttpClients.createDefault();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建请求对象</span></span><br><span class="line">        <span class="type">HttpPost</span> <span class="variable">httpPost</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HttpPost</span>(<span class="string">&quot;http://localhost:8080/admin/employee/login&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">JSONObject</span> <span class="variable">jsonObject</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JSONObject</span>();</span><br><span class="line">        jsonObject.put(<span class="string">&quot;username&quot;</span>,<span class="string">&quot;admin&quot;</span>);</span><br><span class="line">        jsonObject.put(<span class="string">&quot;password&quot;</span>,<span class="string">&quot;123456&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">StringEntity</span> <span class="variable">entity</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringEntity</span>(jsonObject.toString());</span><br><span class="line">        <span class="comment">//指定请求的编码方式</span></span><br><span class="line">        entity.setContentEncoding(<span class="string">&quot;utf-8&quot;</span>);</span><br><span class="line">        <span class="comment">//数据格式</span></span><br><span class="line">        entity.setContentType(<span class="string">&quot;application/json&quot;</span>);</span><br><span class="line">        httpPost.setEntity(entity);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//发送请求</span></span><br><span class="line">        <span class="type">CloseableHttpResponse</span> <span class="variable">response</span> <span class="operator">=</span> httpClient.execute(httpPost);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//解析返回结果</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">statusCode</span> <span class="operator">=</span> response.getStatusLine().getStatusCode();</span><br><span class="line">        System.out.println(<span class="string">&quot;响应码为:&quot;</span> + statusCode);</span><br><span class="line"></span><br><span class="line">        <span class="type">HttpEntity</span> <span class="variable">entity1</span> <span class="operator">=</span> response.getEntity();</span><br><span class="line">        <span class="type">String</span> <span class="variable">body</span> <span class="operator">=</span> EntityUtils.toString(entity1);</span><br><span class="line">        System.out.println(<span class="string">&quot;响应数据为:&quot;</span> + body);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//关闭资源</span></span><br><span class="line">        response.close();</span><br><span class="line">        httpClient.close();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="微信小程序"><a href="#微信小程序" class="headerlink" title="微信小程序"></a>微信小程序</h2><p>小程序包含一个描述整体程序的app和多个描述各自页面的page。</p><p>主体部分由三个部分三个文件组成，必须放在项目的根目录</p><table><thead><tr><th>文件</th><th>必须</th><th>作用</th></tr></thead><tbody><tr><td>app.js</td><td>是</td><td>小程序逻辑</td></tr><tr><td>app.json</td><td>是</td><td>小程序公共配置</td></tr><tr><td>app.wxss</td><td>否</td><td>小程序公共样式表</td></tr></tbody></table><p>一个小程序页面由四个文件组成</p><table><thead><tr><th>文件</th><th>必须</th><th>作用</th></tr></thead><tbody><tr><td>js</td><td>是</td><td>页面逻辑</td></tr><tr><td>wxml</td><td>是</td><td>页面结构</td></tr><tr><td>json</td><td>否</td><td>页面配置</td></tr><tr><td>wxss</td><td>否</td><td>页面样式表</td></tr></tbody></table><h2 id="小程序登录流程"><a href="#小程序登录流程" class="headerlink" title="小程序登录流程"></a>小程序登录流程</h2><p><img src="/../img/java/20.png" alt="20"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Springboot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis常用指令整理</title>
      <link href="/2024/10/10/Redis%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4%E6%95%B4%E7%90%86/"/>
      <url>/2024/10/10/Redis%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="常用Redis命令整理"><a href="#常用Redis命令整理" class="headerlink" title="常用Redis命令整理"></a>常用Redis命令整理</h1><p>启动redis服务端</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server.exe redis.windows.conf</span><br></pre></td></tr></table></figure><p>启动redis客户端</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">redis-cli.exe</span><br><span class="line">后接参数</span><br><span class="line">-h 路由</span><br><span class="line">-p 端口</span><br><span class="line">-a 密码 </span><br></pre></td></tr></table></figure><h2 id="Redis数据类型"><a href="#Redis数据类型" class="headerlink" title="Redis数据类型"></a>Redis数据类型</h2><ol><li><p>string    </p></li><li><p>hash  </p></li><li><p>list  </p></li><li><p>set  集合</p></li><li><p>sorted set&#x2F;zset    有序集合：集合中的每个元素关联一个分数(score)，根据分数升序排列</p></li></ol><h2 id="String命令"><a href="#String命令" class="headerlink" title="String命令"></a>String命令</h2><ul><li>SET key value                                  #设置指定key的值</li><li>GET key                                            #获取指定key的值</li><li>SETEX key seconds value              #设置指定key的值，并将key 的过期时间设为seconds秒</li><li>SETNX key value                             #只有在key不存在时设置key的值</li></ul><h2 id="hash命令"><a href="#hash命令" class="headerlink" title="hash命令"></a>hash命令</h2><ul><li>HSET key field value                      #将哈希表key中的字段field的值设为value </li><li>HGET key field                                #获取存储在哈希表中指定字段的值</li><li>HDEL key field                                #删除存储在哈希表中的指定字段</li><li>HKEYS key                                       #获取哈希表中的所有字段</li><li>HVALS key                                       #获取哈希表中的所有值</li></ul><p><img src="/../img/java/redis/1.png" alt="1"></p><h2 id="list命令"><a href="#list命令" class="headerlink" title="list命令"></a>list命令</h2><ul><li>LPUSH key value1 [value2]      #将一个或多个值插入到列表头部(左边)</li><li>LRANGE key start stop         #获取列表指定范围内的元素</li><li>RPOP key                            #移除并获取列表最后一个元素(右边)</li><li>LLEN key                             # 获取列表长度</li></ul><h2 id="set操作命令"><a href="#set操作命令" class="headerlink" title="set操作命令"></a>set操作命令</h2><ul><li>SADD key member1 [member2]    #向集合添加一个或多个成员</li><li>SMEMBERS key                              #返回集合中的所有成员</li><li>SCARD key                                  #获取集合的成员数</li><li>SINTER key1 [key2]                        #返回给定所有集合的交集</li><li>SUNION key1 [key2]                      #返回所有给定集合的并集</li><li>SREM key member1 [member2]     #删除集合中一个或多个成员</li></ul><h2 id="zset-命令"><a href="#zset-命令" class="headerlink" title="zset 命令"></a>zset 命令</h2><ul><li>ZADD key score1 member1 [score2 member2]                 #向有序集合添加一个或多个成员</li><li>ZRANGE key start stop [WITHSCORES]                             #通过索引区间返回有序集合中指定区间内的成员</li><li>ZINCRBY key increment member                                 #有序集合中对指定成员的分数加上增量 </li><li>incrementZREM key member [member …]                 #移除有序集合中的一个或多个成员</li></ul><h2 id="通用命令"><a href="#通用命令" class="headerlink" title="通用命令"></a>通用命令</h2><ul><li>KEYS pattern         #查找所有符合给定模式( pattern)的 key </li><li>EXISTS key             #检查给定 key 是否存在</li><li>TYPE key                #返回 key 所储存的值的类型</li><li>DEL key                  #该命令用于在 key 存在是删除 key</li></ul><h1 id="在Java中操作Redis"><a href="#在Java中操作Redis" class="headerlink" title="在Java中操作Redis"></a>在Java中操作Redis</h1><p>以使用<strong>Spring Data Redis</strong>为例</p><ol><li>导入Spring Data Redis的maven坐标</li><li>配置Redis数据源</li><li>编写配置类，创建RedisTemplate对象</li><li>通过RedisTemplate对象操作Redis</li></ol><p>for example:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sky.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.sky.SkyApplication;</span><br><span class="line"><span class="keyword">import</span> org.junit.jupiter.api.Test;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.test.context.SpringBootTest;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.redis.core.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@SpringBootTest(classes = SkyApplication.class)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SpringDataRedisTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> RedisTemplate redisTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testRedisTemplate</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(redisTemplate);</span><br><span class="line">        <span class="comment">//创建一个ValueOperations对象，通过这个对象来操作字符串类型</span></span><br><span class="line">        <span class="type">ValueOperations</span> <span class="variable">valueOperations</span> <span class="operator">=</span> redisTemplate.opsForValue();</span><br><span class="line">        <span class="comment">//其他类型数据同理</span></span><br><span class="line">        <span class="type">HashOperations</span> <span class="variable">hashOperations</span> <span class="operator">=</span> redisTemplate.opsForHash();</span><br><span class="line">        <span class="type">ListOperations</span> <span class="variable">listOperations</span> <span class="operator">=</span> redisTemplate.opsForList();</span><br><span class="line">        <span class="type">SetOperations</span> <span class="variable">setOperations</span> <span class="operator">=</span> redisTemplate.opsForSet();</span><br><span class="line">        <span class="type">ZSetOperations</span> <span class="variable">zSetOperations</span> <span class="operator">=</span> redisTemplate.opsForZSet();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 操作字符串类型</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">//set get setex setnx</span></span><br><span class="line">        <span class="comment">//set</span></span><br><span class="line">        redisTemplate.opsForValue().set(<span class="string">&quot;city&quot;</span>,<span class="string">&quot;北京&quot;</span>);</span><br><span class="line">        <span class="comment">//get</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">city</span> <span class="operator">=</span> (String) redisTemplate.opsForValue().get(<span class="string">&quot;city&quot;</span>);</span><br><span class="line">        System.out.println(city);</span><br><span class="line">        <span class="comment">//setex</span></span><br><span class="line">        redisTemplate.opsForValue().set(<span class="string">&quot;code&quot;</span>,<span class="string">&quot;1212&quot;</span>,<span class="number">3</span>, TimeUnit.MINUTES);</span><br><span class="line">        redisTemplate.opsForValue().setIfAbsent(<span class="string">&quot;lock&quot;</span>,<span class="string">&quot;1&quot;</span>);</span><br><span class="line">        redisTemplate.opsForValue().setIfAbsent(<span class="string">&quot;lock&quot;</span>,<span class="string">&quot;2&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testHash</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">//hset hget hdel hkeys hvals</span></span><br><span class="line">        <span class="type">HashOperations</span> <span class="variable">hashOperations</span> <span class="operator">=</span> redisTemplate.opsForHash();</span><br><span class="line"></span><br><span class="line">        hashOperations.put(<span class="string">&quot;100&quot;</span>,<span class="string">&quot;name&quot;</span>,<span class="string">&quot;tom&quot;</span>);</span><br><span class="line">        hashOperations.put(<span class="string">&quot;100&quot;</span>,<span class="string">&quot;age&quot;</span>,<span class="string">&quot;20&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> (String) hashOperations.get(<span class="string">&quot;100&quot;</span>, <span class="string">&quot;name&quot;</span>);</span><br><span class="line">        System.out.println(name);</span><br><span class="line"></span><br><span class="line">        <span class="type">Set</span> <span class="variable">keys</span> <span class="operator">=</span> hashOperations.keys(<span class="string">&quot;100&quot;</span>);</span><br><span class="line">        System.out.println(keys);</span><br><span class="line"></span><br><span class="line">        <span class="type">List</span> <span class="variable">value</span> <span class="operator">=</span>hashOperations.values(<span class="string">&quot;100&quot;</span>);</span><br><span class="line">        System.out.println(value);</span><br><span class="line"></span><br><span class="line">        hashOperations.delete(<span class="string">&quot;100&quot;</span>,<span class="string">&quot;age&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="常见用法："><a href="#常见用法：" class="headerlink" title="常见用法："></a>常见用法：</h2><p><strong>使用RedisTemplate</strong></p><p>Spring Boot提供了RedisTemplate来方便地操作数据。在代码中注入RedisTemplate并使用它来进行CRUD操作：</p><h3 id="Redis常用的数据类型："><a href="#Redis常用的数据类型：" class="headerlink" title="Redis常用的数据类型："></a>Redis常用的数据类型：</h3><ul><li><p>String</p></li><li><p>Hash</p></li><li><p>List</p></li><li><p>Set</p></li><li><p>zSet</p></li><li><p>Sorted set</p></li></ul><h3 id="RedisTemplate-常用-API"><a href="#RedisTemplate-常用-API" class="headerlink" title="RedisTemplate 常用 API"></a>RedisTemplate 常用 API</h3><h4 id="String"><a href="#String" class="headerlink" title="String"></a>String</h4><h5 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h5><ol><li><p>判断是否又key所对应的值</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redisTemplete.hasKey(key);</span><br></pre></td></tr></table></figure></li><li><p>取出key值所对应的值</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redisTemplete.opsForVAlue().get(key);</span><br></pre></td></tr></table></figure></li><li><p>删除key所对应的值</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redisTemplete.delete(key);</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Springboot </tag>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>外卖项目--Springboot回顾Day3</title>
      <link href="/2024/09/28/%E5%A4%96%E5%8D%96%E9%A1%B9%E7%9B%AE-Springboot%E5%9B%9E%E9%A1%BEDay3/"/>
      <url>/2024/09/28/%E5%A4%96%E5%8D%96%E9%A1%B9%E7%9B%AE-Springboot%E5%9B%9E%E9%A1%BEDay3/</url>
      
        <content type="html"><![CDATA[<h1 id="外卖项目–Springboot回顾Day3"><a href="#外卖项目–Springboot回顾Day3" class="headerlink" title="外卖项目–Springboot回顾Day3"></a>外卖项目–Springboot回顾Day3</h1><h2 id="公共字段自动填充"><a href="#公共字段自动填充" class="headerlink" title="公共字段自动填充"></a>公共字段自动填充</h2><p>因为creat_time，create_user，update_time，update_user在每个mapper层中都有，造成了代码冗余并且不利于维护，所以本节使用切面将他们统一处理</p><p>思路：</p><ol><li>自定义注解AutoFill，用于标识需要公共字段自动填充的方法</li><li>自定义切面类AutoFillAspect，统一拦截加入了AutoFill注解的方法，通过反射为公共字段赋值</li><li>在Mapper的方法上加入AutoFill注解</li></ol><p>技术点：注解，AOP，反射</p><h3 id="代码实现-happy"><a href="#代码实现-happy" class="headerlink" title="代码实现:happy:"></a>代码实现:happy:</h3><h4 id="AutoFill-java"><a href="#AutoFill-java" class="headerlink" title="AutoFill.java"></a>AutoFill.java</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义注解，用于标识某个方法需要进行功能字段自动填充处理</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Target(ElementType.METHOD)</span></span><br><span class="line"><span class="meta">@Retention(RetentionPolicy.RUNTIME)</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> AutoFill &#123;</span><br><span class="line">    <span class="comment">//数据库操作类型：UPDATE INSERT</span></span><br><span class="line">    OperationType <span class="title function_">value</span><span class="params">()</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>@Target :指定当前代码会加在什么位置</p></li><li><p>@Retention :</p><p><code>@Retention</code>注解在Java中扮演着非常重要的角色，它用于指定自定义注解的保留策略，即定义注解在Java程序中的生命周期。具体来说，<code>@Retention</code>注解决定了注解信息被保留到什么阶段：是仅保留在源代码中，还是被编译到class文件中，或者是在运行时仍然保留并可被JVM访问。</p><p><code>@Retention</code>注解有一个参数<code>RetentionPolicy</code>，它是一个枚举类型，包含以下三个值：</p><ol><li><p>**<code>RetentionPolicy.SOURCE</code>**：</p><ul><li>这是最短的保留策略。注解仅保留在源代码中，不会被编译进class文件，也不会对运行时产生任何影响。</li><li>这种策略通常用于那些只需要在编译时存在，而在运行时不需要的注解，比如用于生成文档或进行编译时检查的注解。</li></ul></li><li><p>**<code>RetentionPolicy.CLASS</code>**：</p><ul><li>注解会被编译进class文件中，但在运行时不会被JVM保留，因此不能通过反射机制在运行时访问这些注解。</li><li>这是默认的保留策略，如果自定义注解没有显式指定<code>@Retention</code>注解，那么就会采用这种策略。</li><li>这种策略适用于那些需要在编译时或类加载时通过其他机制（非反射）访问的注解。</li></ul></li><li><p>**<code>RetentionPolicy.RUNTIME</code>**：</p><ul><li>注解会被编译进class文件中，并在运行时被JVM保留，因此可以通过反射机制在运行时访问这些注解。</li><li>这种策略通常用于那些需要在运行时通过反射读取注解信息的场景，比如实现自定义的注解处理器或框架。</li></ul></li></ol><p>使用<code>@Retention</code>注解可以帮助开发者更好地控制注解的生命周期，从而在不同的阶段（编译时、类加载时、运行时）根据需要来访问和处理注解信息。这对于开发框架、库或需要高度灵活性和动态性的应用程序来说尤为重要。</p></li></ul><h4 id="AutoFillAspect-java"><a href="#AutoFillAspect-java" class="headerlink" title="AutoFillAspect.java"></a>AutoFillAspect.java</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Aspect</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AutoFillAspect</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 切入点：对哪些类的哪些方法进行切入</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Pointcut(&quot;execution(* com.sky.mapper.*.*(..)) &amp;&amp; @annotation(com.sky.annotation.AutoFill)&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">autoFillPointCut</span><span class="params">()</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 前置通知,在通知中进行公共字段赋值</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Before(&quot;autoFillPointCut()&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">autoFill</span><span class="params">(JoinPoint joinPoint)</span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;开始进行公共字段自动填充...&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取到当前被拦截的数据库操作类型</span></span><br><span class="line">        <span class="type">MethodSignature</span> <span class="variable">signature</span> <span class="operator">=</span> (MethodSignature)joinPoint.getSignature();<span class="comment">//方法签名对象</span></span><br><span class="line">        <span class="type">AutoFill</span> <span class="variable">autoFill</span> <span class="operator">=</span> signature.getMethod().getAnnotation(AutoFill.class);<span class="comment">//获得方法上的注解对象</span></span><br><span class="line">        <span class="type">OperationType</span> <span class="variable">operationType</span> <span class="operator">=</span> autoFill.value();<span class="comment">//获得数据库操作类型</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取到当前被拦截的方法的参数--实体对象</span></span><br><span class="line">        Object[] args = joinPoint.getArgs();</span><br><span class="line">        <span class="keyword">if</span>(args==<span class="literal">null</span> || args.length == <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">Object</span> <span class="variable">entity</span> <span class="operator">=</span> args[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment">//准备复制数据</span></span><br><span class="line">        <span class="type">LocalDateTime</span> <span class="variable">now</span> <span class="operator">=</span> LocalDateTime.now();</span><br><span class="line">        <span class="type">Long</span> <span class="variable">currentId</span> <span class="operator">=</span> BaseContext.getCurrentId();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//根据当前不同的操作类型，为外卖对应的属性栏进行赋值</span></span><br><span class="line">        <span class="keyword">if</span>(operationType == OperationType.INSERT)&#123;</span><br><span class="line">            <span class="comment">//为4个公共字段赋值</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="type">Method</span> <span class="variable">setCreateTime</span> <span class="operator">=</span> entity.getClass().getDeclaredMethod(AutoFillConstant.SET_CREATE_TIME, LocalDateTime.class);</span><br><span class="line">                <span class="type">Method</span> <span class="variable">setCreateUser</span> <span class="operator">=</span> entity.getClass().getDeclaredMethod(AutoFillConstant.SET_CREATE_USER,Long.class);</span><br><span class="line">                <span class="type">Method</span> <span class="variable">setUpdateTime</span> <span class="operator">=</span> entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_TIME, LocalDateTime.class);</span><br><span class="line">                <span class="type">Method</span> <span class="variable">setUpdateUser</span> <span class="operator">=</span> entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_USER, Long.class);</span><br><span class="line"></span><br><span class="line">                <span class="comment">//通过反射为对象属性赋值</span></span><br><span class="line">                setCreateTime.invoke(entity,now);</span><br><span class="line">                setCreateUser.invoke(entity,currentId);</span><br><span class="line">                setUpdateTime.invoke(entity,now);</span><br><span class="line">                setUpdateUser.invoke(entity,currentId);</span><br><span class="line"></span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(operationType == OperationType.UPDATE)&#123;</span><br><span class="line">            <span class="comment">//为2个公共字段赋值</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="type">Method</span> <span class="variable">setUpdateTime</span> <span class="operator">=</span> entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_TIME, LocalDateTime.class);</span><br><span class="line">                <span class="type">Method</span> <span class="variable">setUpdateUser</span> <span class="operator">=</span> entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_USER, Long.class);</span><br><span class="line"></span><br><span class="line">                <span class="comment">//通过反射为对象属性赋值</span></span><br><span class="line">                setUpdateTime.invoke(entity,now);</span><br><span class="line">                setUpdateUser.invoke(entity,currentId);</span><br><span class="line"></span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>@Pointcut：对哪些包的哪些方法进行拦截</li></ul><p>  这个注释是一个AspectJ的<code>@Pointcut</code>注解，用于在面向切面编程（AOP）中定义一个切入点（Pointcut）。切入点是AOP中的一个核心概念，它定义了哪些类的哪些方法将被拦截（或称为“被增强”）以及何时被拦截。具体来说，这个<code>@Pointcut</code>注解定义了一个特定的切入点表达式，让我们逐步解析这个表达式：</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Pointcut(&quot;execution(* com.sky.mapper.*.*(..)) &amp;&amp; @annotation(com.sky.annotation.AutoFill)&quot;)</span></span><br></pre></td></tr></table></figure><h3 id="组成部分"><a href="#组成部分" class="headerlink" title="组成部分"></a>组成部分</h3><ol><li><p><em>execution(</em> com.sky.mapper.</p><p>.*(..))**:</p><ul><li><p>这是切入点表达式的主要部分，使用了<code>execution</code>模式匹配器。</p></li><li><pre><code>* com.sky.mapper.*.*(..)</code></pre><p>指定了匹配的方法签名。</p><ul><li>第一个<code>*</code>表示匹配任何返回类型。</li><li><code>com.sky.mapper</code>指定了包名，表示匹配该包及其子包下的类。</li><li>第二个<code>*</code>表示匹配<code>com.sky.mapper</code>包下的任何类。</li><li>第三个<code>*</code>表示匹配任何方法名。</li><li><code>(..)</code>表示匹配任何数量的参数（包括零个参数）。</li></ul></li><li><p>总的来说，这部分表达式匹配<code>com.sky.mapper</code>包及其子包下所有类的所有方法。</p></li></ul></li><li><p>&amp;&amp; @annotation(com.sky.annotation.AutoFill)</p><p>:</p><ul><li>这部分使用了逻辑与（<code>&amp;&amp;</code>）操作符来进一步限制匹配的方法。</li><li><code>@annotation(com.sky.annotation.AutoFill)</code>指定了另一个条件，即被匹配的方法上必须带有<code>@AutoFill</code>注解，该注解位于<code>com.sky.annotation</code>包下。</li><li>因此，只有当方法既位于<code>com.sky.mapper</code>包或其子包下的类中，又带有<code>@AutoFill</code>注解时，它才会被这个切入点表达式匹配。</li></ul></li></ol><ul><li><p>@Before(“autoFillPointCut()”) </p><p>用于定义一个前置通知（Before Advice），该通知会在目标方法执行之前运行。当你看到<code>@Before(&quot;autoFillPointCut()&quot;)</code>这样的代码时，它意味着定义了一个前置通知，该通知将会在任何被<code>autoFillPointCut()</code>切入点表达式匹配的方法执行之前运行。</p></li></ul><p>为什么使用到反射？</p><p>因为自动复制填充的表不是都是员工表，所以不可以向下转型成员工表，然后调用set方法直接修改，只能用反射动态调用set进行需改。反射允许程序在运行时动态地访问和操作类的属性和方法。通过使用反射，你可以不知道具体类名的情况下，调用任何对象的任何方法，只要这个方法存在且可访问。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Springboot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>外卖项目--Springboot回顾Day2</title>
      <link href="/2024/09/25/%E5%A4%96%E5%8D%96%E9%A1%B9%E7%9B%AE-Springboot%E5%9B%9E%E9%A1%BEDay2/"/>
      <url>/2024/09/25/%E5%A4%96%E5%8D%96%E9%A1%B9%E7%9B%AE-Springboot%E5%9B%9E%E9%A1%BEDay2/</url>
      
        <content type="html"><![CDATA[<h1 id="外卖项目–Springboot回顾Day2"><a href="#外卖项目–Springboot回顾Day2" class="headerlink" title="外卖项目–Springboot回顾Day2"></a>外卖项目–Springboot回顾Day2</h1><p>任务：</p><ol><li>新增员工</li><li>员工分页查询</li><li>启用禁用员工账号</li><li>编辑员工</li><li>导入分类模块功能代码</li></ol><p>每一个任务的完成逻辑：</p><ol><li>需求分析和设计（接口设计）</li><li>代码开发（根据新增员工接口设计对应DTO）</li><li>功能测试</li><li>代码完善</li></ol><p>本项目约定：</p><ul><li><p>管理端发出的请求，统一使用&#x2F;admin作为前缀</p></li><li><p>用户端发出的请求，统一使用&#x2F;user作为前缀</p></li></ul><h2 id="新增员工"><a href="#新增员工" class="headerlink" title="新增员工"></a>新增员工</h2><h3 id="需求分析和设计"><a href="#需求分析和设计" class="headerlink" title="需求分析和设计"></a>需求分析和设计</h3><img src="../img/java/springboot/1.png" alt="1" style="zoom:80%;" /><h3 id="1-在Controller中写方法save"><a href="#1-在Controller中写方法save" class="headerlink" title="1. 在Controller中写方法save"></a>1. 在Controller中写方法save</h3><p>接受前端的数据并封装为EmployeeDTO类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 新增员工</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> employeeDTO</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@PostMapping</span></span><br><span class="line">    <span class="meta">@ApiOperation(&quot;新增员工&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> Result <span class="title function_">save</span><span class="params">(<span class="meta">@RequestBody</span> EmployeeDTO employeeDTO)</span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;新增员工&#123;&#125;&quot;</span>,employeeDTO);</span><br><span class="line">        System.out.println(<span class="string">&quot;当前线程的id:&quot;</span> + Thread.currentThread().getId());</span><br><span class="line">        employeeService.save(employeeDTO);</span><br><span class="line">        <span class="keyword">return</span> Result.success();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h3 id="2-在Service层中的接口声明方法save，并在实现类中实现"><a href="#2-在Service层中的接口声明方法save，并在实现类中实现" class="headerlink" title="2. 在Service层中的接口声明方法save，并在实现类中实现"></a>2. 在Service层中的接口声明方法save，并在实现类中实现</h3><p>需要在Service层中将EmployeeDTO类转为实体类，方便插入到数据库</p><p>EmployeeService.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 新增员工</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> employeeDTO</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">save</span><span class="params">(EmployeeDTO employeeDTO)</span>;</span><br></pre></td></tr></table></figure><p>EmployeeServicelmpl.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 新增员工</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> employeeDTO</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">save</span><span class="params">(EmployeeDTO employeeDTO)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;当前线程的id:&quot;</span> + Thread.currentThread().getId());</span><br><span class="line">        Employee employee= <span class="keyword">new</span> <span class="title class_">Employee</span>();</span><br><span class="line"></span><br><span class="line">         <span class="comment">//对象属性拷贝</span></span><br><span class="line">        BeanUtils.copyProperties(employeeDTO,employee);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置剩余属性</span></span><br><span class="line">        <span class="comment">//设置账号状态，默认正常状态，1表示正常，0表示锁定</span></span><br><span class="line">        employee.setStatus(StatusConstant.ENABLE);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置密码，默认为123456</span></span><br><span class="line">        employee.setPassword(DigestUtils.md5DigestAsHex(PasswordConstant.DEFAULT_PASSWORD.getBytes()));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置当前记录的创建时间你和修改时间</span></span><br><span class="line">        employee.setCreateTime(LocalDateTime.now());</span><br><span class="line">        employee.setUpdateTime(LocalDateTime.now());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//修改当前记录创建人id和修改人id</span></span><br><span class="line">        employee.setCreateUser(<span class="number">10L</span>);</span><br><span class="line">        employee.setUpdateUser(<span class="number">10L</span>);</span><br><span class="line"></span><br><span class="line">        employeeMapper.insert(employee);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>在Service持久层中使用实体类</p><p>所以需要将EmployeeDTO转换为实体类，通过使用对象属性拷贝，来避免过多的get，set方法造成代码冗余</p><h3 id="3-在Mapper层中实现数据插入"><a href="#3-在Mapper层中实现数据插入" class="headerlink" title="3. 在Mapper层中实现数据插入"></a>3. 在Mapper层中实现数据插入</h3><p>由于操作较为简洁，我通过@Insert注解的方式直接在EmployeeMapper.java中实现</p><p>EmployeeMapper.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 插入员工数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> employee</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Insert(&quot;insert into employee (name, username, password, phone, sex, id_number, status, create_time, update_time, create_user, update_user) &quot; +</span></span><br><span class="line"><span class="meta">            &quot;values &quot; +</span></span><br><span class="line"><span class="meta">            &quot;(#&#123;name&#125;,#&#123;username&#125;,#&#123;password&#125;,#&#123;phone&#125;,#&#123;sex&#125;,#&#123;idNumber&#125;,#&#123;status&#125;,#&#123;createTime&#125;,#&#123;updateTime&#125;,#&#123;createUser&#125;,#&#123;updateUser&#125;)&quot;)</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">insert</span><span class="params">(Employee employee)</span>;</span><br></pre></td></tr></table></figure><h3 id="功能测试"><a href="#功能测试" class="headerlink" title="功能测试"></a>功能测试</h3><ul><li>通过接口文档测试</li><li>前后端调测</li></ul><h3 id="代码完善"><a href="#代码完善" class="headerlink" title="代码完善"></a>代码完善</h3><p>问题：</p><ol><li>录入的用户名若已存在，抛出异常后没有处理</li><li>新增员工时，创建人id和修改人id设为了固定值”10L”</li></ol><p>解决:</p><h4 id="重载方法exceptionHandler"><a href="#重载方法exceptionHandler" class="headerlink" title="重载方法exceptionHandler"></a>重载方法exceptionHandler</h4><p>在全局异常处理器GlobalExceptionHandler.java中重载方法exceptionHandler来处理报出的SQLIntegrityConstraintViolationException类异常</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 处理SQL异常</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> ex</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@ExceptionHandler</span></span><br><span class="line">    <span class="keyword">public</span> Result <span class="title function_">exceptionHandler</span><span class="params">(SQLIntegrityConstraintViolationException ex)</span>&#123;</span><br><span class="line">        <span class="comment">//Duplicate entry &#x27;zhangsan&#x27; for key &#x27;idx_username&#x27;</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">message</span> <span class="operator">=</span> ex.getMessage();</span><br><span class="line">        <span class="keyword">if</span>(message.contains(<span class="string">&quot;Duplicate entry&quot;</span>))&#123;</span><br><span class="line">            String[] split = message.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">username</span> <span class="operator">=</span>split[<span class="number">2</span>];</span><br><span class="line">            <span class="type">String</span> <span class="variable">msg</span> <span class="operator">=</span> username + MessageConstant.ALREADY_EXIST;</span><br><span class="line">            <span class="keyword">return</span> Result.error(msg);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="keyword">return</span>(Result.error(MessageConstant.UNKNOWN_ERROR));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h4 id="使用TreadLocal来保存真实创建人id和修改人id"><a href="#使用TreadLocal来保存真实创建人id和修改人id" class="headerlink" title="使用TreadLocal来保存真实创建人id和修改人id"></a>使用TreadLocal来保存真实创建人id和修改人id</h4><p>思路：</p><ol><li>员工登录成功后会生成Jwt令牌并响应给前端</li><li>后续请求中，前端会携带Jwt令牌，通过令牌可以解析出当前员工id</li><li>通过TreadLocal将解析出的当前员工id传递给Service的save方法</li></ol><p>Treadlocal:并不是一个线程，而是线程的一个局部变量：为每个线程单独提供一份存储空间，具有县城隔离效果，只有在同一线程内才能获取到对应的值</p><p>Treadlocal常用方法：</p><ul><li>public void set(T value)          &#x2F;&#x2F;设置当前线程的局部变量的值</li><li>public T get()                            &#x2F;&#x2F;得到当前线程的局部变量的值</li><li>public void remove()              &#x2F;&#x2F;移除当前线程的局部变量的值</li></ul><p>本项目已经把这三个方法封装到了工具类BaseContext</p><h2 id="员工分类查询"><a href="#员工分类查询" class="headerlink" title="员工分类查询"></a>员工分类查询</h2><h3 id="需求分析和设计-1"><a href="#需求分析和设计-1" class="headerlink" title="需求分析和设计"></a>需求分析和设计</h3><img src="../img/java/springboot/2.png" alt="2" style="zoom:50%;" /><h3 id="代码开发"><a href="#代码开发" class="headerlink" title="代码开发"></a>代码开发</h3><p>依据分页查询接口设计对应的DTO</p><p>后面所有的分页查询，统一封装成PageResult对象，再封装为Result<PageResult>，返回给前端</p><p>PageResult.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 封装分页查询结果</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PageResult</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> total; <span class="comment">//总记录数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> List records; <span class="comment">//当前页数据集合</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>之后完成剩余代码</p><p>EmployeeServicelmpl.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 员工分页查询</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> employeePageQueryDTO</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> PageResult <span class="title function_">pageQuery</span><span class="params">(EmployeePageQueryDTO employeePageQueryDTO)</span>&#123;</span><br><span class="line">        <span class="comment">//使用PageHelper插件进行分页查询</span></span><br><span class="line">        PageHelper.startPage(employeePageQueryDTO.getPage(),employeePageQueryDTO.getPageSize());</span><br><span class="line"></span><br><span class="line">        Page&lt;Employee&gt; page=employeeMapper.pageQuery(employeePageQueryDTO);</span><br><span class="line"></span><br><span class="line">        <span class="type">long</span> <span class="variable">total</span> <span class="operator">=</span> page.getTotal();</span><br><span class="line">        List&lt;Employee&gt; record = page.getResult();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">PageResult</span>(total,record);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>问题：返回给前端的日期显示不明确，eg:202309221823，期望显示则是2023年9月22日18：23</p><p>解决方法:</p><ol><li>在属性上加入注释，对日期进行格式化</li><li>在WebMvcConfignration中拓展Spring MVC的消息转换器，统一对日期类型进行格式化处理</li></ol><p>WebMvcConfignration.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 扩展spring MVC框架的消息转化器</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> converters</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">extendMessageConverters</span><span class="params">(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters)</span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;扩展消息转换器...&quot;</span>);</span><br><span class="line">        <span class="comment">//创建一个消息转换器对象</span></span><br><span class="line">        <span class="type">MappingJackson2HttpMessageConverter</span> <span class="variable">converter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MappingJackson2HttpMessageConverter</span>();</span><br><span class="line">        <span class="comment">//为消息转换器设置一个对象转换器，对象转换器可以将Java对象转化为json数据</span></span><br><span class="line">        converter.setObjectMapper(<span class="keyword">new</span> <span class="title class_">JacksonObjectMapper</span>());</span><br><span class="line">        <span class="comment">//将自己的消息转换器加入到容器中</span></span><br><span class="line">        converters.add(<span class="number">0</span>,converter);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>序列化：Java对象—–&gt;Json对象</p><h2 id="启用-禁用员工账号"><a href="#启用-禁用员工账号" class="headerlink" title="启用&#x2F;禁用员工账号"></a>启用&#x2F;禁用员工账号</h2><h3 id="需求分析和设计-2"><a href="#需求分析和设计-2" class="headerlink" title="需求分析和设计"></a>需求分析和设计</h3><p><img src="/../img/java/springboot/3.png" alt="3"></p><p><img src="/../img/java/springboot/4.png" alt="4"></p><h3 id="代码开发-1"><a href="#代码开发-1" class="headerlink" title="代码开发"></a>代码开发</h3><p>EmployeeController.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 启用或禁用员工账号</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> status</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@PostMapping(&quot;/status/&#123;status&#125;&quot;)</span></span><br><span class="line">    <span class="meta">@ApiOperation(&quot;启用或禁用员工账号&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> Result <span class="title function_">startOrStop</span><span class="params">(<span class="meta">@PathVariable(&quot;status&quot;)</span> Integer status,Long id)</span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;启用或禁用员工账号：&#123;&#125;,&#123;&#125;&quot;</span>,status,id);</span><br><span class="line">        employeeService.startOrStop(status,id);</span><br><span class="line">        <span class="keyword">return</span> Result.success();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>EmployeeServicelmpl.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">startOrStop</span><span class="params">(Integer status, Long id)</span> &#123;</span><br><span class="line">        <span class="type">Employee</span> <span class="variable">employee</span> <span class="operator">=</span> Employee.builder()</span><br><span class="line">                .status(status)</span><br><span class="line">                .id(id)</span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        employeeMapper.update(employee);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>EmployeeMapper.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">update</span> <span class="attr">id</span>=<span class="string">&quot;update&quot;</span> <span class="attr">parameterType</span>=<span class="string">&quot;Employee&quot;</span>&gt;</span></span><br><span class="line">        update employee</span><br><span class="line">        <span class="tag">&lt;<span class="name">set</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">if</span> <span class="attr">test</span>=<span class="string">&quot;name != null&quot;</span>&gt;</span>name = #&#123;name&#125;,<span class="tag">&lt;/<span class="name">if</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">if</span> <span class="attr">test</span>=<span class="string">&quot;username != null&quot;</span>&gt;</span>username = #&#123;username&#125;,<span class="tag">&lt;/<span class="name">if</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">if</span> <span class="attr">test</span>=<span class="string">&quot;password != null&quot;</span>&gt;</span>password = #&#123;password&#125;,<span class="tag">&lt;/<span class="name">if</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">if</span> <span class="attr">test</span>=<span class="string">&quot;phone != null&quot;</span>&gt;</span>phone = #&#123;phone&#125;,<span class="tag">&lt;/<span class="name">if</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">if</span> <span class="attr">test</span>=<span class="string">&quot;sex != null&quot;</span>&gt;</span>sex = #&#123;sex&#125;,<span class="tag">&lt;/<span class="name">if</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">if</span> <span class="attr">test</span>=<span class="string">&quot;idNumber != null&quot;</span>&gt;</span>id_Number = #&#123;idNumber&#125;,<span class="tag">&lt;/<span class="name">if</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">if</span> <span class="attr">test</span>=<span class="string">&quot;updateTime != null&quot;</span>&gt;</span>update_Time = #&#123;updateTime&#125;,<span class="tag">&lt;/<span class="name">if</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">if</span> <span class="attr">test</span>=<span class="string">&quot;updateUser != null&quot;</span>&gt;</span>update_User = #&#123;updateUser&#125;,<span class="tag">&lt;/<span class="name">if</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">if</span> <span class="attr">test</span>=<span class="string">&quot;status != null&quot;</span>&gt;</span>status = #&#123;status&#125;,<span class="tag">&lt;/<span class="name">if</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">set</span>&gt;</span></span><br><span class="line">        where id=#&#123;id&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">update</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="编辑员工"><a href="#编辑员工" class="headerlink" title="编辑员工"></a>编辑员工</h2><p>EmployeeController.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 根据id查询员工信息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/&#123;id&#125;&quot;)</span></span><br><span class="line">    <span class="meta">@ApiOperation(&quot;根据id查询员工信息&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> Result&lt;Employee&gt; <span class="title function_">getById</span><span class="params">(<span class="meta">@PathVariable(&quot;id&quot;)</span> Long id)</span>&#123;</span><br><span class="line">        <span class="type">Employee</span> <span class="variable">employee</span> <span class="operator">=</span> employeeService.getById(id);</span><br><span class="line">        <span class="keyword">return</span> Result.success(employee);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 编辑员工信息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> employeeDTO</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@PutMapping</span></span><br><span class="line">    <span class="meta">@ApiOperation(&quot;编辑员工信息&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> Result <span class="title function_">update</span><span class="params">(<span class="meta">@RequestBody</span> EmployeeDTO employeeDTO)</span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;编辑员工信息：&#123;&#125;&quot;</span>,employeeDTO);</span><br><span class="line">        employeeService.update(employeeDTO);</span><br><span class="line">        <span class="keyword">return</span> Result.success();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>EmployeeServicelmpl.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 根据id查询员工信息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> Employee <span class="title function_">getById</span><span class="params">(Long id)</span>&#123;</span><br><span class="line">        <span class="type">Employee</span> <span class="variable">employee</span> <span class="operator">=</span> employeeMapper.getById(id);</span><br><span class="line">        employee.setPassword(<span class="string">&quot;******&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> employee;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 剪辑员工信息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> employeeDTO</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">update</span><span class="params">(EmployeeDTO employeeDTO)</span> &#123;</span><br><span class="line">        <span class="type">Employee</span> <span class="variable">employee</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Employee</span>();</span><br><span class="line">        BeanUtils.copyProperties(employeeDTO,employee);</span><br><span class="line"></span><br><span class="line">        employee.setUpdateTime(LocalDateTime.now());</span><br><span class="line">        employee.setUpdateUser(BaseContext.getCurrentId());</span><br><span class="line"></span><br><span class="line">        employeeMapper.update(employee);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Springboot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>外卖项目--Springboot回顾Day1</title>
      <link href="/2024/09/24/%E5%A4%96%E5%8D%96%E9%A1%B9%E7%9B%AE-Springboot%E5%9B%9E%E9%A1%BEDay1/"/>
      <url>/2024/09/24/%E5%A4%96%E5%8D%96%E9%A1%B9%E7%9B%AE-Springboot%E5%9B%9E%E9%A1%BEDay1/</url>
      
        <content type="html"><![CDATA[<h1 id="外卖项目–Springboot回顾Day1"><a href="#外卖项目–Springboot回顾Day1" class="headerlink" title="外卖项目–Springboot回顾Day1"></a>外卖项目–Springboot回顾Day1</h1><h2 id="项目简单介绍和启动"><a href="#项目简单介绍和启动" class="headerlink" title="项目简单介绍和启动"></a>项目简单介绍和启动</h2><p>前端通过nginx.exe直接启动</p><p>后端使用maven同一管理依赖版本</p><p>后端结构：</p><ol><li>-common 存放实体类</li><li>-pojo 实体类，DTO（数据传输对象）,VO（视图对象-返回给前端页面）,POJO（普通JAVA对象-属性及对应的getter和setter方法）</li><li>-sever 后端服务，Controller，Service，Mapper</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Result&lt;EmployeeLoginVO&gt; <span class="title function_">login</span><span class="params">(<span class="meta">@RequestBody</span> EmployeeLoginDTO employeeLoginDTO)</span>&#123;&#125;</span><br></pre></td></tr></table></figure><p>后端返回的结果统一封装为Result<EmployeeLoginVO>，接受的参数为DTO</p><h2 id="Nginx-反向代理"><a href="#Nginx-反向代理" class="headerlink" title="Nginx 反向代理"></a>Nginx 反向代理</h2><p>前端请求地址：http:&#x2F;&#x2F; localhost&#x2F;api&#x2F;employee&#x2F;login     （默认端口80）</p><p>后端服务地址：http:&#x2F;&#x2F; localhost&#x2F;:8080&#x2F;admin&#x2F;employee&#x2F;login</p><p>浏览器—————&gt; Nginx ————–&gt;Tomcat</p><p>Nginx反向代理:将前端发送的动态请求由Nginx转发到后端服务器</p><p>优点：</p><ol><li><p>提高访问速度 (Nginx有缓存)</p></li><li><p>进行运载均衡：将大量的请求按照指定的方式均衡地分配给集群中的每台服务器</p></li><li><p>保证后端安全(隐藏后端地址)</p></li></ol><h3 id="Nginx策略"><a href="#Nginx策略" class="headerlink" title="Nginx策略"></a>Nginx策略</h3><table><thead><tr><th align="center">论调</th><th align="left">默认</th></tr></thead><tbody><tr><td align="center">weight</td><td align="left">权重，默认为1，权重越大，被分配的客户端请求越多</td></tr><tr><td align="center">ip_hash</td><td align="left">依据ip，每个访客可以固定访问一个后端服务器</td></tr><tr><td align="center">least_conn</td><td align="left">依据最少连接，吧把请求优先分配给连接少的服务器</td></tr><tr><td align="center">url_hash</td><td align="left">依据url分配，相同的url分配到一个后端</td></tr><tr><td align="center">fair</td><td align="left">响应时间，响应时间短的服务优先被分配</td></tr></tbody></table><h3 id="配置文件nginxconf"><a href="#配置文件nginxconf" class="headerlink" title="配置文件nginxconf"></a>配置文件nginxconf</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  localhost;</span><br><span class="line">    </span><br><span class="line">    upstream webservers&#123;</span><br><span class="line">  server 127.0.0.1:8080 weight=90 ;</span><br><span class="line">  #server 127.0.0.1:8088 weight=10 ;</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line">   </span><br><span class="line">    # 反向代理,处理用户端发送的请求</span><br><span class="line">    location /user/ &#123;</span><br><span class="line">        proxy_pass   http://webservers/user/;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;    </span><br></pre></td></tr></table></figure><h2 id="完善登录功能"><a href="#完善登录功能" class="headerlink" title="完善登录功能"></a>完善登录功能</h2><p>问题：员工表中的密码是明文存储，安全性太低</p><p>思路：使用MD5加密</p><ol><li>修改数据库中的明文密码</li><li>修改Java，将前端提交的代码进行MD5加密后再存储</li></ol><h2 id="接口文档"><a href="#接口文档" class="headerlink" title="接口文档"></a>接口文档</h2><p>接口管理平台： YApi </p><p>Swagger ——- 按照约定的规范去定义接口及接口相关信息，就可以生成接口文档以及在线接口调试页面（官网<a href="https://swagger.io/%EF%BC%89">https://swagger.io/）</a></p><p>Knife4j是为JavaMVC框架生成的Swagger生产Api文档的增强解决方案</p><p>使用方式：</p><ol><li>导入knife4j的maven坐标</li><li>在配置中加入knife4j的相关配置</li><li>设置静态资源映射，否则接口文档无法访问</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//WebMvcConfiguration.java</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 配置类，注册web层相关组件</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WebMvcConfiguration</span> <span class="keyword">extends</span> <span class="title class_">WebMvcConfigurationSupport</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> JwtTokenAdminInterceptor jwtTokenAdminInterceptor;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 注册自定义拦截器</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> registry</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">addInterceptors</span><span class="params">(InterceptorRegistry registry)</span> &#123;</span><br><span class="line">        log.info(<span class="string">&quot;开始注册自定义拦截器...&quot;</span>);</span><br><span class="line">        registry.addInterceptor(jwtTokenAdminInterceptor)</span><br><span class="line">                .addPathPatterns(<span class="string">&quot;/admin/**&quot;</span>)</span><br><span class="line">                .excludePathPatterns(<span class="string">&quot;/admin/employee/login&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 通过knife4j生成接口文档</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> Docket <span class="title function_">docket</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">ApiInfo</span> <span class="variable">apiInfo</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ApiInfoBuilder</span>()</span><br><span class="line">                .title(<span class="string">&quot;苍穹外卖项目接口文档&quot;</span>)</span><br><span class="line">                .version(<span class="string">&quot;2.0&quot;</span>)</span><br><span class="line">                .description(<span class="string">&quot;苍穹外卖项目接口文档&quot;</span>)</span><br><span class="line">                .build();</span><br><span class="line">        <span class="type">Docket</span> <span class="variable">docket</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Docket</span>(DocumentationType.SWAGGER_2)</span><br><span class="line">                .apiInfo(apiInfo)</span><br><span class="line">                .select()</span><br><span class="line">                .apis(RequestHandlerSelectors.basePackage(<span class="string">&quot;com.sky.controller&quot;</span>))</span><br><span class="line">                .paths(PathSelectors.any())</span><br><span class="line">                .build();</span><br><span class="line">        <span class="keyword">return</span> docket;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 设置静态资源映射</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> registry</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">addResourceHandlers</span><span class="params">(ResourceHandlerRegistry registry)</span> &#123;</span><br><span class="line">        registry.addResourceHandler(<span class="string">&quot;/doc.html&quot;</span>).addResourceLocations(<span class="string">&quot;classpath:/META-INF/resources/&quot;</span>);</span><br><span class="line">        registry.addResourceHandler(<span class="string">&quot;/webjars/**&quot;</span>).addResourceLocations(<span class="string">&quot;classpath:/META-INF/resources/webjars/&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="常用注解"><a href="#常用注解" class="headerlink" title="常用注解"></a>常用注解</h3><table><thead><tr><th align="center">@Api</th><th>用在类上，例如：Controller ,表对类的说明</th></tr></thead><tbody><tr><td align="center"><strong>@ApiModel</strong></td><td><strong>用在类上，例如：entity,DTO,VO,表对类的用途说明</strong></td></tr><tr><td align="center"><strong>@ApiModelProperty</strong></td><td><strong>用在属性上，描述属性信息</strong></td></tr><tr><td align="center"><strong>@ApiOperation</strong></td><td><strong>用在方法上，说明方法的作用和用途</strong></td></tr></tbody></table>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Springboot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>React快速入门学习笔记</title>
      <link href="/2024/09/12/React%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2024/09/12/React%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="React快速入门笔记"><a href="#React快速入门笔记" class="headerlink" title="React快速入门笔记"></a>React快速入门笔记</h1><h2 id="创建和嵌套组件"><a href="#创建和嵌套组件" class="headerlink" title="创建和嵌套组件"></a>创建和嵌套组件</h2><p>React 应用程序是由 <strong>组件</strong> 组成的。一个组件是 UI（用户界面）的一部分，它拥有自己的逻辑和外观。</p><p>React 组件是返回标签的 JavaScript 函数：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">MyButton</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">button</span>&gt;</span>I&#x27;m a button<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完成以上代码，你就创建了一个MyButton组件，现在将它<strong>嵌套</strong>到另外一个组件中</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">MyApp</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">h1</span>&gt;</span>Welcome to my app<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">MyButton</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>React 组件必须以大写字母开头，而 HTML 标签则必须是小写字母。例如以上代码的**<MyButton />**。</p><p>For example:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">MyButton</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">button</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      I&#x27;m a button</span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">MyApp</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">h1</span>&gt;</span>Welcome to my app<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">MyButton</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>export default</code> 是 JavaScript 模块系统中的一个关键字，用于从一个模块导出一个默认的值或函数或类。</p><h2 id="使用-JSX-编写标签"><a href="#使用-JSX-编写标签" class="headerlink" title="使用 JSX 编写标签"></a>使用 JSX 编写标签</h2><p>JSX 是 JavaScript XML 的缩写，是一种 JavaScript 的语法扩展，它允许开发者在 JavaScript 文件中编写类似 HTML 的代码。</p><p>JSX 比 HTML 更加严格。你必须闭合标签，如 <code>&lt;br /&gt;</code>。你的组件也不能返回多个 JSX 标签。你必须将它们包裹到一个共享的父级中。</p><h2 id="添加样式"><a href="#添加样式" class="headerlink" title="添加样式"></a>添加样式</h2><p>在 React 中，你可以使用 <code>className</code> 来指定一个 CSS 的 class。它与 HTML 的 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTML/Global_attributes/class"><code>class</code></a> 属性的工作方式相同：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;img className=<span class="string">&quot;avatar&quot;</span> /&gt;</span><br></pre></td></tr></table></figure><p>然后，你可以在一个单独的 CSS 文件中为它编写 CSS 规则：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* In your CSS */</span></span><br><span class="line">.<span class="property">avatar</span> &#123;</span><br><span class="line">  border-<span class="attr">radius</span>: <span class="number">50</span>%;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>React 并没有规定你如何添加 CSS 文件。最简单的方式是使用 HTML 的 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTML/Element/link">&#96;&#96;</a> 标签。</p><h2 id="显示数据"><a href="#显示数据" class="headerlink" title="显示数据"></a>显示数据</h2><p>JSX 会让你把标签放到 JavaScript 中。而大括号会让你 “回到” JavaScript 中，这样你就可以从你的代码中嵌入一些变量并展示给用户</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> (</span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">h1</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    &#123;user.name&#125;</span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span></span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>你还可以将 JSX 属性 “转义到 JavaScript”，但你必须使用大括号 <strong>而非</strong> 引号。例如，<code>className=&quot;avatar&quot;</code> 是将 <code>&quot;avatar&quot;</code> 字符串传递给 <code>className</code>，作为 CSS 的 class。但 <code>src=&#123;user.imageUrl&#125;</code> 会读取 JavaScript 的 <code>user.imageUrl</code> 变量，然后将该值作为 <code>src</code> 属性传递：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> (</span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">img</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">    <span class="attr">className</span>=<span class="string">&quot;avatar&quot;</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">    <span class="attr">src</span>=<span class="string">&#123;user.imageUrl&#125;</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">  /&gt;</span></span></span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>也可以把更为复杂的表达式放入 JSX 的大括号内</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> user = &#123;</span><br><span class="line">  <span class="attr">name</span>: <span class="string">&#x27;Hedy Lamarr&#x27;</span>,</span><br><span class="line">  <span class="attr">imageUrl</span>: <span class="string">&#x27;https://i.imgur.com/yXOvdOSs.jpg&#x27;</span>,</span><br><span class="line">  <span class="attr">imageSize</span>: <span class="number">90</span>,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">Profile</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">h1</span>&gt;</span>&#123;user.name&#125;<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">img</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">        <span class="attr">className</span>=<span class="string">&quot;avatar&quot;</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">        <span class="attr">src</span>=<span class="string">&#123;user.imageUrl&#125;</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">        <span class="attr">alt</span>=<span class="string">&#123;</span>&#x27;<span class="attr">Photo</span> <span class="attr">of</span> &#x27; + <span class="attr">user.name</span>&#125;</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">        <span class="attr">style</span>=<span class="string">&#123;&#123;</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          <span class="attr">width:</span> <span class="attr">user.imageSize</span>,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          <span class="attr">height:</span> <span class="attr">user.imageSize</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">        &#125;&#125;</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">      /&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="条件渲染"><a href="#条件渲染" class="headerlink" title="条件渲染"></a>条件渲染</h2><p>React 没有特殊的语法来编写条件语句，因此你使用的就是普通的 JavaScript 代码。例如使用 <a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Statements/if...else"><code>if</code></a> 语句根据条件引入 JSX：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> content;</span><br><span class="line"><span class="keyword">if</span> (isLoggedIn) &#123;</span><br><span class="line">  content = <span class="language-xml"><span class="tag">&lt;<span class="name">AdminPanel</span> /&gt;</span></span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  content = <span class="language-xml"><span class="tag">&lt;<span class="name">LoginForm</span> /&gt;</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> (</span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    &#123;content&#125;</span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>如果你喜欢更为紧凑的代码，可以使用 <a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Operators/Conditional_Operator">条件 <code>?</code> 运算符</a>。与 <code>if</code> 不同的是，它工作于 JSX 内部：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">  &#123;isLoggedIn ? (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">AdminPanel</span> /&gt;</span></span></span><br><span class="line">  ) : (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">LoginForm</span> /&gt;</span></span></span><br><span class="line">  )&#125;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure><p>当你不需要 <code>else</code> 分支时，你也可以使用更简短的  <code>&amp;&amp;</code> </p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">  &#123;isLoggedIn &amp;&amp; <span class="language-xml"><span class="tag">&lt;<span class="name">AdminPanel</span> /&gt;</span></span>&#125;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure><h2 id="渲染列表"><a href="#渲染列表" class="headerlink" title="渲染列表"></a>渲染列表</h2><p>你将依赖 JavaScript 的特性，例如 <a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Statements/for"><code>for</code> 循环</a> 和 <a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Array/map">array 的 <code>map()</code> 函数</a> 来渲染组件列表。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> products = [</span><br><span class="line">  &#123; <span class="attr">title</span>: <span class="string">&#x27;Cabbage&#x27;</span>, <span class="attr">id</span>: <span class="number">1</span> &#125;,</span><br><span class="line">  &#123; <span class="attr">title</span>: <span class="string">&#x27;Garlic&#x27;</span>, <span class="attr">id</span>: <span class="number">2</span> &#125;,</span><br><span class="line">  &#123; <span class="attr">title</span>: <span class="string">&#x27;Apple&#x27;</span>, <span class="attr">id</span>: <span class="number">3</span> &#125;,</span><br><span class="line">];</span><br></pre></td></tr></table></figure><p>在你的组件中，使用 <code>map()</code> 函数将这个数组转换为 <code>&lt;li&gt;</code> 标签构成的列表:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> listItems = products.<span class="title function_">map</span>(<span class="function"><span class="params">product</span> =&gt;</span></span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">li</span> <span class="attr">key</span>=<span class="string">&#123;product.id&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    &#123;product.title&#125;</span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">li</span>&gt;</span></span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> (</span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">ul</span>&gt;</span>&#123;listItems&#125;<span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span></span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>注意， <code>&lt;li&gt;</code> 有一个 <code>key</code> 属性。对于列表中的每一个元素，你都应该传递一个字符串或者数字给 <code>key</code>，用于在其兄弟节点中唯一标识该元素。通常 key 来自你的数据，比如数据库中的 ID。如果你在后续插入、删除或重新排序这些项目，React 将依靠你提供的 key 来思考发生了什么。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> products = [</span><br><span class="line">  &#123; <span class="attr">title</span>: <span class="string">&#x27;Cabbage&#x27;</span>, <span class="attr">isFruit</span>: <span class="literal">false</span>, <span class="attr">id</span>: <span class="number">1</span> &#125;,</span><br><span class="line">  &#123; <span class="attr">title</span>: <span class="string">&#x27;Garlic&#x27;</span>, <span class="attr">isFruit</span>: <span class="literal">false</span>, <span class="attr">id</span>: <span class="number">2</span> &#125;,</span><br><span class="line">  &#123; <span class="attr">title</span>: <span class="string">&#x27;Apple&#x27;</span>, <span class="attr">isFruit</span>: <span class="literal">true</span>, <span class="attr">id</span>: <span class="number">3</span> &#125;,</span><br><span class="line">];</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">ShoppingList</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> listItems = products.<span class="title function_">map</span>(<span class="function"><span class="params">product</span> =&gt;</span></span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">li</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">      <span class="attr">key</span>=<span class="string">&#123;product.id&#125;</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">      <span class="attr">style</span>=<span class="string">&#123;&#123;</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">        <span class="attr">color:</span> <span class="attr">product.isFruit</span> ? &#x27;<span class="attr">magenta</span>&#x27; <span class="attr">:</span> &#x27;<span class="attr">darkgreen</span>&#x27;</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">      &#125;&#125;</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">    &gt;</span></span></span><br><span class="line"><span class="language-xml">      &#123;product.title&#125;</span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">li</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">ul</span>&gt;</span>&#123;listItems&#125;<span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="响应事件"><a href="#响应事件" class="headerlink" title="响应事件"></a>响应事件</h2><p>你可以通过在组件中声明 <strong>事件处理</strong> 函数来响应事件：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">MyButton</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">function</span> <span class="title function_">handleClick</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="title function_">alert</span>(<span class="string">&#x27;You clicked me!&#x27;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">button</span> <span class="attr">onClick</span>=<span class="string">&#123;handleClick&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      Click me</span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意，<code>onClick=&#123;handleClick&#125;</code> 的结尾没有小括号！不要 <strong>调用</strong> 事件处理函数：你只需 <strong>把函数传递给事件</strong> 即可。当用户点击按钮时 React 会调用你传递的事件处理函数。</p><h2 id="更新界面"><a href="#更新界面" class="headerlink" title="更新界面"></a>更新界面</h2><p>通常你会希望你的组件 “记住” 一些信息并展示出来，比如一个按钮被点击的次数。要做到这一点，你需要在你的组件中添加 <strong>state</strong>。</p><p>首先，从 React 引入 <a href="https://zh-hans.react.dev/reference/react/useState"><code>useState</code></a>：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; useState &#125; <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br></pre></td></tr></table></figure><p>现在你可以在你的组件中声明一个 <strong>state 变量</strong>：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">MyButton</span>(<span class="params"></span>) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> [count, setCount] = <span class="title function_">useState</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// ...</span></span><br></pre></td></tr></table></figure><p>你将从 <code>useState</code> 中获得两样东西：当前的 state（<code>count</code>），以及用于更新它的函数（<code>setCount</code>）。你可以给它们起任何名字，但按照惯例会像 <code>[something, setSomething]</code> 这样为它们命名。</p><p>第一次显示按钮时，<code>count</code> 的值为 <code>0</code>，因为你把 <code>0</code> 传给了 <code>useState()</code>。当你想改变 state 时，调用 <code>setCount()</code> 并将新的值传递给它。点击该按钮计数器将递增：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">MyButton</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> [count, setCount] = <span class="title function_">useState</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">function</span> <span class="title function_">handleClick</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="title function_">setCount</span>(count + <span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">button</span> <span class="attr">onClick</span>=<span class="string">&#123;handleClick&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      Clicked &#123;count&#125; times</span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>React 将再次调用你的组件函数。第一次 <code>count</code> 变成 <code>1</code>。接着点击会变成 <code>2</code>。继续点击会逐步递增。</p><p>如果你多次渲染同一个组件，每个组件都会拥有自己的 state。你可以尝试点击不同的按钮：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; useState &#125; <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">MyApp</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">h1</span>&gt;</span>Counters that update separately<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">MyButton</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">MyButton</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">MyButton</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> [count, setCount] = <span class="title function_">useState</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">function</span> <span class="title function_">handleClick</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="title function_">setCount</span>(count + <span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">button</span> <span class="attr">onClick</span>=<span class="string">&#123;handleClick&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      Clicked &#123;count&#125; times</span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>每个按钮会 “记住” 自己的 <code>count</code>，而不影响其他按钮</p><h2 id="组件间共享数据"><a href="#组件间共享数据" class="headerlink" title="组件间共享数据"></a>组件间共享数据</h2><p>在前面的示例中，每个 <code>MyButton</code> 都有自己独立的 <code>count</code>，当每个按钮被点击时，只有被点击按钮的 <code>count</code> 才会发生改变：</p><p>然而，你经常需要组件 <strong>共享数据并一起更新</strong>。</p><p>为了使得 <code>MyButton</code> 组件显示相同的 <code>count</code> 并一起更新，你需要将各个按钮的 state “向上” 移动到最接近包含所有按钮的组件之中。</p><p>在这个示例中，它是 <code>MyApp</code>：</p><p><img src="/../img/java/19.png" alt="19"></p><p>此刻，当你点击任何一个按钮时，<code>MyApp</code> 中的 <code>count</code> 都将改变，同时会改变 <code>MyButton</code> 中的两个 count。具体代码如下：</p><p>首先，将 <code>MyButton</code> 的 <strong>state 上移到</strong> <code>MyApp</code> 中：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">MyApp</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> [count, setCount] = <span class="title function_">useState</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">function</span> <span class="title function_">handleClick</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="title function_">setCount</span>(count + <span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">h1</span>&gt;</span>Counters that update separately<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">MyButton</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">MyButton</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">MyButton</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="comment">// ... we&#x27;re moving code from here ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接着，将 <code>MyApp</code> 中的点击事件处理函数以及 <strong>state 一同向下传递到</strong> 每个 <code>MyButton</code> 中。你可以使用 JSX 的大括号向 <code>MyButton</code> 传递信息。就像之前向 <code>&lt;img&gt;</code> 等内置标签所做的那样:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">MyApp</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> [count, setCount] = <span class="title function_">useState</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">function</span> <span class="title function_">handleClick</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="title function_">setCount</span>(count + <span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">h1</span>&gt;</span>Counters that update together<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">MyButton</span> <span class="attr">count</span>=<span class="string">&#123;count&#125;</span> <span class="attr">onClick</span>=<span class="string">&#123;handleClick&#125;</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">MyButton</span> <span class="attr">count</span>=<span class="string">&#123;count&#125;</span> <span class="attr">onClick</span>=<span class="string">&#123;handleClick&#125;</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用这种方式传递的信息被称作 <strong>prop</strong>。此时 <code>MyApp</code> 组件包含了 <code>count</code> state 以及 <code>handleClick</code> 事件处理函数，并将它们作为 <strong>prop 传递给</strong> 了每个按钮。</p><p>最后，改变 <code>MyButton</code> 以 <strong>读取</strong> 从父组件传递来的 prop：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">MyButton</span>(<span class="params">&#123; count, onClick &#125;</span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">button</span> <span class="attr">onClick</span>=<span class="string">&#123;onClick&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      Clicked &#123;count&#125; times</span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当你点击按钮时，<code>onClick</code> 处理程序会启动。每个按钮的 <code>onClick</code> prop 会被设置为 <code>MyApp</code> 内的 <code>handleClick</code> 函数，所以函数内的代码会被执行。该代码会调用 <code>setCount(count + 1)</code>，使得 state 变量 <code>count</code> 递增。新的 <code>count</code> 值会被作为 prop 传递给每个按钮，因此它们每次展示的都是最新的值。这被称为“状态提升”。通过向上移动 state，我们实现了在组件间共享它。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; useState &#125; <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">MyApp</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> [count, setCount] = <span class="title function_">useState</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">function</span> <span class="title function_">handleClick</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="title function_">setCount</span>(count + <span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">h1</span>&gt;</span>Counters that update together<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">MyButton</span> <span class="attr">count</span>=<span class="string">&#123;count&#125;</span> <span class="attr">onClick</span>=<span class="string">&#123;handleClick&#125;</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">MyButton</span> <span class="attr">count</span>=<span class="string">&#123;count&#125;</span> <span class="attr">onClick</span>=<span class="string">&#123;handleClick&#125;</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">MyButton</span>(<span class="params">&#123; count, onClick &#125;</span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">button</span> <span class="attr">onClick</span>=<span class="string">&#123;onClick&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      Clicked &#123;count&#125; times</span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Javascript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql常用方法整理</title>
      <link href="/2024/09/12/mysql%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%E6%95%B4%E7%90%86/"/>
      <url>/2024/09/12/mysql%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="Mysql常用方法简单整理"><a href="#Mysql常用方法简单整理" class="headerlink" title="Mysql常用方法简单整理"></a>Mysql常用方法简单整理</h1><h2 id="连接数据库"><a href="#连接数据库" class="headerlink" title="连接数据库"></a>连接数据库</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -uroot -p123123 -h127.0.0.1</span><br></pre></td></tr></table></figure><h2 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE DATABASE MyDb;</span><br></pre></td></tr></table></figure><h2 id="选择数据库"><a href="#选择数据库" class="headerlink" title="选择数据库"></a>选择数据库</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">USE MyDb;</span><br></pre></td></tr></table></figure><h2 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE t_class</span><br><span class="line">(</span><br><span class="line">  id INT PRIMARY KEY,  </span><br><span class="line">  name VARCHAR(32)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h2 id="外键约束"><a href="#外键约束" class="headerlink" title="外键约束"></a>外键约束</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CONSTRAINT 外键名 FOREIGN KEY 字段名 REFERENCES 主表名(主键名)</span><br></pre></td></tr></table></figure><h2 id="常用约束"><a href="#常用约束" class="headerlink" title="常用约束"></a>常用约束</h2><h3 id="唯一约束"><a href="#唯一约束" class="headerlink" title="唯一约束"></a>唯一约束</h3><p>唯一约束（Unique Constraint）要求该列唯一，允许为空，但是只能有一个空值。唯一约束可以确保一列或者几列不出现重复值。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">关键词 UNIQUE</span><br></pre></td></tr></table></figure><h3 id="非空约束"><a href="#非空约束" class="headerlink" title="非空约束"></a>非空约束</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">关键词 NOT NULL </span><br></pre></td></tr></table></figure><h3 id="默认约束"><a href="#默认约束" class="headerlink" title="默认约束"></a>默认约束</h3><p>默认约束：即给字段一个默认值。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">关键词 DEFAULT</span><br></pre></td></tr></table></figure><h3 id="设置表的属性值自动增加"><a href="#设置表的属性值自动增加" class="headerlink" title="设置表的属性值自动增加"></a>设置表的属性值自动增加</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">关键词 AUTO_INCREMENT</span><br></pre></td></tr></table></figure><h3 id="常用约束总结"><a href="#常用约束总结" class="headerlink" title="常用约束总结"></a>常用约束总结</h3><p>以下是在 MySQL 中常用的约束。</p><p>NOT NULL 约束：确保某列不能有 NULL 值。</p><p>DEFAULT 约束：当某列没有指定值时，为该列提供默认值。</p><p>UNIQUE 约束：确保某列中的所有值是不同的。</p><p>PRIMARY Key 约束：唯一标识数据库表中的各行&#x2F;记录。</p><p>CHECK 约束：CHECK 约束确保某列中的所有值满足一定条件。</p><h2 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DROP TABLE 表名;</span><br></pre></td></tr></table></figure><h2 id="查看数据表基本结构"><a href="#查看数据表基本结构" class="headerlink" title="查看数据表基本结构"></a>查看数据表基本结构</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DESCRIBE 表名；</span><br></pre></td></tr></table></figure><h2 id="查看数据表详细结构"><a href="#查看数据表详细结构" class="headerlink" title="查看数据表详细结构"></a>查看数据表详细结构</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHOW CREATE TABLE 表名\G;</span><br></pre></td></tr></table></figure><p>使用 SHOW CREATE TABLE 语句，不仅仅可以返回给我们建表时所写的详细语句，而且还可以查看存储引擎和字符编码。</p><p>改变表名</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE 旧表名 RENAME 新表名;</span><br></pre></td></tr></table></figure><h2 id="修改字段名"><a href="#修改字段名" class="headerlink" title="修改字段名"></a>修改字段名</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE 表名 CHANGE 旧字段名 新字段名 新数据类型;</span><br></pre></td></tr></table></figure><p>tip： 如果不需要修改字段的数据类型，可以把新字段的数据类型设置为和原来一样，但是！千万不要空着它！</p><h2 id="修改字段数据类型"><a href="#修改字段数据类型" class="headerlink" title="修改字段数据类型"></a>修改字段数据类型</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE 表名 MODIFY 字段名 数据类型;</span><br></pre></td></tr></table></figure><h2 id="添加与删除字段"><a href="#添加与删除字段" class="headerlink" title="添加与删除字段"></a>添加与删除字段</h2><h3 id="添加字段"><a href="#添加字段" class="headerlink" title="添加字段"></a>添加字段</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE 表名 ADD 新字段名 数据类型 [约束条件] [FIRST|AFTER] 已存在字段名;</span><br></pre></td></tr></table></figure><h4 id="在表的最后一列添加字段"><a href="#在表的最后一列添加字段" class="headerlink" title="在表的最后一列添加字段"></a>在表的最后一列添加字段</h4><p>只要不做[FIRST|AFTER]的位置说明，在添加字段时MySQL会默认把新字段加入到表的最后一列。</p><h4 id="在表的第一列添加字段"><a href="#在表的第一列添加字段" class="headerlink" title="在表的第一列添加字段"></a>在表的第一列添加字段</h4><p>如果我们想在第一列添加新的字段，只需做FIRST的位置说明。</p><p>举个例子：<br>现在我们要把字段prod_country添加到表Mall_products的第一列。</p><p>输入命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE Mall_products ADD prod_country varchar(30) FIRST;</span><br></pre></td></tr></table></figure><h4 id="在表的指定列后添加字段"><a href="#在表的指定列后添加字段" class="headerlink" title="在表的指定列后添加字段"></a>在表的指定列后添加字段</h4><p>如果我们想在某一列后面添加新的字段，只需做AFTER的位置说明，然后注明你想让它添加在哪个字段的后面即可。</p><p>举个例子：<br>现在我们要把字段prod_country添加到表Mall_products的 prod_name字段的后面。</p><p>输入命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE Mall_products ADD prod_country varchar(30) AFTER prod_name;</span><br></pre></td></tr></table></figure><h3 id="删除字段"><a href="#删除字段" class="headerlink" title="删除字段"></a>删除字段</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE 表名 DROP 字段名;</span><br></pre></td></tr></table></figure><h2 id="修改字段的排列位置"><a href="#修改字段的排列位置" class="headerlink" title="修改字段的排列位置"></a>修改字段的排列位置</h2><h3 id="修改字段的排列位置-1"><a href="#修改字段的排列位置-1" class="headerlink" title="修改字段的排列位置"></a>修改字段的排列位置</h3><p>我们可以通过ALTER TABLE来改变表中字段的相对位置。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE 表名 MODIFY 字段1 数据类型 FIRST|AFTER 字段2; </span><br></pre></td></tr></table></figure><p>其中，字段1指要修改位置的字段，FIRST与AFTER 字段2为可选参数。</p><h4 id="修改字段为表的第一个字段"><a href="#修改字段为表的第一个字段" class="headerlink" title="修改字段为表的第一个字段"></a>修改字段为表的第一个字段</h4><p>如果我们想把字段的位置调整到第一列，只需做FIRST的位置说明。</p><p>举个例子<br>现在我们要把字段prod_price调整到表Mall_products的第一列。Mall_products表结构</p><p>输入命令：</p><p>ALTER TABLE Mall_products MODIFY prod_price FLOAT FIRST;</p><h4 id="修改字段到表的指定列之后"><a href="#修改字段到表的指定列之后" class="headerlink" title="修改字段到表的指定列之后"></a>修改字段到表的指定列之后</h4><p>还有一种位置调整的方法可以让你把想调整的字段放在除了第一列的任何位置。调整的时候需要做AFTER 字段2的位置说明。</p><h2 id="删除表的外键约束"><a href="#删除表的外键约束" class="headerlink" title="删除表的外键约束"></a>删除表的外键约束</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE 表名 DROP FOREIGN KEY 外键约束名; </span><br></pre></td></tr></table></figure><h2 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h2><h3 id="为表的所有字段插入数据"><a href="#为表的所有字段插入数据" class="headerlink" title="为表的所有字段插入数据"></a>为表的所有字段插入数据</h3><p>向表中插入数据最简单的方法就是使用INSERT语句。INSERT语句需要你声明要插入内容的表(table)名和内容(values)。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO 表名 (字段名) VALUES (内容);</span><br></pre></td></tr></table></figure><h3 id="为表的指定字段插入数据"><a href="#为表的指定字段插入数据" class="headerlink" title="为表的指定字段插入数据"></a>为表的指定字段插入数据</h3><p>为表的指定字段插入数据，就是在INSERT中只向部分插入值，而其他字段的值为表定义时的默认值。</p><p>example:</p><p>假设我们现在有一张空表 MyUser 如下</p><p><img src="/../img/mysql/1.png" alt="1"></p><p>我们忽略字段 age，为表 MyUser 插入内容:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into MyUser(name) values(&#x27;lisi&#x27;),(&#x27;fawaikuangtu&#x27;),(&#x27;zhangsan&#x27;);</span><br></pre></td></tr></table></figure><h2 id="更新数据"><a href="#更新数据" class="headerlink" title="更新数据"></a>更新数据</h2><h3 id="更新表中指定的内容"><a href="#更新表中指定的内容" class="headerlink" title="更新表中指定的内容"></a>更新表中指定的内容</h3><p>需要更新的表（table）名；</p><p>需要更新的字段（column）名和它的新内容（value）；</p><p>决定更新哪一条内容（value）的过滤条件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UPDATE 表名 SET 字段名1 = 内容1, 字段名2 = 内容2, 字段名3 = 内容3 WHERE 过滤条件; 。</span><br></pre></td></tr></table></figure><p>example:</p><p>有一张表Mall_products2，内容如下图</p><p><img src="/../img/mysql/2.png" alt="2"></p><p>把Span换成Pakistan，地区代码也换为92 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">UPDATE Mall_products2</span><br><span class="line">SET country_name = &quot;Pakistan&quot;, country_id = 92</span><br><span class="line">WHERE id = 2;</span><br></pre></td></tr></table></figure><h2 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h2><h3 id="删除表中的指定行"><a href="#删除表中的指定行" class="headerlink" title="删除表中的指定行"></a>删除表中的指定行</h3><p>从数据表中删除数据内容需要使用DELETE语句，它需要WHERE语句来配合它来指定我们究竟应该删除哪些数据内容。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE FROM 表名 WHERE 条件语句;</span><br></pre></td></tr></table></figure><p>example:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DELETE FROM Mall_products2 </span><br><span class="line">WHERE id=2 OR id=3;</span><br></pre></td></tr></table></figure><h3 id="删除表中的所有行"><a href="#删除表中的所有行" class="headerlink" title="删除表中的所有行"></a>删除表中的所有行</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE FROM Mall_products2;</span><br></pre></td></tr></table></figure><h2 id="基本查询语句"><a href="#基本查询语句" class="headerlink" title="基本查询语句"></a>基本查询语句</h2><h3 id="查询数据表中指定字段的内容"><a href="#查询数据表中指定字段的内容" class="headerlink" title="查询数据表中指定字段的内容"></a>查询数据表中指定字段的内容</h3><p>MySQL从数据表中查询数据的基本语句为SELECT语句。</p><p>SELECT语句的可选参数比较多，让我们先从最简单的开始，带大家一步一步的深入SELECT语句的使用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT 字段名 FROM 表名;</span><br></pre></td></tr></table></figure><p>若需要查询多个字段下的内容。这时，我们只需要在字段之间加入逗号,即可。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT 字段名1, 字段名2 FROM 表名;</span><br></pre></td></tr></table></figure><h3 id="查询数据表中的所有内容"><a href="#查询数据表中的所有内容" class="headerlink" title="查询数据表中的所有内容"></a>查询数据表中的所有内容</h3><p>如果我们不记得字段名字了，我们还可以查看整张表的内容。这时候，只需要我们用星号*来代替字段的名字，就会得到一整张表的内容。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM 表名;</span><br></pre></td></tr></table></figure><h2 id="带IN关键字的查询"><a href="#带IN关键字的查询" class="headerlink" title="带IN关键字的查询"></a>带IN关键字的查询</h2><p>IN关键字被用在WHERE语句的后边，用来过滤你所需要查询的内容。更形象的说，IN关键字的使用情形就像点名，点到谁谁就要站出来。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT 字段名 FROM 表名 WHERE 字段名 IN (n1,n2,n3,...); </span><br></pre></td></tr></table></figure><p>其中，括号内的数字必须为INT格式的数字。被“点到名”的这些括号里数字对应的内容，都要乖乖的站到前边来展示给大家看。</p><h2 id="带-BETWEEN-AND-的范围查询"><a href="#带-BETWEEN-AND-的范围查询" class="headerlink" title="带 BETWEEN AND 的范围查询"></a>带 BETWEEN AND 的范围查询</h2><p>BETWEEN AND需要两个参数支持，一个是范围的开始值，另一个就是结束值了。如果字段值满足指定的范围查询条件，就返回这些满足条件的数据内容。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT 字段名 FROM 表名 WHERE 字段名 BETWEEN n1 AND n2;</span><br></pre></td></tr></table></figure><h2 id="带-LIKE-的字符匹配查询"><a href="#带-LIKE-的字符匹配查询" class="headerlink" title="带 LIKE 的字符匹配查询"></a>带 LIKE 的字符匹配查询</h2><p>SQL语句支持很多种通配符，其中可以和LIKE一起搭配使用的就是通配符%和_</p><h3 id="使用通配符-模糊匹配数据内容"><a href="#使用通配符-模糊匹配数据内容" class="headerlink" title="使用通配符%模糊匹配数据内容"></a>使用通配符%模糊匹配数据内容</h3><p>百分号通配符%可以匹配任意长度的字符，甚至包括零字符。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT 字段名 FROM 表名 WHERE 字段名 LIKE &#x27;字符%&#x27;;</span><br></pre></td></tr></table></figure><p>其中 % 的位置可以根据需要在字符间变化。</p><p>example:</p><p>假设我们现在有一张表Mall_products，内容如下：</p><p><img src="/../img/mysql/3.jpg" alt="3"></p><p>使用LIKE关键字和通配符%检索出所有商品名称带ir的商品信息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT *</span><br><span class="line">FROM Mall_products</span><br><span class="line">WHERE prod_name LIKE &#x27;%ir%&#x27;;</span><br></pre></td></tr></table></figure><h3 id="使用通配符-模糊匹配数据内容-1"><a href="#使用通配符-模糊匹配数据内容-1" class="headerlink" title="使用通配符_模糊匹配数据内容"></a>使用通配符_模糊匹配数据内容</h3><p>下划线通配符_与百分号通配符%类似，也用于模糊匹配。但是区别在于下划线通配符_只能模糊匹配1个字符。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT 字段名 FROM 表名 WHERE 字段名 LIKE &#x27;字符_&#x27;;</span><br></pre></td></tr></table></figure><h2 id="查询空值与去除重复结果"><a href="#查询空值与去除重复结果" class="headerlink" title="查询空值与去除重复结果"></a>查询空值与去除重复结果</h2><h3 id="查询空值"><a href="#查询空值" class="headerlink" title="查询空值"></a>查询空值</h3><p>在数据表创建之初，创建者可以指定某个字段是否为空值NULL。注意了，这个NULL既不代表0，也不代表空字符，而是代表一种未知的状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT 字段名 FROM 表名 WHERE 字段名 IS NULL; </span><br></pre></td></tr></table></figure><h3 id="去除重复结果"><a href="#去除重复结果" class="headerlink" title="去除重复结果"></a>去除重复结果</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT DISTINCT 字段名 FROM 表名;</span><br></pre></td></tr></table></figure><h2 id="带-AND-与-OR-的多条件查询"><a href="#带-AND-与-OR-的多条件查询" class="headerlink" title="带 AND 与 OR 的多条件查询"></a>带 AND 与 OR 的多条件查询</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT 字段名 FROM 表名 WHERE 表达式1 AND/OR 表达式2;</span><br></pre></td></tr></table></figure><h2 id="对查询结果进行排序"><a href="#对查询结果进行排序" class="headerlink" title="对查询结果进行排序"></a>对查询结果进行排序</h2><p>如果我们需要对读取的语句进行排序，我们就可以使用Order By子句来设定你想要按照的字段进行排序并返回结果。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT 字段名 FROM 表名 ORDER BY 字段名 [ASC[DESC]];</span><br></pre></td></tr></table></figure><p>ASC 升序关键字  ;   DESC 降序关键字</p><p>在默认情况下，它是按升序排列的。 </p><p>注:若要添加WHERE等语句，需要加在ORDER BY之前。</p><h2 id="分组查询"><a href="#分组查询" class="headerlink" title="分组查询"></a>分组查询</h2><h3 id="分组查询的单独使用-做了解，实际少用"><a href="#分组查询的单独使用-做了解，实际少用" class="headerlink" title="分组查询的单独使用(做了解，实际少用)"></a>分组查询的单独使用(做了解，实际少用)</h3><p>分组查询的关键字是Group By，查询的是每个分组中 首次出现的一条记录。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT 字段名 FROM 表名 GROUP BY 字段名;</span><br></pre></td></tr></table></figure><h2 id="使用-LIMIT-限制查询结果的数量"><a href="#使用-LIMIT-限制查询结果的数量" class="headerlink" title="使用 LIMIT 限制查询结果的数量"></a>使用 LIMIT 限制查询结果的数量</h2><h3 id="LIMIT的使用"><a href="#LIMIT的使用" class="headerlink" title="LIMIT的使用"></a>LIMIT的使用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT 字段名 FROM 表名 LIMIT [OFFSET,] 记录数;</span><br></pre></td></tr></table></figure><ol><li>第一个参数，OFFSET，可选参数，表示偏移量，如果不指定默认值为0，表示从查询结果的第一条记录开始，若偏移量为1，则从查询结果中的第二条记录开始，以此类推。</li><li>第二个参数，记录数，表示返回查询结果的条数。</li></ol><h2 id="内连接查询"><a href="#内连接查询" class="headerlink" title="内连接查询"></a>内连接查询</h2><p>仅将两个表中满足连接条件的行组合起来作为结果集，称为<strong>内连接</strong>；</p><p>关键字：[inner] join …  on。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">表1 [inner] join 表2 on 表1.字段=表2.字段</span><br></pre></td></tr></table></figure><p>从表1中取出每一条记录，去表2中与所有的记录进行匹配，匹配必须是某个条件在表1中与表2中相同，最终才会保留结果，否则不保留。inner 关键字可省略不写；on 表示连接条件：条件字段就是代表相同的业务含义（如下面两张表中的 employee.dept_id 和 department.id），大多数情况下为两张表中的主外键关系。</p><p>现在我们有两张表，数据如下</p><p>employee表数据</p><table><thead><tr><th align="center">id</th><th align="center">name</th><th align="center">dept_id</th></tr></thead><tbody><tr><td align="center">1</td><td align="center">Nancy</td><td align="center">4</td></tr><tr><td align="center">2</td><td align="center">Tod</td><td align="center">2</td></tr><tr><td align="center">3</td><td align="center">Carly</td><td align="center">1</td></tr><tr><td align="center">4</td><td align="center">Allen</td><td align="center">2</td></tr><tr><td align="center">5</td><td align="center">Mary</td><td align="center">NULL</td></tr></tbody></table><p>department表数据：</p><table><thead><tr><th align="center">id</th><th>name</th></tr></thead><tbody><tr><td align="center">1</td><td>开发部</td></tr><tr><td align="center">2</td><td>测试部</td></tr><tr><td align="center">3</td><td>运维部</td></tr><tr><td align="center">4</td><td>销售部</td></tr></tbody></table><p>现在想要查询出员工姓名以及其对应的部门名称，我们就使用内连接来进行查询。</p><p>我们可以将关联查询思路分为三步：<br>1.确定所连接的表，<br>2.确定所要查询的字段，<br>3.确定连接条件与连接方式。</p><p><img src="/../img/mysql/4.png" alt="4"></p><p>其中，没有部门的员工和部门没有员工的部门都没有被查出来，这就是内连接的特点，只查询在连接表中有对应的记录，其中dept.id&#x3D;emp.dept_id是连接条件。</p><p>example:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select tb_student.name as studentName,tb_class.name as className </span><br><span class="line">from tb_class join tb_student </span><br><span class="line">on tb_class.id=tb_student.class_id;</span><br></pre></td></tr></table></figure><h2 id="外连接查询"><a href="#外连接查询" class="headerlink" title="外连接查询"></a>外连接查询</h2><ol><li><p>以某张表为主，取出里面的所有记录，然后每条与另外一张表进行连接，不管能不能匹配上条件，最终都会保留。能匹配，正确保留；不能匹配，其它表的字段都置空（null），称为外连接。</p></li><li><p>外连接查询分为左外连接查询和右外连接查询；</p></li><li><p>关键字：left&#x2F;right [outer] join … on。</p></li></ol><p>又如上面那两张表</p><p>若查询所有员工姓名以及他所在部门，在内连接中Mary没有被查出，因为他没有对应的部门，现在想把Mary也查出来，就要使用左外连接。</p><p><img src="/../img/mysql/5.png" alt="5"></p><p>此查询语句以employee为主表查询，因此最终记录至少不少于主表已有的记录数。</p><p>右外连接是同理的，只是基准表的位置变化了而已。</p><p>我们在这里只要将left修改成了right,但是基准表变化了，是以department表的数据去匹配employee表，所以左外连接能做到的查询，右外连接也能做到，仅展现的效果有所不同。</p><p><img src="/../img/mysql/6.png" alt="6"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Springboot简单回顾</title>
      <link href="/2024/09/06/Springboot%E7%AE%80%E5%8D%95%E5%9B%9E%E9%A1%BE/"/>
      <url>/2024/09/06/Springboot%E7%AE%80%E5%8D%95%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="Springboot简单回顾"><a href="#Springboot简单回顾" class="headerlink" title="Springboot简单回顾"></a>Springboot简单回顾</h1><p>自从入了深度学习的坑，已不学java良久，今日重拾知识</p><h2 id="Spring-Boot-的主要特点包括："><a href="#Spring-Boot-的主要特点包括：" class="headerlink" title="Spring Boot 的主要特点包括："></a>Spring Boot 的主要特点包括：</h2><ol><li><strong>简化配置</strong>: Spring Boot 遵循约定优于配置的原则，减少了传统 Spring 应用中的大量配置。它通过自动配置（auto-configuration）和起步依赖（starter dependencies）来简化项目的配置过程，让开发者可以快速搭建起一个可运行的 Spring 应用。</li><li><strong>集成性强</strong>: Spring Boot 提供了大量的开箱即用的特性和功能，如内嵌的 Servlet 容器（如Tomcat、Jetty或Undertow）、健康检查、指标监控等。它还整合了诸多常用的库和框架，如Spring Data、Spring Security等，使得开发者可以快速构建出功能完善的应用。</li><li><strong>微服务支持</strong>: Spring Boot 非常适合用于构建微服务架构。它提供了丰富的支持，如通过Spring Cloud进行微服务架构的开发，集成了服务发现、配置中心、负载均衡等功能，帮助开发者构建可伸缩、高可用的微服务系统。</li><li><strong>内嵌服务器</strong>: Spring Boot 可以将应用程序打包成一个可执行的 JAR 文件，并内置了常用的 Servlet 容器，如 Tomcat、Jetty 或 Undertow。这样一来，开发者可以通过简单的 <strong>java -jar</strong> 命令来运行应用程序，而无需部署到外部应用服务器。</li><li><strong>生态丰富</strong>: 由于 Spring Boot 的广泛应用和强大生态系统，开发者可以轻松地使用各种扩展和插件，如 Actuator、Spring Boot DevTools 等，提高开发效率和应用质量。</li></ol><h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><p><img src="/../img/java/18.png" alt="18"></p><h2 id="rest-api规范"><a href="#rest-api规范" class="headerlink" title="rest api规范"></a>rest api规范</h2><h3 id="路径"><a href="#路径" class="headerlink" title="路径"></a>路径</h3><p>路径又称”终点”（endpoint），表示API的具体网址。</p><p>在RESTful架构中，每个网址代表一种资源（resource），所以网址中不能有动词，只能有名词，而且所用的名词往往与数据库的表格名对应。</p><h3 id="Http-动词"><a href="#Http-动词" class="headerlink" title="Http 动词"></a>Http 动词</h3><ul><li>GET（SELECT）：从服务器取出资源（一项或多项）。</li><li>POST（CREATE）：在服务器新建一个资源。</li><li>PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。</li><li>PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。</li><li>DELETE（DELETE）：从服务器删除资源。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Springboot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flexbox弹性盒子</title>
      <link href="/2024/08/12/Flexbox%E5%BC%B9%E6%80%A7%E7%9B%92%E5%AD%90/"/>
      <url>/2024/08/12/Flexbox%E5%BC%B9%E6%80%A7%E7%9B%92%E5%AD%90/</url>
      
        <content type="html"><![CDATA[<p>Flexbox（弹性盒布局）是一种 CSS 布局模型，用于设计和布局复杂的网页布局，尤其是在响应式设计中非常有用。它使得容器中的子元素可以灵活地排列和对齐，即使在不同的屏幕尺寸和容器大小下也能保持一致的布局。</p><h3 id="Flexbox-的基本概念"><a href="#Flexbox-的基本概念" class="headerlink" title="Flexbox 的基本概念"></a>Flexbox 的基本概念</h3><ol><li><strong>Flex容器（Flex Container）</strong>：这是你要应用 Flexbox 布局的父元素。通过设置 <code>display: flex;</code> 或 <code>display: inline-flex;</code>，你将一个元素转变为 Flex 容器。</li><li><strong>Flex 项目（Flex Items）</strong>：这是 Flex 容器中的子元素，自动成为 Flex 项目。</li></ol><h3 id="Flexbox-的主要属性"><a href="#Flexbox-的主要属性" class="headerlink" title="Flexbox 的主要属性"></a>Flexbox 的主要属性</h3><h4 id="1-Flex-容器的属性"><a href="#1-Flex-容器的属性" class="headerlink" title="1. Flex 容器的属性"></a>1. <strong>Flex 容器的属性</strong></h4><ul><li><code>display</code><ul><li><code>flex</code>：将元素定义为 Flex 容器，启用 Flexbox 布局。</li><li><code>inline-flex</code>：将元素定义为内联 Flex 容器，和 <code>inline</code> 元素一样在行内显示。</li></ul></li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">css复制代码<span class="selector-class">.container</span> &#123;</span><br><span class="line">  <span class="attribute">display</span>: flex; <span class="comment">/* 或 inline-flex */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p><code>flex-direction</code></p><p>：定义主轴的方向（即项目排列的方向）。</p><ul><li><code>row</code>（默认）：从左到右排列。</li><li><code>column</code>：从上到下排列。</li><li><code>row-reverse</code>：从右到左排列。</li><li><code>column-reverse</code>：从下到上排列。</li></ul></li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">css复制代码<span class="selector-class">.container</span> &#123;</span><br><span class="line">  <span class="attribute">flex-direction</span>: row; <span class="comment">/* 或 column, row-reverse, column-reverse */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p><code>flex-wrap</code></p><p>：定义 Flex 项目是否换行。</p><ul><li><code>nowrap</code>（默认）：不换行。</li><li><code>wrap</code>：换行。</li><li><code>wrap-reverse</code>：反向换行。</li></ul></li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">css复制代码<span class="selector-class">.container</span> &#123;</span><br><span class="line">  <span class="attribute">flex-wrap</span>: wrap; <span class="comment">/* 或 nowrap, wrap-reverse */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>**<code>flex-flow</code>**：简写属性，用于设置 <code>flex-direction</code> 和 <code>flex-wrap</code>。</li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">css复制代码<span class="selector-class">.container</span> &#123;</span><br><span class="line">  <span class="attribute">flex-flow</span>: row wrap; <span class="comment">/* row / column 和 nowrap / wrap */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p><code>justify-content</code></p><p>：定义主轴上项目的对齐方式。</p><ul><li><code>flex-start</code>（默认）：对齐到主轴的开始位置。</li><li><code>center</code>：对齐到主轴的中心。</li><li><code>flex-end</code>：对齐到主轴的结束位置。</li><li><code>space-between</code>：项目之间留有均匀的间隔。</li><li><code>space-around</code>：项目周围有均匀的间隔。</li><li><code>space-evenly</code>：项目之间和项目与容器边缘的间隔均匀。</li></ul></li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">css复制代码<span class="selector-class">.container</span> &#123;</span><br><span class="line">  <span class="attribute">justify-content</span>: center; <span class="comment">/* 或 flex-start, flex-end, space-between, space-around, space-evenly */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p><code>align-items</code></p><p>：定义交叉轴（主轴的垂直方向）上项目的对齐方式。</p><ul><li><code>stretch</code>（默认）：项目被拉伸以填充容器。</li><li><code>flex-start</code>：对齐到交叉轴的开始位置。</li><li><code>center</code>：对齐到交叉轴的中心。</li><li><code>flex-end</code>：对齐到交叉轴的结束位置。</li><li><code>baseline</code>：项目的文本基线对齐。</li></ul></li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">css复制代码<span class="selector-class">.container</span> &#123;</span><br><span class="line">  <span class="attribute">align-items</span>: center; <span class="comment">/* 或 stretch, flex-start, flex-end, baseline */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p><code>align-content</code></p><p>：定义多行（如果有的话）之间的对齐方式。</p><ul><li><code>stretch</code>（默认）：行之间拉伸以填充容器。</li><li><code>flex-start</code>：对齐到交叉轴的开始位置。</li><li><code>center</code>：对齐到交叉轴的中心。</li><li><code>flex-end</code>：对齐到交叉轴的结束位置。</li><li><code>space-between</code>：行之间留有均匀的间隔。</li><li><code>space-around</code>：行周围有均匀的间隔。</li><li><code>space-evenly</code>：行之间和行与容器边缘的间隔均匀。</li></ul></li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">css复制代码<span class="selector-class">.container</span> &#123;</span><br><span class="line">  <span class="attribute">align-content</span>: center; <span class="comment">/* 或 stretch, flex-start, flex-end, space-between, space-around, space-evenly */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p><code>align-items</code></p><p> 和 </p><p><code>align-content</code></p><p> 的区别：</p><ul><li><code>align-items</code> 是用来对齐单行项目。</li><li><code>align-content</code> 是用来对齐多行项目。</li></ul></li></ul><h4 id="2-Flex-项目的属性"><a href="#2-Flex-项目的属性" class="headerlink" title="2. Flex 项目的属性"></a>2. <strong>Flex 项目的属性</strong></h4><ul><li><p><code>flex-grow</code></p><p>：定义项目的放大比例。默认为 0，即项目不放大。</p><ul><li>值为 <code>1</code> 表示项目会填充剩余空间。</li></ul></li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">css复制代码<span class="selector-class">.item</span> &#123;</span><br><span class="line">  <span class="attribute">flex-grow</span>: <span class="number">1</span>; <span class="comment">/* 项目会填充剩余空间 */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p><code>flex-shrink</code></p><p>：定义项目的缩小比例。默认为 1，即项目会缩小以适应容器。</p><ul><li>值为 <code>0</code> 表示项目不会缩小。</li></ul></li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">css复制代码<span class="selector-class">.item</span> &#123;</span><br><span class="line">  <span class="attribute">flex-shrink</span>: <span class="number">1</span>; <span class="comment">/* 项目会缩小 */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p><code>flex-basis</code></p><p>：定义在分配多余空间之前，项目占据的初始空间。默认值为 </p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">auto</span><br></pre></td></tr></table></figure><p>。</p><ul><li>可以设置具体的像素值或百分比。</li></ul></li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">css复制代码<span class="selector-class">.item</span> &#123;</span><br><span class="line">  <span class="attribute">flex-basis</span>: <span class="number">200px</span>; <span class="comment">/* 项目初始占据 200px 的空间 */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p><code>flex</code></p><p>：简写属性，用于设置 </p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">flex-grow</span></span><br></pre></td></tr></table></figure><p>、</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">flex-shrink</span></span><br></pre></td></tr></table></figure><p> 和 </p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">flex-basis</span></span><br></pre></td></tr></table></figure><p>。</p><ul><li>例如：<code>flex: 1 0 200px;</code> 相当于设置 <code>flex-grow</code> 为 <code>1</code>，<code>flex-shrink</code> 为 <code>0</code>，<code>flex-basis</code> 为 <code>200px</code>。</li></ul></li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">css复制代码<span class="selector-class">.item</span> &#123;</span><br><span class="line">  <span class="attribute">flex</span>: <span class="number">1</span> <span class="number">0</span> <span class="number">200px</span>; <span class="comment">/* 等价于 flex-grow: 1; flex-shrink: 0; flex-basis: 200px; */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p><code>align-self</code></p><p>：允许单个项目在交叉轴上的对齐方式不同于其他项目。</p><ul><li>取值和 <code>align-items</code> 类似：<code>auto</code>, <code>flex-start</code>, <code>center</code>, <code>flex-end</code>, <code>baseline</code>, <code>stretch</code>。</li></ul></li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">css复制代码<span class="selector-class">.item</span> &#123;</span><br><span class="line">  <span class="attribute">align-self</span>: center; <span class="comment">/* 该项目在交叉轴上居中对齐 */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Flexbox-实例"><a href="#Flexbox-实例" class="headerlink" title="Flexbox 实例"></a>Flexbox 实例</h3><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">html</span>复制代码&lt;<span class="selector-tag">div</span> class=&quot;container&quot;&gt;</span><br><span class="line">  &lt;<span class="selector-tag">div</span> class=&quot;item&quot;&gt;项 <span class="number">1</span>&lt;/<span class="selector-tag">div</span>&gt;</span><br><span class="line">  &lt;<span class="selector-tag">div</span> class=&quot;item&quot;&gt;项 <span class="number">2</span>&lt;/<span class="selector-tag">div</span>&gt;</span><br><span class="line">  &lt;<span class="selector-tag">div</span> class=&quot;item&quot;&gt;项 <span class="number">3</span>&lt;/<span class="selector-tag">div</span>&gt;</span><br><span class="line">&lt;/<span class="selector-tag">div</span>&gt;</span><br><span class="line">css复制代码<span class="selector-class">.container</span> &#123;</span><br><span class="line">  <span class="attribute">display</span>: flex;</span><br><span class="line">  <span class="attribute">flex-direction</span>: row; <span class="comment">/* 项目在一行中显示 */</span></span><br><span class="line">  <span class="attribute">justify-content</span>: space-between; <span class="comment">/* 项目之间有均匀的间隔 */</span></span><br><span class="line">  <span class="attribute">align-items</span>: center; <span class="comment">/* 项目在交叉轴上居中对齐 */</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.item</span> &#123;</span><br><span class="line">  <span class="attribute">flex</span>: <span class="number">1</span>; <span class="comment">/* 项目会填充剩余空间 */</span></span><br><span class="line">  <span class="attribute">margin</span>: <span class="number">5px</span>; <span class="comment">/* 项目之间的间隔 */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tmux常见命令整理</title>
      <link href="/2024/08/01/tmux%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"/>
      <url>/2024/08/01/tmux%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="tmux常见命令整理"><a href="#tmux常见命令整理" class="headerlink" title="tmux常见命令整理"></a>tmux常见命令整理</h1><p>tmux是一个强大的终端复用器，允许用户在一个终端窗口中运行多个终端会话，并且可以在这些会话之间自由切换。以下是tmux的一些常见命令及其功能：</p><h3 id="会话操作"><a href="#会话操作" class="headerlink" title="会话操作"></a>会话操作</h3><ol><li><p><strong>新建会话</strong></p><ul><li><code>tmux</code>：创建一个新的会话，如果不指定名称，则使用默认名称。</li><li><code>tmux new -s &lt;session_name&gt;</code>：创建一个新的会话，并指定会话名称。</li></ul></li><li><p><strong>退出会话</strong></p><ul><li><code>Ctrl + b</code> 后接 <code>d</code>：分离当前会话（退出会话界面，但会话仍在后台运行）。</li></ul></li><li><p><strong>查看所有会话</strong></p><ul><li><code>tmux ls</code> 或 <code>tmux list-sessions</code>：列出所有已存在的会话。</li></ul></li><li><p><strong>恢复会话</strong></p><ul><li><code>tmux attach -t &lt;session_name&gt;</code> 或 <code>tmux a -t &lt;session_name&gt;</code>：连接到一个已存在的会话。</li></ul></li><li><p><strong>重命名会话</strong></p><ul><li><code>tmux rename-session -t &lt;old_name&gt; &lt;new_name&gt;</code>：重命名一个已存在的会话。</li></ul></li><li><p><strong>关闭会话</strong></p><ul><li><code>tmux kill-session -t &lt;session_name&gt;</code>：终止一个已存在的会话。</li></ul></li></ol><h3 id="窗口操作"><a href="#窗口操作" class="headerlink" title="窗口操作"></a>窗口操作</h3><ol><li><p><strong>新建窗口</strong></p><ul><li><code>Ctrl + b</code> 后接 <code>c</code>：在当前会话中创建一个新窗口。</li></ul></li><li><p><strong>切换窗口</strong></p><ul><li><code>Ctrl + b</code> 后接 <code>&lt;窗口序号&gt;</code>：切换到指定序号的窗口。</li><li><code>Ctrl + b</code> 后接 <code>p</code>：切换到上一个窗口。</li><li><code>Ctrl + b</code> 后接 <code>n</code>：切换到下一个窗口。</li><li><code>Ctrl + b</code> 后接 <code>w</code>：进入窗口选择列表，通过方向键和回车键选择窗口。</li></ul></li><li><p><strong>重命名窗口</strong></p><ul><li><code>Ctrl + b</code> 后接 <code>,</code>：重命名当前窗口。</li></ul></li><li><p><strong>关闭窗口</strong></p><ul><li><code>Ctrl + b</code> 后接 <code>&amp;</code>：关闭当前窗口。</li></ul></li></ol><h3 id="窗格操作"><a href="#窗格操作" class="headerlink" title="窗格操作"></a>窗格操作</h3><ol><li><p><strong>划分窗格</strong></p><ul><li><code>Ctrl + b</code> 后接 <code>%</code>：将当前窗口划分为左右两个窗格。</li><li><code>Ctrl + b</code> 后接 <code>&quot;</code>：将当前窗口划分为上下两个窗格。</li></ul></li><li><p><strong>切换活动窗格</strong></p><ul><li><code>Ctrl + b</code> 后接 <code>&lt;方向键&gt;</code>：在窗格之间切换。</li></ul></li><li><p><strong>调整窗格大小</strong></p><ul><li><code>Ctrl + b</code> 后接 <code>&lt;方向键&gt;</code>（同时按住）：以1个单元格为单位调整当前窗格的边缘。</li><li><code>Alt + 方向键</code>：以5个单元格为单位调整当前窗格的边缘（取决于配置）。</li></ul></li><li><p><strong>关闭窗格</strong></p><ul><li><code>Ctrl + b</code> 后接 <code>x</code>：关闭当前窗格。</li></ul></li><li><p><strong>窗格布局切换</strong></p><ul><li><code>Ctrl + b</code> 后接 <code>空格键</code>：在预置的窗格布局中循环切换。</li></ul></li></ol><h3 id="其他操作"><a href="#其他操作" class="headerlink" title="其他操作"></a>其他操作</h3><ol><li><p><strong>文本复制模式</strong></p><ul><li><code>Ctrl + b</code> 后接 <code>[</code>：进入文本复制模式，此时可以使用方向键和翻页键来选择文本，按 <code>Enter</code> 键复制选中的文本，按 <code>q</code> 退出复制模式。</li></ul></li><li><p><strong>会话快捷键提示</strong></p><ul><li><code>Ctrl + b</code> 后接 <code>?</code>：列出所有快捷键，按 <code>q</code> 返回。</li></ul></li><li><p><strong>配置选项</strong></p><ul><li>tmux的配置通常保存在用户的家目录下的<code>.tmux.conf</code>文件中，可以通过编辑该文件来自定义tmux的行为和外观。</li></ul></li></ol><p>请注意，tmux的快捷键前缀默认是<code>Ctrl + b</code>，但用户可以在<code>.tmux.conf</code>文件中通过<code>set -g prefix &lt;new-prefix&gt;</code>命令来更改这个前缀。此外，tmux还提供了丰富的命令和配置选项，用户可以通过<code>man tmux</code>或<code>tmux --help</code>命令来查看更多信息。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux常见命令速查</title>
      <link href="/2024/07/30/Linux%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4%E9%80%9F%E6%9F%A5/"/>
      <url>/2024/07/30/Linux%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4%E9%80%9F%E6%9F%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux命令速查—程序羊"><a href="#Linux命令速查—程序羊" class="headerlink" title="Linux命令速查—程序羊"></a>Linux命令速查—程序羊</h1><p><img src="/../img/Linux/1.jpg" alt="1"></p><p><img src="/../img/Linux/2.jpg" alt="2"></p><p><img src="/../img/Linux/3.jpg" alt="3"></p><p><img src="/../img/Linux/4.jpg" alt="4"></p><p><img src="/../img/Linux/5.jpg" alt="5"></p><p><img src="/../img/Linux/6.jpg" alt="6"></p><p><img src="/../img/Linux/7.jpg" alt="7"></p><p><img src="/../img/Linux/8.jpg" alt="8"></p><p><img src="/../img/Linux/9.jpg" alt="9"></p><p><img src="/../img/Linux/10.jpg" alt="10"></p><p><img src="/../img/Linux/11.jpg" alt="11"></p><p><img src="/../img/Linux/12.jpg" alt="12"></p><p><img src="/../img/Linux/13.jpg" alt="13"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RNN学习笔记（慎入）</title>
      <link href="/2024/07/04/RNN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2024/07/04/RNN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="RNN学习笔记—就陆熠鹏自己看得懂"><a href="#RNN学习笔记—就陆熠鹏自己看得懂" class="headerlink" title="RNN学习笔记—就陆熠鹏自己看得懂"></a>RNN学习笔记—就陆熠鹏自己看得懂</h1><p><img src="/../img/note/1.jpg" alt="1"></p><p><img src="/../img/note/2.jpg" alt="2"></p><p><img src="/../img/note/3.jpg" alt="3"></p><p><img src="/../img/note/4.jpg" alt="4"></p>]]></content>
      
      
      
        <tags>
            
            <tag> machine-learning </tag>
            
            <tag> note </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch9RNN循环神经网络</title>
      <link href="/2024/07/04/Pytorch9-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2024/07/04/Pytorch9-RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="RNN循环神经网络"><a href="#RNN循环神经网络" class="headerlink" title="RNN循环神经网络"></a>RNN循环神经网络</h1><h2 id="循环神经网络的从零开始实现"><a href="#循环神经网络的从零开始实现" class="headerlink" title="循环神经网络的从零开始实现"></a>循环神经网络的从零开始实现</h2><p>先读取数据集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">batch_size, num_steps = <span class="number">32</span>, <span class="number">35</span></span><br><span class="line">train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)</span><br></pre></td></tr></table></figure><h3 id="独热编码"><a href="#独热编码" class="headerlink" title="独热编码"></a>独热编码</h3><p>回想一下，在<code>train_iter</code>中，每个词元都表示为一个数字索引， 将这些索引直接输入神经网络可能会使学习变得困难。 我们通常将每个词元表示为更具表现力的特征向量。 最简单的表示称为<em>独热编码</em>（one-hot encoding）</p><p>简言之，将每个索引映射为相互不同的单位向量： 假设词表中不同词元的数目为𝑁（即<code>len(vocab)</code>）， 词元索引的范围为0到𝑁−1。 如果词元的索引是整数𝑖， 那么我们将创建一个长度为𝑁的全0向量， 并将第𝑖处的元素设置为1。 此向量是原始词元的一个独热向量。 索引为0和2的独热向量如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">F.one_hot(torch.tensor([<span class="number">0</span>, <span class="number">2</span>]), <span class="built_in">len</span>(vocab))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">         <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">         <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</span><br></pre></td></tr></table></figure><p>我们每次采样的小批量数据形状是二维张量： （批量大小，时间步数）。 <code>one_hot</code>函数将这样一个小批量数据转换成三维张量， 张量的最后一个维度等于词表大小（<code>len(vocab)</code>）。 我们经常转换输入的维度，以便获得形状为 （时间步数，批量大小，词表大小）的输出。 这将使我们能够更方便地通过最外层的维度， 一步一步地更新小批量数据的隐状态。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = torch.arange(<span class="number">10</span>).reshape((<span class="number">2</span>, <span class="number">5</span>))</span><br><span class="line">F.one_hot(X.T, <span class="number">28</span>).shape</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([<span class="number">5</span>, <span class="number">2</span>, <span class="number">28</span>])</span><br></pre></td></tr></table></figure><h3 id="始化模型参数"><a href="#始化模型参数" class="headerlink" title="始化模型参数"></a>始化模型参数</h3><p>接下来，我们初始化循环神经网络模型的模型参数。 隐藏单元数<code>num_hiddens</code>是一个可调的超参数。 当训练语言模型时，输入和输出来自相同的词表。 因此，它们具有相同的维度，即词表的大小。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_params</span>(<span class="params">vocab_size, num_hiddens, device</span>):</span><br><span class="line">    num_inputs = num_outputs = vocab_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">normal</span>(<span class="params">shape</span>):</span><br><span class="line">        <span class="keyword">return</span> torch.randn(size=shape, device=device) * <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 隐藏层参数</span></span><br><span class="line">    W_xh = normal((num_inputs, num_hiddens))</span><br><span class="line">    W_hh = normal((num_hiddens, num_hiddens))</span><br><span class="line">    b_h = torch.zeros(num_hiddens, device=device)</span><br><span class="line">    <span class="comment"># 输出层参数</span></span><br><span class="line">    W_hq = normal((num_hiddens, num_outputs))</span><br><span class="line">    b_q = torch.zeros(num_outputs, device=device)</span><br><span class="line">    <span class="comment"># 附加梯度</span></span><br><span class="line">    params = [W_xh, W_hh, b_h, W_hq, b_q]</span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">        param.requires_grad_(<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> params</span><br></pre></td></tr></table></figure><h3 id="循环神经网络模型"><a href="#循环神经网络模型" class="headerlink" title="循环神经网络模型"></a>循环神经网络模型</h3><p>为了定义循环神经网络模型， 我们首先需要一个<code>init_rnn_state</code>函数在初始化时返回隐状态。 这个函数的返回是一个张量，张量全用0填充， 形状为（批量大小，隐藏单元数）。 在后面的章节中我们将会遇到隐状态包含多个变量的情况， 而使用元组可以更容易地处理些。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_rnn_state</span>(<span class="params">batch_size, num_hiddens, device</span>):</span><br><span class="line">    <span class="keyword">return</span> (torch.zeros((batch_size, num_hiddens), device=device), )</span><br></pre></td></tr></table></figure><p>下面的<code>rnn</code>函数定义了如何在一个时间步内计算隐状态和输出。 循环神经网络模型通过<code>inputs</code>最外层的维度实现循环， 以便逐时间步更新小批量数据的隐状态<code>H</code>。 此外，这里使用tanh函数作为激活函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">rnn</span>(<span class="params">inputs, state, params</span>):</span><br><span class="line">    <span class="comment"># inputs的形状：(时间步数量，批量大小，词表大小)</span></span><br><span class="line">    W_xh, W_hh, b_h, W_hq, b_q = params</span><br><span class="line">    H, = state</span><br><span class="line">    outputs = []</span><br><span class="line">    <span class="comment"># X的形状：(批量大小，词表大小)</span></span><br><span class="line">    <span class="keyword">for</span> X <span class="keyword">in</span> inputs:</span><br><span class="line">        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)</span><br><span class="line">        Y = torch.mm(H, W_hq) + b_q</span><br><span class="line">        outputs.append(Y)</span><br><span class="line">    <span class="keyword">return</span> torch.cat(outputs, dim=<span class="number">0</span>), (H,)</span><br></pre></td></tr></table></figure><p>定义了所有需要的函数之后，接下来我们创建一个类来包装这些函数， 并存储从零开始实现的循环神经网络模型的参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RNNModelScratch</span>: <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;从零开始实现的循环神经网络模型&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, num_hiddens, device,</span></span><br><span class="line"><span class="params">                 get_params, init_state, forward_fn</span>):</span><br><span class="line">        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens</span><br><span class="line">        self.params = get_params(vocab_size, num_hiddens, device)</span><br><span class="line">        self.init_state, self.forward_fn = init_state, forward_fn</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, X, state</span>):</span><br><span class="line">        X = F.one_hot(X.T, self.vocab_size).<span class="built_in">type</span>(torch.float32)</span><br><span class="line">        <span class="keyword">return</span> self.forward_fn(X, state, self.params)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">begin_state</span>(<span class="params">self, batch_size, device</span>):</span><br><span class="line">        <span class="keyword">return</span> self.init_state(batch_size, self.num_hiddens, device)</span><br></pre></td></tr></table></figure><p>让我们检查输出是否具有正确的形状。 例如，隐状态的维数是否保持不变。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">num_hiddens = <span class="number">512</span></span><br><span class="line">net = RNNModelScratch(<span class="built_in">len</span>(vocab), num_hiddens, d2l.try_gpu(), get_params,</span><br><span class="line">                      init_rnn_state, rnn)</span><br><span class="line">state = net.begin_state(X.shape[<span class="number">0</span>], d2l.try_gpu())</span><br><span class="line">Y, new_state = net(X.to(d2l.try_gpu()), state)</span><br><span class="line">Y.shape, <span class="built_in">len</span>(new_state), new_state[<span class="number">0</span>].shape</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(torch.Size([<span class="number">10</span>, <span class="number">28</span>]), <span class="number">1</span>, torch.Size([<span class="number">2</span>, <span class="number">512</span>]))</span><br></pre></td></tr></table></figure><p>我们可以看到输出形状是（时间步数×批量大小，词表大小）， 而隐状态形状保持不变，即（批量大小，隐藏单元数）。</p><h3 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h3><p>让我们首先定义预测函数来生成<code>prefix</code>之后的新字符， 其中的<code>prefix</code>是一个用户提供的包含多个字符的字符串。 在循环遍历<code>prefix</code>中的开始字符时， 我们不断地将隐状态传递到下一个时间步，但是不生成任何输出。 这被称为<em>预热</em>（warm-up）期， 因为在此期间模型会自我更新（例如，更新隐状态）， 但不会进行预测。 预热期结束后，隐状态的值通常比刚开始的初始值更适合预测， 从而预测字符并输出它们。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict_ch8</span>(<span class="params">prefix, num_preds, net, vocab, device</span>):  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;在prefix后面生成新字符&quot;&quot;&quot;</span></span><br><span class="line">    state = net.begin_state(batch_size=<span class="number">1</span>, device=device)</span><br><span class="line">    outputs = [vocab[prefix[<span class="number">0</span>]]]</span><br><span class="line">    get_input = <span class="keyword">lambda</span>: torch.tensor([outputs[-<span class="number">1</span>]], device=device).reshape((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> prefix[<span class="number">1</span>:]:  <span class="comment"># 预热期</span></span><br><span class="line">        _, state = net(get_input(), state)</span><br><span class="line">        outputs.append(vocab[y])</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_preds):  <span class="comment"># 预测num_preds步</span></span><br><span class="line">        y, state = net(get_input(), state)</span><br><span class="line">        outputs.append(<span class="built_in">int</span>(y.argmax(dim=<span class="number">1</span>).reshape(<span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join([vocab.idx_to_token[i] <span class="keyword">for</span> i <span class="keyword">in</span> outputs])</span><br></pre></td></tr></table></figure><p>现在我们可以测试<code>predict_ch8</code>函数。 我们将前缀指定为<code>time traveller</code>， 并基于这个前缀生成10个后续字符。 鉴于我们还没有训练网络，它会生成荒谬的预测结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_ch8(<span class="string">&#x27;time traveller &#x27;</span>, <span class="number">10</span>, net, vocab, d2l.try_gpu())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;time traveller aaaaaaaaaa&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="梯度裁剪"><a href="#梯度裁剪" class="headerlink" title="梯度裁剪"></a>梯度裁剪</h3><p>对于长度为𝑇的序列，我们在迭代中计算这𝑇个时间步上的梯度， 将会在反向传播过程中产生长度为𝑂(𝑇)的矩阵乘法链。 如之前所述， 当𝑇较大时，它可能导致数值不稳定， 例如可能导致梯度爆炸或梯度消失。 因此，循环神经网络模型往往需要额外的方式来支持稳定训练。</p><p>一般来说，当解决优化问题时，我们对模型参数采用更新步骤。 假定在向量形式的𝑥中， 或者在小批量数据的负梯度𝑔方向上。 例如，使用𝜂&gt;0作为学习率时，在一次迭代中， 我们将𝑥更新为𝑥−𝜂𝑔。 如果我们进一步假设目标函数𝑓表现良好， 即函数𝑓在常数𝐿下是<em>利普希茨连续的</em>（Lipschitz continuous）。 也就是说，对于任意𝑥和𝑦我们有：</p><p>​                                                                                                |𝑓(𝑥)−𝑓(𝑦)|≤𝐿‖𝑥−𝑦‖.</p><p>在这种情况下，我们可以安全地假设： 如果我们通过𝜂𝑔更新参数向量，则</p><p>​                                                                                               |𝑓(𝑥)−𝑓(𝑥−𝜂𝑔)|≤𝐿𝜂‖𝑔‖,</p><p>这意味着我们不会观察到超过𝐿𝜂‖𝑔‖的变化。 这既是坏事也是好事。 坏的方面，它限制了取得进展的速度； 好的方面，它限制了事情变糟的程度，尤其当我们朝着错误的方向前进时。</p><p>有时梯度可能很大，从而优化算法可能无法收敛。 我们可以通过降低𝜂的学习率来解决这个问题。 但是如果我们很少得到大的梯度呢？ 在这种情况下，这种做法似乎毫无道理。 一个流行的替代方案是通过将梯度𝑔投影回给定半径 （例如𝜃）的球来裁剪梯度𝑔。 如下式：</p><p>​                                                                                                   𝑔←min(1,𝜃‖𝑔‖)𝑔.</p><p>通过这样做，我们知道梯度范数永远不会超过𝜃， 并且更新后的梯度完全与𝑔的原始方向对齐。 它还有一个值得拥有的副作用， 即限制任何给定的小批量数据（以及其中任何给定的样本）对参数向量的影响， 这赋予了模型一定程度的稳定性。 梯度裁剪提供了一个快速修复梯度爆炸的方法， 虽然它并不能完全解决问题，但它是众多有效的技术之一。</p><p>下面我们定义一个函数来裁剪模型的梯度， 模型是从零开始实现的模型或由高级API构建的模型。 我们在此计算了所有模型参数的梯度的范数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">grad_clipping</span>(<span class="params">net, theta</span>):  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;裁剪梯度&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, nn.Module):</span><br><span class="line">        params = [p <span class="keyword">for</span> p <span class="keyword">in</span> net.parameters() <span class="keyword">if</span> p.requires_grad]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        params = net.params</span><br><span class="line">    norm = torch.sqrt(<span class="built_in">sum</span>(torch.<span class="built_in">sum</span>((p.grad ** <span class="number">2</span>)) <span class="keyword">for</span> p <span class="keyword">in</span> params))</span><br><span class="line">    <span class="keyword">if</span> norm &gt; theta:</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">            param.grad[:] *= theta / norm</span><br></pre></td></tr></table></figure><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>在训练模型之前，让我们定义一个函数在一个迭代周期内训练模型。 它与我们训练之前的模型的方式有三个不同之处。</p><ol><li>序列数据的不同采样方法（随机采样和顺序分区）将导致隐状态初始化的差异。</li><li>我们在更新模型参数之前裁剪梯度。 这样的操作的目的是，即使训练过程中某个点上发生了梯度爆炸，也能保证模型不会发散。</li><li>我们用困惑度来评价模型。 这样的度量确保了不同长度的序列具有可比性。</li></ol><p>具体来说，当使用顺序分区时， 我们只在每个迭代周期的开始位置初始化隐状态。 由于下一个小批量数据中的第𝑖个子序列样本 与当前第𝑖个子序列样本相邻， 因此当前小批量数据最后一个样本的隐状态， 将用于初始化下一个小批量数据第一个样本的隐状态。 这样，存储在隐状态中的序列的历史信息 可以在一个迭代周期内流经相邻的子序列。 然而，在任何一点隐状态的计算， 都依赖于同一迭代周期中前面所有的小批量数据， 这使得梯度计算变得复杂。 为了降低计算量，在处理任何一个小批量数据之前， 我们先分离梯度，使得隐状态的梯度计算总是限制在一个小批量数据的时间步内。</p><p>当使用随机抽样时，因为每个样本都是在一个随机位置抽样的， 因此需要为每个迭代周期重新初始化隐状态。 <code>updater</code>是更新模型参数的常用函数。 它既可以是从头开始实现的<code>d2l.sgd</code>函数， 也可以是深度学习框架中内置的优化函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_epoch_ch8</span>(<span class="params">net, train_iter, loss, updater, device, use_random_iter</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;训练网络一个迭代周期（定义见第8章）&quot;&quot;&quot;</span></span><br><span class="line">    state, timer = <span class="literal">None</span>, d2l.Timer()</span><br><span class="line">    metric = d2l.Accumulator(<span class="number">2</span>)  <span class="comment"># 训练损失之和,词元数量</span></span><br><span class="line">    <span class="keyword">for</span> X, Y <span class="keyword">in</span> train_iter:</span><br><span class="line">        <span class="keyword">if</span> state <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> use_random_iter:</span><br><span class="line">            <span class="comment"># 在第一次迭代或使用随机抽样时初始化state</span></span><br><span class="line">            state = net.begin_state(batch_size=X.shape[<span class="number">0</span>], device=device)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, nn.Module) <span class="keyword">and</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(state, <span class="built_in">tuple</span>):</span><br><span class="line">                <span class="comment"># state对于nn.GRU是个张量</span></span><br><span class="line">                state.detach_()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># state对于nn.LSTM或对于我们从零开始实现的模型是个张量</span></span><br><span class="line">                <span class="keyword">for</span> s <span class="keyword">in</span> state:</span><br><span class="line">                    s.detach_()</span><br><span class="line">        y = Y.T.reshape(-<span class="number">1</span>)</span><br><span class="line">        X, y = X.to(device), y.to(device)</span><br><span class="line">        y_hat, state = net(X, state)</span><br><span class="line">        l = loss(y_hat, y.long()).mean()</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(updater, torch.optim.Optimizer):</span><br><span class="line">            updater.zero_grad()</span><br><span class="line">            l.backward()</span><br><span class="line">            grad_clipping(net, <span class="number">1</span>)</span><br><span class="line">            updater.step()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            l.backward()</span><br><span class="line">            grad_clipping(net, <span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 因为已经调用了mean函数</span></span><br><span class="line">            updater(batch_size=<span class="number">1</span>)</span><br><span class="line">        metric.add(l * y.numel(), y.numel())</span><br><span class="line">    <span class="keyword">return</span> math.exp(metric[<span class="number">0</span>] / metric[<span class="number">1</span>]), metric[<span class="number">1</span>] / timer.stop()</span><br></pre></td></tr></table></figure><p>循环神经网络模型的训练函数既支持从零开始实现， 也可以使用高级API来实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_ch8</span>(<span class="params">net, train_iter, vocab, lr, num_epochs, device,</span></span><br><span class="line"><span class="params">              use_random_iter=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;训练模型（定义见第8章）&quot;&quot;&quot;</span></span><br><span class="line">    loss = nn.CrossEntropyLoss()</span><br><span class="line">    animator = d2l.Animator(xlabel=<span class="string">&#x27;epoch&#x27;</span>, ylabel=<span class="string">&#x27;perplexity&#x27;</span>,</span><br><span class="line">                            legend=[<span class="string">&#x27;train&#x27;</span>], xlim=[<span class="number">10</span>, num_epochs])</span><br><span class="line">    <span class="comment"># 初始化</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, nn.Module):</span><br><span class="line">        updater = torch.optim.SGD(net.parameters(), lr)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        updater = <span class="keyword">lambda</span> batch_size: d2l.sgd(net.params, lr, batch_size)</span><br><span class="line">    predict = <span class="keyword">lambda</span> prefix: predict_ch8(prefix, <span class="number">50</span>, net, vocab, device)</span><br><span class="line">    <span class="comment"># 训练和预测</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        ppl, speed = train_epoch_ch8(</span><br><span class="line">            net, train_iter, loss, updater, device, use_random_iter)</span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(predict(<span class="string">&#x27;time traveller&#x27;</span>))</span><br><span class="line">            animator.add(epoch + <span class="number">1</span>, [ppl])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;困惑度 <span class="subst">&#123;ppl:<span class="number">.1</span>f&#125;</span>, <span class="subst">&#123;speed:<span class="number">.1</span>f&#125;</span> 词元/秒 <span class="subst">&#123;<span class="built_in">str</span>(device)&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(predict(<span class="string">&#x27;time traveller&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(predict(<span class="string">&#x27;traveller&#x27;</span>))</span><br></pre></td></tr></table></figure><p>现在，我们训练循环神经网络模型。 因为我们在数据集中只使用了10000个词元， 所以模型需要更多的迭代周期来更好地收敛。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">num_epochs, lr = <span class="number">500</span>, <span class="number">1</span></span><br><span class="line">train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">困惑度 <span class="number">1.0</span>, <span class="number">67212.6</span> 词元/秒 cuda:<span class="number">0</span></span><br><span class="line">time traveller <span class="keyword">for</span> so it will be convenient to speak of himwas e</span><br><span class="line">travelleryou can show black <span class="keyword">is</span> white by argument said filby</span><br></pre></td></tr></table></figure><p><img src="/../img/Pytorch1/pytorch8/3.png" alt="3"></p><p>从零开始实现上述循环神经网络模型， 虽然有指导意义，但是并不方便。 在下一节中，我们将学习如何改进循环神经网络模型。 例如，如何使其实现地更容易，且运行速度更快。</p><h2 id="循环神经网络的简洁实现"><a href="#循环神经网络的简洁实现" class="headerlink" title="循环神经网络的简洁实现"></a>循环神经网络的简洁实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">batch_size, num_steps = <span class="number">32</span>, <span class="number">35</span></span><br><span class="line">train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)</span><br></pre></td></tr></table></figure><h3 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h3><p>高级API提供了循环神经网络的实现。 我们构造一个具有256个隐藏单元的单隐藏层的循环神经网络层<code>rnn_layer</code>。 事实上，我们还没有讨论多层循环神经网络的意义。 现在仅需要将多层理解为一层循环神经网络的输出被用作下一层循环神经网络的输入就足够了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">num_hiddens = <span class="number">256</span></span><br><span class="line">rnn_layer = nn.RNN(<span class="built_in">len</span>(vocab), num_hiddens)</span><br></pre></td></tr></table></figure><p>我们使用张量来初始化隐状态，它的形状是（隐藏层数，批量大小，隐藏单元数）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">state = torch.zeros((<span class="number">1</span>, batch_size, num_hiddens))</span><br><span class="line">state.shape</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([<span class="number">1</span>, <span class="number">32</span>, <span class="number">256</span>])</span><br></pre></td></tr></table></figure><p>通过一个隐状态和一个输入，我们就可以用更新后的隐状态计算输出。 需要强调的是，<code>rnn_layer</code>的“输出”（<code>Y</code>）不涉及输出层的计算： 它是指每个时间步的隐状态，这些隐状态可以用作后续输出层的输入。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X = torch.rand(size=(num_steps, batch_size, <span class="built_in">len</span>(vocab)))</span><br><span class="line">Y, state_new = rnn_layer(X, state)</span><br><span class="line">Y.shape, state_new.shape</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(torch.Size([<span class="number">35</span>, <span class="number">32</span>, <span class="number">256</span>]), torch.Size([<span class="number">1</span>, <span class="number">32</span>, <span class="number">256</span>]))</span><br></pre></td></tr></table></figure><p>我们为一个完整的循环神经网络模型定义了一个<code>RNNModel</code>类。 注意，<code>rnn_layer</code>只包含隐藏的循环层，我们还需要创建一个单独的输出层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RNNModel</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;循环神经网络模型&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, rnn_layer, vocab_size, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(RNNModel, self).__init__(**kwargs)</span><br><span class="line">        self.rnn = rnn_layer</span><br><span class="line">        self.vocab_size = vocab_size</span><br><span class="line">        self.num_hiddens = self.rnn.hidden_size</span><br><span class="line">        <span class="comment"># 如果RNN是双向的（之后将介绍），num_directions应该是2，否则应该是1</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.rnn.bidirectional:</span><br><span class="line">            self.num_directions = <span class="number">1</span></span><br><span class="line">            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.num_directions = <span class="number">2</span></span><br><span class="line">            self.linear = nn.Linear(self.num_hiddens * <span class="number">2</span>, self.vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs, state</span>):</span><br><span class="line">        X = F.one_hot(inputs.T.long(), self.vocab_size)</span><br><span class="line">        X = X.to(torch.float32)</span><br><span class="line">        Y, state = self.rnn(X, state)</span><br><span class="line">        <span class="comment"># 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数)</span></span><br><span class="line">        <span class="comment"># 它的输出形状是(时间步数*批量大小,词表大小)。</span></span><br><span class="line">        output = self.linear(Y.reshape((-<span class="number">1</span>, Y.shape[-<span class="number">1</span>])))</span><br><span class="line">        <span class="keyword">return</span> output, state</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">begin_state</span>(<span class="params">self, device, batch_size=<span class="number">1</span></span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(self.rnn, nn.LSTM):</span><br><span class="line">            <span class="comment"># nn.GRU以张量作为隐状态</span></span><br><span class="line">            <span class="keyword">return</span>  torch.zeros((self.num_directions * self.rnn.num_layers,</span><br><span class="line">                                 batch_size, self.num_hiddens),</span><br><span class="line">                                device=device)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># nn.LSTM以元组作为隐状态</span></span><br><span class="line">            <span class="keyword">return</span> (torch.zeros((</span><br><span class="line">                self.num_directions * self.rnn.num_layers,</span><br><span class="line">                batch_size, self.num_hiddens), device=device),</span><br><span class="line">                    torch.zeros((</span><br><span class="line">                        self.num_directions * self.rnn.num_layers,</span><br><span class="line">                        batch_size, self.num_hiddens), device=device))</span><br></pre></td></tr></table></figure><h3 id="训练与预测"><a href="#训练与预测" class="headerlink" title="训练与预测"></a>训练与预测</h3><p>在训练模型之前，让我们基于一个具有随机权重的模型进行预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">device = d2l.try_gpu()</span><br><span class="line">net = RNNModel(rnn_layer, vocab_size=<span class="built_in">len</span>(vocab))</span><br><span class="line">net = net.to(device)</span><br><span class="line">d2l.predict_ch8(<span class="string">&#x27;time traveller&#x27;</span>, <span class="number">10</span>, net, vocab, device)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;time travellerbbabbkabyg&#x27;</span></span><br></pre></td></tr></table></figure><p>很明显，这种模型根本不能输出好的结果。 接下来，我们使用之前中定义的超参数调用<code>train_ch8</code>，并且使用pytorch训练模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">num_epochs, lr = <span class="number">500</span>, <span class="number">1</span></span><br><span class="line">d2l.train_ch8(net, train_iter, vocab, lr, num_epochs, device)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">perplexity <span class="number">1.3</span>, <span class="number">404413.8</span> tokens/sec on cuda:<span class="number">0</span></span><br><span class="line">time travellerit would be remarkably convenient <span class="keyword">for</span> the historia</span><br><span class="line">travellery of il the hise fupt might <span class="keyword">and</span> st was it loflers</span><br></pre></td></tr></table></figure><p><img src="/../img/Pytorch1/pytorch8/4.png" alt="4"></p>]]></content>
      
      
      
        <tags>
            
            <tag> machine-learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch8 CNN卷积神经网络</title>
      <link href="/2024/07/01/CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2024/07/01/CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="CNN卷积神经网络"><a href="#CNN卷积神经网络" class="headerlink" title="CNN卷积神经网络"></a>CNN卷积神经网络</h1><h2 id="全连接网络-VS-卷积网络"><a href="#全连接网络-VS-卷积网络" class="headerlink" title="全连接网络 VS 卷积网络"></a>全连接网络 VS 卷积网络</h2><p>全连接神经网络之所以不太适合图像识别任务，主要有以下几个方面的问题：</p><ul><li><strong>参数数量太多</strong> 考虑一个输入1000<em>1000像素的图片(一百万像素，现在已经不能算大图了)，输入层有1000</em>1000&#x3D;100万节点。假设第一个隐藏层有100个节点(这个数量并不多)，那么仅这一层就有(1000*1000+1)*100&#x3D;1亿参数，这实在是太多了！我们看到图像只扩大一点，参数数量就会多很多，因此它的扩展性很差。</li><li><strong>没有利用像素之间的位置信息</strong> 对于图像识别任务来说，每个像素和其周围像素的联系是比较紧密的，和离得很远的像素的联系可能就很小了。如果一个神经元和上一层所有神经元相连，那么就相当于对于一个像素来说，把图像的所有像素都等同看待，这不符合前面的假设。当我们完成每个连接权重的学习之后，最终可能会发现，有大量的权重，它们的值都是很小的(也就是这些连接其实无关紧要)。努力学习大量并不重要的权重，这样的学习必将是非常低效的。</li><li><strong>网络层数限制</strong> 我们知道网络层数越多其表达能力越强，但是通过梯度下降方法训练深度全连接神经网络很困难，因为全连接神经网络的梯度很难传递超过3层。因此，我们不可能得到一个很深的全连接神经网络，也就限制了它的能力。</li></ul><p>那么，卷积神经网络又是怎样解决这个问题的呢？主要有三个思路：</p><ul><li><strong>局部连接</strong> 这个是最容易想到的，每个神经元不再和上一层的所有神经元相连，而只和一小部分神经元相连。这样就减少了很多参数。</li><li><strong>权值共享</strong> 一组连接可以共享同一个权重，而不是每个连接有一个不同的权重，这样又减少了很多参数。</li><li><strong>下采样</strong> 可以使用Pooling来减少每层的样本数，进一步减少参数数量，同时还可以提升模型的鲁棒性。</li></ul><p>对于图像识别任务来说，卷积神经网络通过尽可能保留重要的参数，去掉大量不重要的参数，来达到更好的学习效果。</p><h2 id="卷积结构"><a href="#卷积结构" class="headerlink" title="卷积结构"></a>卷积结构</h2><h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>卷积层可以产生一组平行的特征图（feature map），它通过在输入图像上滑动不同的卷积核并执行一定的运算而组成。此外，在每一个滑动的位置上，卷积核与输入图像之间会执行一个元素对应乘积并求和的运算以将感受视野内的信息投影到特征图中的一个元素。这一滑动的过程可称为步幅 Z_s，步幅 Z_s 是控制输出特征图尺寸的一个因素。卷积核的尺寸要比输入图像小得多，且重叠或平行地作用于输入图像中，一张特征图中的所有元素都是通过一个卷积核计算得出的，也即一张特征图共享了相同的权重和偏置项。</p><h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>池化（Pooling）是卷积神经网络中另一个重要的概念，它实际上是一种非线性形式的降采样。有多种不同形式的非线性池化函数，而其中“最大池化（Max pooling）”是最为常见的。它是将输入的图像划分为若干个矩形区域，对每个子区域输出最大值。</p><p>一个特征的精确位置远不及它相对于其他特征的粗略位置重要。池化层会不断地减小数据的空间大小，因此参数的数量和计算量也会下降，这在一定程度上也控制了<a href="https://zh.wikipedia.org/wiki/%E8%BF%87%E6%8B%9F%E5%90%88">过拟合</a>。通常来说，CNN的网络结构中的卷积层之间都会周期性地插入池化层。池化操作提供了另一种形式的平移不变性。因为卷积核是一种特征发现器，我们通过卷积层可以很容易地发现图像中的各种边缘。但是卷积层发现的特征往往过于精确，我们即使高速连拍拍摄一个物体，照片中的物体的边缘像素位置也不大可能完全一致，通过池化层我们可以降低卷积层对边缘的敏感性。</p><h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p>最后，在经过几个卷积和最大池化层之后，神经网络中的高级推理通过完全连接层来完成。就和常规的非卷积人工神经网络中一样，完全连接层中的神经元与前一层中的所有激活都有联系。因此，它们的激活可以作为<a href="https://zh.wikipedia.org/wiki/%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2">仿射变换</a>来计算，也就是先乘以一个矩阵然后加上一个偏差(bias)偏移量(向量加上一个固定的或者学习来的偏差量)。</p><h2 id="卷积神经网络（LeNet）"><a href="#卷积神经网络（LeNet）" class="headerlink" title="卷积神经网络（LeNet）"></a>卷积神经网络（LeNet）</h2><h3 id="模型实现"><a href="#模型实现" class="headerlink" title="模型实现"></a>模型实现</h3><p>LeNet是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关注。</p><p>用Pytorch框架实现此类模型非常简单。我们只需要实例化一个<code>Sequential</code>块并将需要的层连接在一起。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>), nn.Sigmoid(),</span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>), nn.Sigmoid(),</span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">120</span>, <span class="number">84</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">84</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure><p>将一个大小为28×28的单通道（黑白）图像通过LeNet。通过在每一层打印输出的形状，我们可以检查模型</p><p><img src="/../img/Pytorch1/pytorch8/1.png" alt="1"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = torch.rand(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), dtype=torch.float32)</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(layer.__class__.__name__,<span class="string">&#x27;output shape: \t&#x27;</span>,X.shape)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Conv2d output shape:         torch.Size([<span class="number">1</span>, <span class="number">6</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line">Sigmoid output shape:        torch.Size([<span class="number">1</span>, <span class="number">6</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line">AvgPool2d output shape:      torch.Size([<span class="number">1</span>, <span class="number">6</span>, <span class="number">14</span>, <span class="number">14</span>])</span><br><span class="line">Conv2d output shape:         torch.Size([<span class="number">1</span>, <span class="number">16</span>, <span class="number">10</span>, <span class="number">10</span>])</span><br><span class="line">Sigmoid output shape:        torch.Size([<span class="number">1</span>, <span class="number">16</span>, <span class="number">10</span>, <span class="number">10</span>])</span><br><span class="line">AvgPool2d output shape:      torch.Size([<span class="number">1</span>, <span class="number">16</span>, <span class="number">5</span>, <span class="number">5</span>])</span><br><span class="line">Flatten output shape:        torch.Size([<span class="number">1</span>, <span class="number">400</span>])</span><br><span class="line">Linear output shape:         torch.Size([<span class="number">1</span>, <span class="number">120</span>])</span><br><span class="line">Sigmoid output shape:        torch.Size([<span class="number">1</span>, <span class="number">120</span>])</span><br><span class="line">Linear output shape:         torch.Size([<span class="number">1</span>, <span class="number">84</span>])</span><br><span class="line">Sigmoid output shape:        torch.Size([<span class="number">1</span>, <span class="number">84</span>])</span><br><span class="line">Linear output shape:         torch.Size([<span class="number">1</span>, <span class="number">10</span>])</span><br></pre></td></tr></table></figure><h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><p>现在我们已经实现了LeNet，让我们看看LeNet在Fashion-MNIST数据集上的表现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)</span><br></pre></td></tr></table></figure><p>由于完整的数据集位于内存中，因此在模型使用GPU计算数据集之前，我们需要将其复制到显存中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_accuracy_gpu</span>(<span class="params">net, data_iter, device=<span class="literal">None</span></span>): <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;使用GPU计算模型在数据集上的精度&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, nn.Module):</span><br><span class="line">        net.<span class="built_in">eval</span>()  <span class="comment"># 设置为评估模式</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> device:</span><br><span class="line">            device = <span class="built_in">next</span>(<span class="built_in">iter</span>(net.parameters())).device</span><br><span class="line">    <span class="comment"># 正确预测的数量，总预测的数量</span></span><br><span class="line">    metric = d2l.Accumulator(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(X, <span class="built_in">list</span>):</span><br><span class="line">                <span class="comment"># BERT微调所需的（之后将介绍）</span></span><br><span class="line">                X = [x.to(device) <span class="keyword">for</span> x <span class="keyword">in</span> X]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                X = X.to(device)</span><br><span class="line">            y = y.to(device)</span><br><span class="line">            metric.add(d2l.accuracy(net(X), y), y.numel())</span><br><span class="line">    <span class="keyword">return</span> metric[<span class="number">0</span>] / metric[<span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>与全连接层一样，我们使用交叉熵损失函数和小批量随机梯度下降。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_ch6</span>(<span class="params">net, train_iter, test_iter, num_epochs, lr, device</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;用GPU训练模型&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">m</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear <span class="keyword">or</span> <span class="built_in">type</span>(m) == nn.Conv2d:</span><br><span class="line">            nn.init.xavier_uniform_(m.weight)</span><br><span class="line">    net.apply(init_weights)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;training on&#x27;</span>, device)</span><br><span class="line">    net.to(device)</span><br><span class="line">    optimizer = torch.optim.SGD(net.parameters(), lr=lr)</span><br><span class="line">    loss = nn.CrossEntropyLoss()</span><br><span class="line">    animator = d2l.Animator(xlabel=<span class="string">&#x27;epoch&#x27;</span>, xlim=[<span class="number">1</span>, num_epochs],</span><br><span class="line">                            legend=[<span class="string">&#x27;train loss&#x27;</span>, <span class="string">&#x27;train acc&#x27;</span>, <span class="string">&#x27;test acc&#x27;</span>])</span><br><span class="line">    timer, num_batches = d2l.Timer(), <span class="built_in">len</span>(train_iter)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="comment"># 训练损失之和，训练准确率之和，样本数</span></span><br><span class="line">        metric = d2l.Accumulator(<span class="number">3</span>)</span><br><span class="line">        net.train()</span><br><span class="line">        <span class="keyword">for</span> i, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_iter):</span><br><span class="line">            timer.start()</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            X, y = X.to(device), y.to(device)</span><br><span class="line">            y_hat = net(X)</span><br><span class="line">            l = loss(y_hat, y)</span><br><span class="line">            l.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                metric.add(l * X.shape[<span class="number">0</span>], d2l.accuracy(y_hat, y), X.shape[<span class="number">0</span>])</span><br><span class="line">            timer.stop()</span><br><span class="line">            train_l = metric[<span class="number">0</span>] / metric[<span class="number">2</span>]</span><br><span class="line">            train_acc = metric[<span class="number">1</span>] / metric[<span class="number">2</span>]</span><br><span class="line">            <span class="keyword">if</span> (i + <span class="number">1</span>) % (num_batches // <span class="number">5</span>) == <span class="number">0</span> <span class="keyword">or</span> i == num_batches - <span class="number">1</span>:</span><br><span class="line">                animator.add(epoch + (i + <span class="number">1</span>) / num_batches,</span><br><span class="line">                             (train_l, train_acc, <span class="literal">None</span>))</span><br><span class="line">        test_acc = evaluate_accuracy_gpu(net, test_iter)</span><br><span class="line">        animator.add(epoch + <span class="number">1</span>, (<span class="literal">None</span>, <span class="literal">None</span>, test_acc))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;loss <span class="subst">&#123;train_l:<span class="number">.3</span>f&#125;</span>, train acc <span class="subst">&#123;train_acc:<span class="number">.3</span>f&#125;</span>, &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;test acc <span class="subst">&#123;test_acc:<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;metric[<span class="number">2</span>] * num_epochs / timer.<span class="built_in">sum</span>():<span class="number">.1</span>f&#125;</span> examples/sec &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;on <span class="subst">&#123;<span class="built_in">str</span>(device)&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><p>训练和评估LeNet-5模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lr, num_epochs = <span class="number">0.9</span>, <span class="number">10</span></span><br><span class="line">train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss <span class="number">0.469</span>, train acc <span class="number">0.823</span>, test acc <span class="number">0.779</span></span><br><span class="line"><span class="number">55296.6</span> examples/sec on cuda:<span class="number">0</span></span><br></pre></td></tr></table></figure><p><img src="/../img/Pytorch1/pytorch8/2.png" alt="2"></p>]]></content>
      
      
      
        <tags>
            
            <tag> machine-learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java容器用法</title>
      <link href="/2024/06/30/Java%E5%AE%B9%E5%99%A8%E7%94%A8%E6%B3%95/"/>
      <url>/2024/06/30/Java%E5%AE%B9%E5%99%A8%E7%94%A8%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="Java容器用法汇总"><a href="#Java容器用法汇总" class="headerlink" title="Java容器用法汇总"></a>Java容器用法汇总</h1><h2 id="容器分类"><a href="#容器分类" class="headerlink" title="容器分类"></a>容器分类</h2><p><img src="/../img/java/%E5%AE%B9%E5%99%A8%E6%B1%87%E6%80%BB/1.png" alt="1"></p><ul><li>List(对付顺序的好帮手): 存储的元素是有序的、可重复的。</li><li>Set (注重独一无二的性质)：存储的元素是无序的、不可重复的。</li><li>Queue (实现排队功能的叫号机):按特定的排队规则来确定先后顺序，存储的元素是有序的、可重复的。</li><li>Map (用 key 来搜索的专家) :使用键值对（key-value）存储，类似于数学上的函数 y&#x3D;f(x)，“x” 代表 key，“y” 代表 value，key 是无序的、不可重复的，value 是无序的、可重复的，每个键最多映射到一个值。</li></ul><h2 id="Collection"><a href="#Collection" class="headerlink" title="Collection"></a>Collection</h2><p>Collection是所有单列集合的父接口，因此在Collection中定义了单列集合(List和Set)通用的一些方法，这些方法可用于操作所有的单列集合。方法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CollectionAPITest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">//Collection是接口，使用需要实现类</span></span><br><span class="line">        <span class="type">Collection</span> <span class="variable">col</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ArrayList</span>();</span><br><span class="line">        <span class="comment">//add()添加一个元素，添加基本数据类型，会自动装箱，int---&gt;Integer</span></span><br><span class="line">        col.add(<span class="number">1</span>);</span><br><span class="line">        col.add(<span class="number">2</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;使用add方法添加1和2：&quot;</span>+col);</span><br><span class="line">        <span class="comment">//addALl()添加一个集合的所有元素</span></span><br><span class="line">        List&lt;Integer&gt; integers = Arrays.asList(<span class="keyword">new</span> <span class="title class_">Integer</span>[]&#123;<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>&#125;);</span><br><span class="line">        col.addAll(integers);</span><br><span class="line">        System.out.println(<span class="string">&quot;使用addAll方法添加&#123;3, 4, 5, 6, 7, 8&#125;:&quot;</span>+col);</span><br><span class="line">        System.out.println(Integer.toBinaryString(<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toBinaryString(-<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toHexString(-<span class="number">2</span>&gt;&gt;&gt;<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toBinaryString(-<span class="number">2</span>&gt;&gt;&gt;<span class="number">2</span>));</span><br><span class="line">        <span class="comment">//remove()方法移除指定元素</span></span><br><span class="line">        System.out.println(<span class="string">&quot;使用remove()方法移除元素1：&quot;</span>+col.remove(<span class="number">1</span>)+<span class="string">&quot;(true成功/false失败)移除后集合&quot;</span>+col);</span><br><span class="line">        System.out.println(<span class="string">&quot;再次使用remove()方法移除元素1：&quot;</span>+col.remove(<span class="number">1</span>)+<span class="string">&quot;(true成功/false失败)移除后集合&quot;</span>+col);</span><br><span class="line">        System.out.println(Integer.toBinaryString(<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toBinaryString(-<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toHexString(-<span class="number">2</span>&gt;&gt;&gt;<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toBinaryString(-<span class="number">2</span>&gt;&gt;&gt;<span class="number">2</span>));</span><br><span class="line">        <span class="comment">//clear()方法清除集合</span></span><br><span class="line">        col.clear();</span><br><span class="line">        System.out.println(<span class="string">&quot;使用clear方法清除集合&quot;</span>+col);</span><br><span class="line">        <span class="comment">//isEmpty()方法查看集合是否为空</span></span><br><span class="line">        System.out.println(<span class="string">&quot;使用isEmpty方法查看集合是否为空&quot;</span>+col.isEmpty());</span><br><span class="line">        System.out.println(Integer.toBinaryString(<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toBinaryString(-<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toHexString(-<span class="number">2</span>&gt;&gt;&gt;<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toBinaryString(-<span class="number">2</span>&gt;&gt;&gt;<span class="number">2</span>));</span><br><span class="line">        <span class="comment">//equals()方法比较两个集合是否相等</span></span><br><span class="line">        ArrayList&lt;Object&gt; objects = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        System.out.println(<span class="string">&quot;集合一：&quot;</span>+col+<span class="string">&quot;集合二：&quot;</span>+objects+<span class="string">&quot;使用equals()比较两个集合元素是否相等&quot;</span>+col.equals(objects));</span><br><span class="line">        objects.add(<span class="number">1</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;集合一：&quot;</span>+col+<span class="string">&quot;集合二：&quot;</span>+objects+<span class="string">&quot;使用equals()比较两个集合元素是否相等&quot;</span>+col.equals(objects));</span><br><span class="line">        System.out.println(Integer.toBinaryString(<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toBinaryString(-<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toHexString(-<span class="number">2</span>&gt;&gt;&gt;<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toBinaryString(-<span class="number">2</span>&gt;&gt;&gt;<span class="number">2</span>));</span><br><span class="line">        <span class="comment">//contains()方法判断集合是否包含指定元素</span></span><br><span class="line">        System.out.println(<span class="string">&quot;集合：&quot;</span>+objects+<span class="string">&quot;使用contains()方法判断集合是否包含1这个元素&quot;</span>+objects.contains(<span class="number">1</span>));</span><br><span class="line">        System.out.println(<span class="string">&quot;集合：&quot;</span>+objects+<span class="string">&quot;使用contains()方法判断集合是否包含2这个元素&quot;</span>+objects.contains(<span class="number">2</span>));</span><br><span class="line">        System.out.println(Integer.toBinaryString(<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toBinaryString(-<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toHexString(-<span class="number">2</span>&gt;&gt;&gt;<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toBinaryString(-<span class="number">2</span>&gt;&gt;&gt;<span class="number">2</span>));</span><br><span class="line">        <span class="comment">//size()方法获取集合长度</span></span><br><span class="line">        System.out.println(<span class="string">&quot;集合：&quot;</span>+col+<span class="string">&quot;使用size()方法获取集合长度&quot;</span>+col.size());</span><br><span class="line">        System.out.println(<span class="string">&quot;集合：&quot;</span>+objects+<span class="string">&quot;使用size()方法获取集合长度&quot;</span>+objects.size());</span><br><span class="line">        System.out.println(Integer.toBinaryString(<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toBinaryString(-<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toHexString(-<span class="number">2</span>&gt;&gt;&gt;<span class="number">2</span>)+<span class="string">&quot; &quot;</span>+Integer.toBinaryString(-<span class="number">2</span>&gt;&gt;&gt;<span class="number">2</span>));</span><br><span class="line">        <span class="comment">//使用iterator()迭代器遍历集合</span></span><br><span class="line">        col.addAll( Arrays.asList(<span class="keyword">new</span> <span class="title class_">Integer</span>[]&#123;<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>&#125;));</span><br><span class="line">        System.out.println(<span class="string">&quot;使用iterator()遍历集合&quot;</span>+col);</span><br><span class="line"></span><br><span class="line">        <span class="type">Iterator</span> <span class="variable">iterator</span> <span class="operator">=</span> col.iterator();<span class="comment">//获取Iterator对象</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(iterator.hasNext())&#123;<span class="comment">//Iterator.hasNext()方法，判断是否有个下一个可迭代对象</span></span><br><span class="line">            <span class="type">Object</span> <span class="variable">next</span> <span class="operator">=</span> iterator.next();<span class="comment">//返回当前元素，并指针后移，指针指向下一个元素，若没有，下一次hasNext方法会做处理</span></span><br><span class="line">            System.out.println(<span class="string">&quot;第&quot;</span>+i+<span class="string">&quot;个元素：&quot;</span>+next);</span><br><span class="line">            i++;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="常见用法"><a href="#常见用法" class="headerlink" title="常见用法"></a>常见用法</h2><h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//增删改查方法</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(Object element)</span> <span class="comment">//增添元素</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> index,Object element)</span> <span class="comment">//在指定位置增添元素</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">remove</span><span class="params">(Object o)</span> <span class="comment">//删除指定对象</span></span><br><span class="line"><span class="keyword">public</span> Object <span class="title function_">remove</span><span class="params">(<span class="type">int</span> index)</span> <span class="comment">//删除指定位置的元素</span></span><br><span class="line"><span class="keyword">public</span> Object <span class="title function_">set</span><span class="params">(<span class="type">int</span> index,Object element)</span> <span class="comment">//修改指定位置元素的值</span></span><br><span class="line"><span class="keyword">public</span> Object <span class="title function_">get</span><span class="params">(<span class="type">int</span> index)</span> <span class="comment">//获取指定位置元素</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">indexOf</span><span class="params">(Object o)</span> <span class="comment">//获取指定元素的位置</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">contains</span><span class="params">(Object o)</span> <span class="comment">//判断指定元素是否存在</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">//其他常用方法</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">size</span><span class="params">()</span> <span class="comment">//获取容器中元素个数</span></span><br><span class="line"><span class="keyword">public</span> Iterator&lt;E&gt; <span class="title function_">iterator</span><span class="params">()</span> <span class="comment">//获取迭代器</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">clear</span><span class="params">()</span> <span class="comment">//清空元素</span></span><br></pre></td></tr></table></figure><p>ArrayList适合快速查找元素，LinkedList适合频繁地对列表进行增加或删除元素操作，因此LinkedList类可用于实现堆栈和队列，对此LinkedList类中定义了特定的方法，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//模拟栈和队列操作</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addFirst</span><span class="params">(Object o)</span> <span class="comment">//在链表头增添元素</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addLast</span><span class="params">(Object o)</span> <span class="comment">//在链表尾增添元素</span></span><br><span class="line"><span class="keyword">public</span> Object <span class="title function_">removeFirst</span><span class="params">()</span> <span class="comment">//删除链表头元素，并返回该元素</span></span><br><span class="line"><span class="keyword">public</span> Object <span class="title function_">removeLast</span><span class="params">()</span> <span class="comment">//删除链表尾元素，并返回该元素</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isEmpty</span><span class="params">()</span> <span class="comment">//判断链表是否为空</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">push</span><span class="params">(E e)</span> <span class="comment">//等价于addFirst()</span></span><br><span class="line"><span class="keyword">public</span> E <span class="title function_">pop</span><span class="params">()</span> <span class="comment">//等价于removeFirst()</span></span><br><span class="line"><span class="keyword">public</span> E <span class="title function_">getFirst</span><span class="params">()</span> <span class="comment">//获取链表首元素</span></span><br><span class="line"><span class="keyword">public</span> E <span class="title function_">getLast</span><span class="params">()</span> <span class="comment">//获取链表尾元素</span></span><br></pre></td></tr></table></figure><h3 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//增删查方法</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(Object element)</span> <span class="comment">//增添元素</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">remove</span><span class="params">(object element)</span> <span class="comment">//删除元素</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">contains</span><span class="params">(Object o)</span> <span class="comment">//判断元素是否存在</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">//其他常用方法</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">size</span><span class="params">()</span> <span class="comment">//获取容器中元素个数</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isEmpty</span><span class="params">()</span> <span class="comment">//判断集合是否为空</span></span><br><span class="line"><span class="keyword">public</span> Iterator&lt;E&gt; <span class="title function_">iterator</span><span class="params">()</span> <span class="comment">//获取迭代器</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">clear</span><span class="params">()</span> <span class="comment">//清空元素</span></span><br></pre></td></tr></table></figure><h3 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//增删查</span></span><br><span class="line"><span class="keyword">public</span> Object <span class="title function_">put</span><span class="params">(Object key,Object value)</span> <span class="comment">//增添元素</span></span><br><span class="line"><span class="keyword">public</span> Object <span class="title function_">remove</span><span class="params">(Object key)</span> <span class="comment">//删除元素,并返回键对应的值</span></span><br><span class="line"><span class="keyword">public</span> Object <span class="title function_">get</span><span class="params">(Object key)</span> <span class="comment">//获取键对应的值</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">containsKey</span><span class="params">(Object key)</span> <span class="comment">//判断指定键是否存在</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">containsValue</span><span class="params">(Object value)</span> <span class="comment">//判断指定值是否存在</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">//获取键、值、元素集合</span></span><br><span class="line"><span class="keyword">public</span> Collection <span class="title function_">values</span><span class="params">()</span> <span class="comment">//获取值集合</span></span><br><span class="line"><span class="keyword">public</span> Set <span class="title function_">KeySet</span><span class="params">()</span> <span class="comment">//获取键集合</span></span><br><span class="line"><span class="keyword">public</span> Set <span class="title function_">entrySet</span><span class="params">()</span> <span class="comment">//获取元素集合</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">//其他方法</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">size</span><span class="params">()</span> <span class="comment">//获取容器中元素个数</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isEmpty</span><span class="params">()</span> <span class="comment">//判断容器是否为空</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">clear</span><span class="params">()</span> <span class="comment">//清空元素</span></span><br></pre></td></tr></table></figure><p>Map 接口没有提供 iterator() 方法，其子接口 Entry 提供了 iterator() 方法，并且提供了获取键、值的方法，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Map.Entry接口主要方法</span></span><br><span class="line"><span class="keyword">public</span> Iterator&lt;E&gt; <span class="title function_">iterator</span><span class="params">()</span> <span class="comment">//获取迭代器</span></span><br><span class="line"><span class="keyword">public</span> Object <span class="title function_">getKey</span><span class="params">()</span> <span class="comment">//获取键</span></span><br><span class="line"><span class="keyword">public</span> Object <span class="title function_">getValue</span><span class="params">()</span> <span class="comment">//获取值</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">//调用案例</span></span><br><span class="line">Iterator(Entry) iter=map.entrySet().iterator();</span><br><span class="line"><span class="keyword">while</span>(iter.hasNext())&#123;</span><br><span class="line">    Entry entry=iter.next();</span><br><span class="line">    <span class="type">int</span> key=(Integer)entry.getKey();</span><br><span class="line">    <span class="type">int</span> val=(Integer)entry.getValue();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Arrays"><a href="#Arrays" class="headerlink" title="Arrays"></a>Arrays</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">binarySearch</span><span class="params">(Object[] a, Object key)</span> <span class="comment">//二分查找（a已排序）</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">equals</span><span class="params">(Object[] a, Object[] a2)</span> <span class="comment">//判断两数组是否完全一致</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">fill</span><span class="params">(Object[] a, Object val)</span> <span class="comment">//在a中所有位置填充val</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">fill</span><span class="params">(Object[] a, <span class="type">int</span> fromIndex, <span class="type">int</span> toIndex, Object val)</span> <span class="comment">//在[fromIndex,toIndex)中填充元素val</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title function_">toString</span><span class="params">(Object[] a)</span> <span class="comment">//将数组a转换为字符串，如&quot;[1, 2, 3]&quot;</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">sort</span><span class="params">(Object[] a)</span> <span class="comment">//改进的快速排序（升序）</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">sort</span><span class="params">(Object[] a, <span class="type">int</span> fromIndex, <span class="type">int</span> toIndex)</span> <span class="comment">//对[fromIndex,toIndex)中的元素排序（升序）</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="keyword">void</span> <span class="title function_">sort</span><span class="params">(T[] a, Comparator&lt;? <span class="built_in">super</span> T&gt; c)</span> <span class="comment">//自定义比较器排序</span></span><br></pre></td></tr></table></figure><h3 id="HashMap"><a href="#HashMap" class="headerlink" title="HashMap"></a>HashMap</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建 HashMap 对象 Sites</span></span><br><span class="line">HashMap&lt;Integer, String&gt; Sites = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;Integer, String&gt;();</span><br><span class="line"><span class="comment">// 添加键值对</span></span><br><span class="line">Sites.put(<span class="number">1</span>, <span class="string">&quot;Google&quot;</span>);</span><br><span class="line"><span class="comment">//使用 get(key) 方法来获取 key 对应的 value</span></span><br><span class="line"><span class="comment">//remove(key) 方法来删除 key 对应的键值对(key-value)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">clear()<span class="comment">//删除 hashMap 中的所有键/值对</span></span><br><span class="line">clone()<span class="comment">//复制一份 hashMap</span></span><br><span class="line">isEmpty()<span class="comment">//判断 hashMap 是否为空</span></span><br><span class="line">size()<span class="comment">//计算 hashMap 中键/值对的数量</span></span><br><span class="line">put()<span class="comment">//将键/值对添加到 hashMap 中</span></span><br><span class="line">putAll()<span class="comment">//将所有键/值对添加到 hashMap 中</span></span><br><span class="line">putIfAbsent()<span class="comment">//如果 hashMap 中不存在指定的键，则将指定的键/值对插入到 hashMap 中。</span></span><br><span class="line">remove()<span class="comment">//删除 hashMap 中指定键 key 的映射关系</span></span><br><span class="line">containsKey()<span class="comment">//检查 hashMap 中是否存在指定的 key 对应的映射关系。</span></span><br><span class="line">containsValue()<span class="comment">//检查 hashMap 中是否存在指定的 value 对应的映射关系。</span></span><br><span class="line">replace()<span class="comment">//替换 hashMap 中是指定的 key 对应的 value。</span></span><br><span class="line">replaceAll()<span class="comment">//将 hashMap 中的所有映射关系替换成给定的函数所执行的结果。</span></span><br><span class="line">get()<span class="comment">//获取指定 key 对应对 value</span></span><br><span class="line">getOrDefault()<span class="comment">//获取指定 key 对应对 value，如果找不到 key ，则返回设置的默认值</span></span><br><span class="line">forEach()<span class="comment">//对 hashMap 中的每个映射执行指定的操作。</span></span><br><span class="line">entrySet()<span class="comment">//返回 hashMap 中所有映射项的集合集合视图。</span></span><br><span class="line">keySet()<span class="comment">//返回 hashMap 中所有 key 组成的集合视图。</span></span><br><span class="line">values()<span class="comment">//返回 hashMap 中存在的所有 value 值。</span></span><br><span class="line">merge()     <span class="comment">//添加键值对到 hashMap 中</span></span><br><span class="line">compute()<span class="comment">//对 hashMap 中指定 key 的值进行重新计算</span></span><br><span class="line">computeIfAbsent()<span class="comment">//对 hashMap 中指定 key 的值进行重新计算，如果不存在这个 key，则添加到 hasMap 中</span></span><br><span class="line">computeIfPresent()<span class="comment">//对 hashMap 中指定 key 的值进行重新计算，前提是该 key 存在于 hashMap 中。</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch7深度学习计算</title>
      <link href="/2024/06/26/Pytorch7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"/>
      <url>/2024/06/26/Pytorch7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习计算"><a href="#深度学习计算" class="headerlink" title="深度学习计算"></a>深度学习计算</h1><h2 id="块和层"><a href="#块和层" class="headerlink" title="块和层"></a>块和层</h2><p>对于多层感知机而言，整个模型及其组成层都是这种架构。 整个模型接受原始输入（特征），生成输出（预测）， 并包含一些参数（所有组成层的参数集合）。 同样，每个单独的层接收输入（由前一层提供）， 生成输出（到下一层的输入），并且具有一组可调参数， 这些参数根据从下一层反向传播的信号进行更新。</p><p>事实证明，研究讨论“比单个层大”但“比整个模型小”的组件更有价值。 例如，在计算机视觉中广泛流行的ResNet-152架构就有数百层， 这些层是由<em>层组</em>（groups of layers）的重复模式组成。 这个ResNet架构赢得了2015年ImageNet和COCO计算机视觉比赛 的识别和检测任务 (<a href="https://zh-v2.d2l.ai/chapter_references/zreferences.html#id60">He <em>et al.</em>, 2016</a>)。 目前ResNet架构仍然是许多视觉任务的首选架构。 在其他的领域，如自然语言处理和语音， 层组以各种重复模式排列的类似架构现在也是普遍存在。</p><p>为了实现这些复杂的网络，我们引入了神经网络<em>块</em>的概念。 <em>块</em>（block）可以描述单个层、由多个层组成的组件或整个模型本身。 使用块进行抽象的一个好处是可以将一些块组合成更大的组件， 这一过程通常是递归的，如下图所示。 通过定义代码来按需生成任意复杂度的块， 我们可以通过简洁的代码实现复杂的神经网络。</p><p><img src="/../img/Pytorch1/pytorch7/1.png" alt="1"></p><p>从编程的角度来看，块由<em>类</em>（class）表示。 它的任何子类都必须定义一个将其输入转换为输出的前向传播函数， 并且必须存储任何必需的参数。 注意，有些块不需要任何参数。 最后，为了计算梯度，块必须具有反向传播函数。 在定义我们自己的块时，由于自动微分提供了一些后端实现，我们只需要考虑前向传播函数和必需的参数。</p><p>在构造自定义块之前，我们先回顾一下多层感知机的代码。 下面的代码生成一个网络，其中包含一个具有256个单元和ReLU激活函数的全连接隐藏层， 然后是一个具有10个隐藏单元且不带激活函数的全连接输出层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(nn.Linear(<span class="number">20</span>, <span class="number">256</span>), nn.ReLU(), nn.Linear(<span class="number">256</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">X = torch.rand(<span class="number">2</span>, <span class="number">20</span>)</span><br><span class="line">net(X)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">0.0343</span>,  <span class="number">0.0264</span>,  <span class="number">0.2505</span>, -<span class="number">0.0243</span>,  <span class="number">0.0945</span>,  <span class="number">0.0012</span>, -<span class="number">0.0141</span>,  <span class="number">0.0666</span>,</span><br><span class="line">         -<span class="number">0.0547</span>, -<span class="number">0.0667</span>],</span><br><span class="line">        [ <span class="number">0.0772</span>, -<span class="number">0.0274</span>,  <span class="number">0.2638</span>, -<span class="number">0.0191</span>,  <span class="number">0.0394</span>, -<span class="number">0.0324</span>,  <span class="number">0.0102</span>,  <span class="number">0.0707</span>,</span><br><span class="line">         -<span class="number">0.1481</span>, -<span class="number">0.1031</span>]], grad_fn=&lt;AddmmBackward0&gt;)</span><br></pre></td></tr></table></figure><p>在这个例子中，我们通过实例化<code>nn.Sequential</code>来构建我们的模型， 层的执行顺序是作为参数传递的。 简而言之，<code>nn.Sequential</code>定义了一种特殊的<code>Module</code>， 即在PyTorch中表示一个块的类， 它维护了一个由<code>Module</code>组成的有序列表。 注意，两个全连接层都是<code>Linear</code>类的实例， <code>Linear</code>类本身就是<code>Module</code>的子类。 另外，到目前为止，我们一直在通过<code>net(X)</code>调用我们的模型来获得模型的输出。 这实际上是<code>net.__call__(X)</code>的简写。 这个前向传播函数非常简单： 它将列表中的每个块连接在一起，将每个块的输出作为下一个块的输入。</p><h2 id="自定义块"><a href="#自定义块" class="headerlink" title="自定义块"></a>自定义块</h2><p>要想直观地了解块是如何工作的，最简单的方法就是自己实现一个。 在实现我们自定义块之前，我们简要总结一下每个块必须提供的基本功能。</p><ol><li>将输入数据作为其前向传播函数的参数。</li><li>通过前向传播函数来生成输出。请注意，输出的形状可能与输入的形状不同。例如，我们上面模型中的第一个全连接的层接收一个20维的输入，但是返回一个维度为256的输出。</li><li>计算其输出关于输入的梯度，可通过其反向传播函数进行访问。通常这是自动发生的。</li><li>存储和访问前向传播计算所需的参数。</li><li>根据需要初始化模型参数。</li></ol><p>从零编写一个块，它包含一个多层感知机，其具有256个隐藏单元的隐藏层和一个10维输出层。 注意，下面的<code>MLP</code>类继承了表示块的类。 我们的实现只需要提供我们自己的构造函数（Python中的<code>__init__</code>函数）和前向传播函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line">    <span class="comment"># 用模型参数声明层。这里，我们声明两个全连接的层</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 调用MLP的父类Module的构造函数来执行必要的初始化。</span></span><br><span class="line">        <span class="comment"># 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.hidden = nn.Linear(<span class="number">20</span>, <span class="number">256</span>)  <span class="comment"># 隐藏层</span></span><br><span class="line">        self.out = nn.Linear(<span class="number">256</span>, <span class="number">10</span>)  <span class="comment"># 输出层</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义模型的前向传播，即如何根据输入X返回所需的模型输出</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义。</span></span><br><span class="line">        <span class="keyword">return</span> self.out(F.relu(self.hidden(X)))</span><br></pre></td></tr></table></figure><p>我们首先看一下前向传播函数，它以<code>X</code>作为输入， 计算带有激活函数的隐藏表示，并输出其未规范化的输出值。 在这个<code>MLP</code>实现中，两个层都是实例变量。 要了解这为什么是合理的，可以想象实例化两个多层感知机（<code>net1</code>和<code>net2</code>）， 并根据不同的数据对它们进行训练。 当然，我们希望它们学到两种不同的模型。</p><p>接着我们实例化多层感知机的层，然后在每次调用前向传播函数时调用这些层。 注意一些关键细节： 首先，我们定制的<code>__init__</code>函数通过<code>super().__init__()</code> 调用父类的<code>__init__</code>函数， 省去了重复编写模版代码的痛苦。 然后，我们实例化两个全连接层， 分别为<code>self.hidden</code>和<code>self.out</code>。 注意，除非我们实现一个新的运算符， 否则我们不必担心反向传播函数或参数初始化， 系统将自动生成这些。</p><p>我们来试一下这个函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net = MLP()</span><br><span class="line">net(X)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">0.0669</span>,  <span class="number">0.2202</span>, -<span class="number">0.0912</span>, -<span class="number">0.0064</span>,  <span class="number">0.1474</span>, -<span class="number">0.0577</span>, -<span class="number">0.3006</span>,  <span class="number">0.1256</span>,</span><br><span class="line">         -<span class="number">0.0280</span>,  <span class="number">0.4040</span>],</span><br><span class="line">        [ <span class="number">0.0545</span>,  <span class="number">0.2591</span>, -<span class="number">0.0297</span>,  <span class="number">0.1141</span>,  <span class="number">0.1887</span>,  <span class="number">0.0094</span>, -<span class="number">0.2686</span>,  <span class="number">0.0732</span>,</span><br><span class="line">         -<span class="number">0.0135</span>,  <span class="number">0.3865</span>]], grad_fn=&lt;AddmmBackward0&gt;)</span><br></pre></td></tr></table></figure><p>块的一个主要优点是它的多功能性。 我们可以子类化块以创建层（如全连接层的类）、 整个模型（如上面的<code>MLP</code>类）或具有中等复杂度的各种组件。 我们在接下来的章节中充分利用了这种多功能性， 比如在处理卷积神经网络时。</p><h2 id="顺序块"><a href="#顺序块" class="headerlink" title="顺序块"></a>顺序块</h2><p>现在我们可以更仔细地看看<code>Sequential</code>类是如何工作的， 回想一下<code>Sequential</code>的设计是为了把其他模块串起来。 为了构建我们自己的简化的<code>MySequential</code>， 我们只需要定义两个关键函数：</p><ol><li>一种将块逐个追加到列表中的函数；</li><li>一种前向传播函数，用于将输入按追加块的顺序传递给块组成的“链条”。</li></ol><p>下面的<code>MySequential</code>类提供了与默认<code>Sequential</code>类相同的功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MySequential</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, *args</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">for</span> idx, module <span class="keyword">in</span> <span class="built_in">enumerate</span>(args):</span><br><span class="line">            <span class="comment"># 这里，module是Module子类的一个实例。我们把它保存在&#x27;Module&#x27;类的成员</span></span><br><span class="line">            <span class="comment"># 变量_modules中。_module的类型是OrderedDict</span></span><br><span class="line">            self._modules[<span class="built_in">str</span>(idx)] = module</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># OrderedDict保证了按照成员添加的顺序遍历它们</span></span><br><span class="line">        <span class="keyword">for</span> block <span class="keyword">in</span> self._modules.values():</span><br><span class="line">            X = block(X)</span><br><span class="line">        <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure><p><code>__init__</code>函数将每个模块逐个添加到有序字典<code>_modules</code>中。 读者可能会好奇为什么每个<code>Module</code>都有一个<code>_modules</code>属性？ 以及为什么我们使用它而不是自己定义一个Python列表？ 简而言之，<code>_modules</code>的主要优点是： 在模块的参数初始化过程中， 系统知道在<code>_modules</code>字典中查找需要初始化参数的子块。</p><p>当<code>MySequential</code>的前向传播函数被调用时， 每个添加的块都按照它们被添加的顺序执行。 现在可以使用我们的<code>MySequential</code>类重新实现多层感知机。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net = MySequential(nn.Linear(<span class="number">20</span>, <span class="number">256</span>), nn.ReLU(), nn.Linear(<span class="number">256</span>, <span class="number">10</span>))</span><br><span class="line">net(X)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">2.2759e-01</span>, -<span class="number">4.7003e-02</span>,  <span class="number">4.2846e-01</span>, -<span class="number">1.2546e-01</span>,  <span class="number">1.5296e-01</span>,</span><br><span class="line">          <span class="number">1.8972e-01</span>,  <span class="number">9.7048e-02</span>,  <span class="number">4.5479e-04</span>, -<span class="number">3.7986e-02</span>,  <span class="number">6.4842e-02</span>],</span><br><span class="line">        [ <span class="number">2.7825e-01</span>, -<span class="number">9.7517e-02</span>,  <span class="number">4.8541e-01</span>, -<span class="number">2.4519e-01</span>, -<span class="number">8.4580e-02</span>,</span><br><span class="line">          <span class="number">2.8538e-01</span>,  <span class="number">3.6861e-02</span>,  <span class="number">2.9411e-02</span>, -<span class="number">1.0612e-01</span>,  <span class="number">1.2620e-01</span>]],</span><br><span class="line">       grad_fn=&lt;AddmmBackward0&gt;)</span><br></pre></td></tr></table></figure><h2 id="在前向传播函数中执行代码"><a href="#在前向传播函数中执行代码" class="headerlink" title="在前向传播函数中执行代码"></a>在前向传播函数中执行代码</h2><p><code>Sequential</code>类使模型构造变得简单， 允许我们组合新的架构，而不必定义自己的类。 然而，并不是所有的架构都是简单的顺序架构。 当需要更强的灵活性时，我们需要定义自己的块。 例如，我们可能希望在前向传播函数中执行Python的控制流。 此外，我们可能希望执行任意的数学运算， 而不是简单地依赖预定义的神经网络层。</p><p>到目前为止， 我们网络中的所有操作都对网络的激活值及网络的参数起作用。 然而，有时我们可能希望合并既不是上一层的结果也不是可更新参数的项， 我们称之为<em>常数参数</em>（constant parameter）。 例如，我们需要一个计算函数 𝑓(𝑥,𝑤)&#x3D;𝑐⋅𝑤⊤𝑥的层， 其中𝑥是输入， 𝑤是参数， 𝑐是某个在优化过程中没有更新的指定常量。 因此我们实现了一个<code>FixedHiddenMLP</code>类，如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FixedHiddenMLP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 不计算梯度的随机权重参数。因此其在训练期间保持不变</span></span><br><span class="line">        self.rand_weight = torch.rand((<span class="number">20</span>, <span class="number">20</span>), requires_grad=<span class="literal">False</span>)</span><br><span class="line">        self.linear = nn.Linear(<span class="number">20</span>, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        X = self.linear(X)</span><br><span class="line">        <span class="comment"># 使用创建的常量参数以及relu和mm函数</span></span><br><span class="line">        X = F.relu(torch.mm(X, self.rand_weight) + <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 复用全连接层。这相当于两个全连接层共享参数</span></span><br><span class="line">        X = self.linear(X)</span><br><span class="line">        <span class="comment"># 控制流</span></span><br><span class="line">        <span class="keyword">while</span> X.<span class="built_in">abs</span>().<span class="built_in">sum</span>() &gt; <span class="number">1</span>:</span><br><span class="line">            X /= <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> X.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure><p>在这个<code>FixedHiddenMLP</code>模型中，我们实现了一个隐藏层， 其权重（<code>self.rand_weight</code>）在实例化时被随机初始化，之后为常量。 这个权重不是一个模型参数，因此它永远不会被反向传播更新。 然后，神经网络将这个固定层的输出通过一个全连接层。</p><p>注意，在返回输出之前，模型做了一些不寻常的事情： 它运行了一个while循环，在𝐿1范数大于1的条件下， 将输出向量除以2，直到它满足条件为止。 最后，模型返回了<code>X</code>中所有项的和。 注意，此操作可能不会常用于在任何实际任务中， 我们只展示如何将任意代码集成到神经网络计算的流程中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net = FixedHiddenMLP()</span><br><span class="line">net(X)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="number">0.1862</span>, grad_fn=&lt;SumBackward0&gt;)</span><br></pre></td></tr></table></figure><p>我们可以混合搭配各种组合块的方法。 在下面的例子中，我们以一些想到的方法嵌套块。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NestMLP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.net = nn.Sequential(nn.Linear(<span class="number">20</span>, <span class="number">64</span>), nn.ReLU(),</span><br><span class="line">                                 nn.Linear(<span class="number">64</span>, <span class="number">32</span>), nn.ReLU())</span><br><span class="line">        self.linear = nn.Linear(<span class="number">32</span>, <span class="number">16</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="keyword">return</span> self.linear(self.net(X))</span><br><span class="line"></span><br><span class="line">chimera = nn.Sequential(NestMLP(), nn.Linear(<span class="number">16</span>, <span class="number">20</span>), FixedHiddenMLP())</span><br><span class="line">chimera(X)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="number">0.2183</span>, grad_fn=&lt;SumBackward0&gt;)</span><br></pre></td></tr></table></figure><h2 id="参数管理"><a href="#参数管理" class="headerlink" title="参数管理"></a>参数管理</h2><ul><li>访问管理—&gt;调试，诊断和可视化</li><li>参数初始化</li><li>在不同模型组件之间共享参数</li></ul><p>先以一个单层隐藏层的多层感知机为例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">inport nn <span class="keyword">from</span> torch</span><br><span class="line"></span><br><span class="line">net = nn Sequential(nn.Linear(<span class="number">4</span>,<span class="number">8</span>),nn.ReLU(),nn.Linear(<span class="number">8</span>,<span class="number">1</span>));</span><br><span class="line">X =torch.rand(size=(<span class="number">2</span>,<span class="number">4</span>));      //输入为一个形状为(<span class="number">2</span>, <span class="number">4</span>)的张量，表示一个批次中有两个样本，每个样本有<span class="number">4</span>个特征。</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[-<span class="number">0.0970</span>],</span><br><span class="line">        [-<span class="number">0.0827</span>]], grad_fn=&lt;AddmmBackward0&gt;)          </span><br></pre></td></tr></table></figure><p><code>grad_fn=&lt;AddmmBackward0&gt;</code>这部分信息表示这个张量有一个与之关联的梯度函数（在这个情况下是<code>AddmmBackward0</code>），这通常意味着这个张量是通过一个需要梯度的操作（如反向传播）得到的。在PyTorch中，当你进行自动微分（autograd）时，每个计算图（computation graph）中的张量都会与一个梯度函数相关联，以便在需要时可以计算梯度。</p><p>由于调用了<code>nn.Linear</code>层，这些层在定义时默认启用了<code>requires_grad=True</code>（除非明确设置为<code>False</code>），因此对这些层进行前向传播时，输出的张量也会有一个与之关联的梯度函数。</p><h3 id="参数访问"><a href="#参数访问" class="headerlink" title="参数访问"></a>参数访问</h3><p>当通过<code>Sequential</code>类定义模型时， 我们可以通过索引来访问模型的任意层</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(net.state_dict())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">OrderedDict([(<span class="string">&#x27;weight&#x27;</span>, tensor([[-<span class="number">0.0427</span>, -<span class="number">0.2939</span>, -<span class="number">0.1894</span>,  <span class="number">0.0220</span>, -<span class="number">0.1709</span>, -<span class="number">0.1522</span>, -<span class="number">0.0334</span>, -<span class="number">0.2263</span>]])), (<span class="string">&#x27;bias&#x27;</span>, tensor([<span class="number">0.0887</span>]))])</span><br></pre></td></tr></table></figure><p>这个全连接层包含两个参数，分别是该层的权重和偏置。 两者都存储为单精度浮点数（float32）。 注意，参数名称允许唯一标识每个参数，即使在包含数百个层的网络中也是如此。</p><h4 id="目标参数"><a href="#目标参数" class="headerlink" title="目标参数"></a>目标参数</h4><p>每个参数都表示为参数类的一个实例。 要对参数执行任何操作，首先我们需要访问底层的数值。 有几种方法可以做到这一点。有些比较简单，而另一些则比较通用。 下面的代码从第二个全连接层（即第三个神经网络层）提取偏置， 提取后返回的是一个参数类实例，并进一步访问该参数的值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(net[<span class="number">2</span>].bias))  <span class="comment"># 打印偏置的类型  </span></span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">2</span>].bias)        <span class="comment"># 打印偏置对象，包括grad_fn（如果有的话）  </span></span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">2</span>].bias.data)   <span class="comment"># 打印偏置的数据（不包括grad_fn）</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;torch.nn.parameter.Parameter&#x27;</span>&gt;</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([<span class="number">0.0887</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">tensor([<span class="number">0.0887</span>])</span><br></pre></td></tr></table></figure><p>参数是复合的对象，包含值、梯度和额外信息。 这就是我们需要显式参数值的原因。 除了值之外，我们还可以访问每个参数的梯度。 在上面这个网络中，由于我们还没有调用反向传播，所以参数的梯度处于初始状态。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net[<span class="number">2</span>].weight.grad == <span class="literal">None</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure><h4 id="一次性访问所有参数"><a href="#一次性访问所有参数" class="headerlink" title="一次性访问所有参数"></a>一次性访问所有参数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(*[(name, param.shape) <span class="keyword">for</span> name, param <span class="keyword">in</span> net[<span class="number">0</span>].named_parameters()])</span><br><span class="line"><span class="built_in">print</span>(*[(name, param.shape) <span class="keyword">for</span> name, param <span class="keyword">in</span> net.named_parameters()])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(<span class="string">&#x27;weight&#x27;</span>, torch.Size([<span class="number">8</span>, <span class="number">4</span>])) (<span class="string">&#x27;bias&#x27;</span>, torch.Size([<span class="number">8</span>]))</span><br><span class="line">(<span class="string">&#x27;0.weight&#x27;</span>, torch.Size([<span class="number">8</span>, <span class="number">4</span>])) (<span class="string">&#x27;0.bias&#x27;</span>, torch.Size([<span class="number">8</span>])) (<span class="string">&#x27;2.weight&#x27;</span>, torch.Size([<span class="number">1</span>, <span class="number">8</span>])) (<span class="string">&#x27;2.bias&#x27;</span>, torch.Size([<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><p>另一种访问网络参数的方式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.state_dict()[<span class="string">&#x27;2.bias&#x27;</span>].data</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">0.0887</span>])</span><br></pre></td></tr></table></figure><h4 id="从嵌套块收集参数"><a href="#从嵌套块收集参数" class="headerlink" title="从嵌套块收集参数"></a>从嵌套块收集参数</h4><p>首先定义一个生成块的函数（可以说是“块工厂”），然后将这些块组合到更大的块中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">block1</span>():</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(nn.Linear(<span class="number">4</span>, <span class="number">8</span>), nn.ReLU(),</span><br><span class="line">                         nn.Linear(<span class="number">8</span>, <span class="number">4</span>), nn.ReLU())</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">block2</span>():</span><br><span class="line">    net = nn.Sequential()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        <span class="comment"># 在这里嵌套</span></span><br><span class="line">        net.add_module(<span class="string">f&#x27;block <span class="subst">&#123;i&#125;</span>&#x27;</span>, block1())</span><br><span class="line">    <span class="keyword">return</span> net</span><br><span class="line"></span><br><span class="line">rgnet = nn.Sequential(block2(), nn.Linear(<span class="number">4</span>, <span class="number">1</span>))</span><br><span class="line">rgnet(X)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">0.2596</span>],</span><br><span class="line">        [<span class="number">0.2596</span>]], grad_fn=&lt;AddmmBackward0&gt;)</span><br></pre></td></tr></table></figure><p>设计了网络后，查看一下它是如何工作的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(rgnet)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Sequential(</span><br><span class="line">    (block <span class="number">0</span>): Sequential(</span><br><span class="line">      (<span class="number">0</span>): Linear(in_features=<span class="number">4</span>, out_features=<span class="number">8</span>, bias=<span class="literal">True</span>)</span><br><span class="line">      (<span class="number">1</span>): ReLU()</span><br><span class="line">      (<span class="number">2</span>): Linear(in_features=<span class="number">8</span>, out_features=<span class="number">4</span>, bias=<span class="literal">True</span>)</span><br><span class="line">      (<span class="number">3</span>): ReLU()</span><br><span class="line">    )</span><br><span class="line">    (block <span class="number">1</span>): Sequential(</span><br><span class="line">      (<span class="number">0</span>): Linear(in_features=<span class="number">4</span>, out_features=<span class="number">8</span>, bias=<span class="literal">True</span>)</span><br><span class="line">      (<span class="number">1</span>): ReLU()</span><br><span class="line">      (<span class="number">2</span>): Linear(in_features=<span class="number">8</span>, out_features=<span class="number">4</span>, bias=<span class="literal">True</span>)</span><br><span class="line">      (<span class="number">3</span>): ReLU()</span><br><span class="line">    )</span><br><span class="line">    (block <span class="number">2</span>): Sequential(</span><br><span class="line">      (<span class="number">0</span>): Linear(in_features=<span class="number">4</span>, out_features=<span class="number">8</span>, bias=<span class="literal">True</span>)</span><br><span class="line">      (<span class="number">1</span>): ReLU()</span><br><span class="line">      (<span class="number">2</span>): Linear(in_features=<span class="number">8</span>, out_features=<span class="number">4</span>, bias=<span class="literal">True</span>)</span><br><span class="line">      (<span class="number">3</span>): ReLU()</span><br><span class="line">    )</span><br><span class="line">    (block <span class="number">3</span>): Sequential(</span><br><span class="line">      (<span class="number">0</span>): Linear(in_features=<span class="number">4</span>, out_features=<span class="number">8</span>, bias=<span class="literal">True</span>)</span><br><span class="line">      (<span class="number">1</span>): ReLU()</span><br><span class="line">      (<span class="number">2</span>): Linear(in_features=<span class="number">8</span>, out_features=<span class="number">4</span>, bias=<span class="literal">True</span>)</span><br><span class="line">      (<span class="number">3</span>): ReLU()</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (<span class="number">1</span>): Linear(in_features=<span class="number">4</span>, out_features=<span class="number">1</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>因为层是分层嵌套的，所以我们也可以像通过嵌套列表索引一样访问它们。 下面，我们访问第一个主要的块中、第二个子块的第一层的偏置项。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rgnet[<span class="number">0</span>][<span class="number">1</span>][<span class="number">0</span>].bias.data</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([ <span class="number">0.1999</span>, -<span class="number">0.4073</span>, -<span class="number">0.1200</span>, -<span class="number">0.2033</span>, -<span class="number">0.1573</span>,  <span class="number">0.3546</span>, -<span class="number">0.2141</span>, -<span class="number">0.2483</span>])</span><br></pre></td></tr></table></figure><h3 id="参数初始化"><a href="#参数初始化" class="headerlink" title="参数初始化"></a>参数初始化</h3><p>默认情况下，PyTorch会根据一个范围均匀地初始化权重和偏置矩阵， 这个范围是根据输入和输出维度计算出的。 PyTorch的<code>nn.init</code>模块提供了多种预置初始化方法。</p><h4 id="内置初始化"><a href="#内置初始化" class="headerlink" title="内置初始化"></a>内置初始化</h4><p>调用内置的初始化器。 下面的代码将所有权重参数初始化为标准差为0.01的高斯随机变量， 且将偏置参数设置为0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_normal</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        nn.init.normal_(m.weight, mean=<span class="number">0</span>, std=<span class="number">0.01</span>)</span><br><span class="line">        nn.init.zeros_(m.bias)</span><br><span class="line">net.apply(init_normal)</span><br><span class="line">net[<span class="number">0</span>].weight.data[<span class="number">0</span>], net[<span class="number">0</span>].bias.data[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([-<span class="number">0.0214</span>, -<span class="number">0.0015</span>, -<span class="number">0.0100</span>, -<span class="number">0.0058</span>]), tensor(<span class="number">0.</span>))</span><br></pre></td></tr></table></figure><p>还可以将所有参数初始化为给定的常数，比如初始化为1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_constant</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        nn.init.constant_(m.weight, <span class="number">1</span>)</span><br><span class="line">        nn.init.zeros_(m.bias)</span><br><span class="line">net.apply(init_constant)</span><br><span class="line">net[<span class="number">0</span>].weight.data[<span class="number">0</span>], net[<span class="number">0</span>].bias.data[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]), tensor(<span class="number">0.</span>))</span><br></pre></td></tr></table></figure><h2 id="读写文件"><a href="#读写文件" class="headerlink" title="读写文件"></a>读写文件</h2><p>加载和存储权重向量和整个模型</p><h3 id="加载和保存张量"><a href="#加载和保存张量" class="headerlink" title="加载和保存张量"></a>加载和保存张量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">x = torch.arange(<span class="number">4</span>)</span><br><span class="line">torch.save(x, <span class="string">&#x27;x-file&#x27;</span>)</span><br></pre></td></tr></table></figure><p>现在可以将存储在文件中的数据读回内存。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x2 = torch.load(<span class="string">&#x27;x-file&#x27;</span>)</span><br><span class="line">x2</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><p>可以存储一个张量列表，然后把它们读回内存。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y = torch.zeros(<span class="number">4</span>)</span><br><span class="line">torch.save([x, y],<span class="string">&#x27;x-files&#x27;</span>)</span><br><span class="line">x2, y2 = torch.load(<span class="string">&#x27;x-files&#x27;</span>)</span><br><span class="line">(x2, y2)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]), tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]))</span><br></pre></td></tr></table></figure><p>甚至可以写入或读取从字符串映射到张量的字典。 当我们要读取或写入模型中的所有权重时，这很方便</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mydict = &#123;<span class="string">&#x27;x&#x27;</span>: x, <span class="string">&#x27;y&#x27;</span>: y&#125;</span><br><span class="line">torch.save(mydict, <span class="string">&#x27;mydict&#x27;</span>)</span><br><span class="line">mydict2 = torch.load(<span class="string">&#x27;mydict&#x27;</span>)</span><br><span class="line">mydict2</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;x&#x27;</span>: tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]), <span class="string">&#x27;y&#x27;</span>: tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>])&#125;</span><br></pre></td></tr></table></figure><h3 id="加载和保存模型参数"><a href="#加载和保存模型参数" class="headerlink" title="加载和保存模型参数"></a>加载和保存模型参数</h3><p>将模型的参数存储在一个叫做“mlp.params”的文件中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(net.state_dict(), <span class="string">&#x27;mlp.params&#x27;</span>)</span><br></pre></td></tr></table></figure><p>为了恢复模型，我们实例化了原始多层感知机模型的一个备份。 这里我们不需要随机初始化模型参数，而是直接读取文件中存储的参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">clone = MLP()</span><br><span class="line">clone.load_state_dict(torch.load(<span class="string">&#x27;mlp.params&#x27;</span>))</span><br><span class="line">clone.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">MLP(</span><br><span class="line">  (hidden): Linear(in_features=<span class="number">20</span>, out_features=<span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (output): Linear(in_features=<span class="number">256</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!nvidia-smi</span><br></pre></td></tr></table></figure><p>在PyTorch中，每个数组都有一个设备（device）， 我们通常将其称为环境（context）。 默认情况下，所有变量和相关的计算都分配给CPU。 有时环境可能是GPU。 当我们跨多个服务器部署作业时，事情会变得更加棘手。 通过智能地将数组分配给环境， 我们可以最大限度地减少在设备之间传输数据的时间。 例如，当在带有GPU的服务器上训练神经网络时， 我们通常希望模型的参数在GPU上。</p><h3 id="计算设备"><a href="#计算设备" class="headerlink" title="计算设备"></a>计算设备</h3><p>在PyTorch中，CPU和GPU可以用<code>torch.device(&#39;cpu&#39;)</code> 和<code>torch.device(&#39;cuda&#39;)</code>表示。 应该注意的是，<code>cpu</code>设备意味着所有物理CPU和内存， 这意味着PyTorch的计算将尝试使用所有CPU核心。 然而，<code>gpu</code>设备只代表一个卡和相应的显存。 如果有多个GPU，我们使用<code>torch.device(f&#39;cuda:&#123;i&#125;&#39;)</code> 来表示第𝑖块GPU（𝑖从0开始）。 另外，<code>cuda:0</code>和<code>cuda</code>是等价的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">torch.device(<span class="string">&#x27;cpu&#x27;</span>), torch.device(<span class="string">&#x27;cuda&#x27;</span>), torch.device(<span class="string">&#x27;cuda:1&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(device(<span class="built_in">type</span>=<span class="string">&#x27;cpu&#x27;</span>), device(<span class="built_in">type</span>=<span class="string">&#x27;cuda&#x27;</span>), device(<span class="built_in">type</span>=<span class="string">&#x27;cuda&#x27;</span>, index=<span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>我们可以查询可用gpu的数量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cuda.device_count()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure><h3 id="张量与GPU"><a href="#张量与GPU" class="headerlink" title="张量与GPU"></a>张量与GPU</h3><p>我们可以查询张量所在的设备。 默认在CPU上创建的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">x.device</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">device(<span class="built_in">type</span>=<span class="string">&#x27;cpu&#x27;</span>)</span><br></pre></td></tr></table></figure><p>无论何时我们要对多个项进行操作， 它们都必须在同一个设备上。 例如，如果我们对两个张量求和， 我们需要确保两个张量都位于同一个设备上， 否则框架将不知道在哪里存储结果，甚至不知道在哪里执行计算。</p><h4 id="存储在GPU上"><a href="#存储在GPU上" class="headerlink" title="存储在GPU上"></a>存储在GPU上</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = torch.ones(<span class="number">2</span>, <span class="number">3</span>, device=try_gpu())</span><br><span class="line">X</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]], device=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="神经网络与GPU"><a href="#神经网络与GPU" class="headerlink" title="神经网络与GPU"></a>神经网络与GPU</h3><p>下面的代码将模型参数放在GPU上。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(nn.Linear(<span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line">net = net.to(device=try_gpu())</span><br></pre></td></tr></table></figure><p>输入为GPU上的张量时，模型将在同一GPU上计算结果。</p><p>让我们确认模型参数存储在同一个GPU上。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net[<span class="number">0</span>].weight.data.device</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">device(<span class="built_in">type</span>=<span class="string">&#x27;cuda&#x27;</span>, index=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h2 id="总结：-PyTorch构建神经网络的主要工具"><a href="#总结：-PyTorch构建神经网络的主要工具" class="headerlink" title="总结： PyTorch构建神经网络的主要工具"></a>总结： PyTorch构建神经网络的主要工具</h2><p>使用PyTorch构建神经网络使用的主要工具（或类）及相互关系</p><p><img src="/../img/Pytorch1/pytorch7/2.png" alt="2"></p><p>从图中可知，可以基于Module类或函数（nn.functional）构建网络层。nn中的大多数层（layer）在functional中都有与之对应的函数。nn.functional中的函数与nn.Module中的layer的主要区别是后者继承自Module类，可自动提取可学习的参数，而nn.functional更像是纯函数。两者功能相同，性能也没有很大区别，那么如何选择呢？卷积层、全连接层、dropout层等含有可学习参数，一般使用nn.Module，而激活函数、池化层不含可学习参数，可以使用nn.functional中对应的函数。</p><h3 id="nn-Module"><a href="#nn-Module" class="headerlink" title="nn.Module"></a>nn.Module</h3><p>nn是一个有效工具。它是专门为深度学习设计的一个模块，而nn.Module是nn的一个核心数据结构。nn.Module可以是神经网络的某个层，也可以是包含多层的神经网络。在实际使用中，最常见的做法是继承nn.Module，生成自己的网络&#x2F;层。nn中已实现了绝大多数层，包括全连接层、损失层、激活层、卷积层、循环层等。这些层都是nn.Module的子类，能够自动检测到自己的参数，并将其作为学习参数，且针对GPU运行进行了CuDNN优化。</p><h3 id="nn-functional"><a href="#nn-functional" class="headerlink" title="nn.functional"></a>nn.functional</h3><p>nn中的层，一类是继承了nn.Module，其命名一般为nn.Xxx（第一个是大写），如nn.Linear、nn.Conv2d、nn.CrossEntropyLoss等。另一类是nn.functional中的函数，其名称一般为nn.funtional.xxx，如nn.funtional.linear、nn.funtional.conv2d、nn.funtional.cross_entropy等。从功能来说两者相当，基于nn.Mudle能实现的层，也可以基于nn.funtional实现</p><p>不过在具体使用时，两者还是有区别的，主要区别如下。</p><ol><li>nn.Xxx继承于nn.Module，nn.Xxx 需要先实例化并传入参数，然后以函数调用的方式调用实例化的对象并传入输入数据。它能够很好的与nn.Sequential结合使用，而nn.functional.xxx无法与nn.Sequential结合使用。</li><li>nn.Xxx不需要自己定义和管理weight、bias参数；而nn.functional.xxx需要你自己定义weight、bias，每次调用的时候都需要手动传入weight、bias等参数, 不利于代码复用。</li><li>dropout操作在训练和测试阶段是有区别的，使用nn.Xxx方式定义dropout，在调用model.eval()之后，自动实现状态的转换，而使用nn.functional.xxx却无此功能。</li></ol><p>总的来说，两种功能都是相同的，但PyTorch官方推荐：具有学习参数的（例如，conv2d、 linear、batch_norm、dropout等）情况采用nn.Xxx方式，没有学习参数的（例如，maxpool, loss func, activation func）等情况选择使用nn.functional.xxx或者nn.Xxx方式。3.5节中使用激活层，我们采用无学习参数的F.relu方式来实现，即nn.functional.xxx方式。</p><h3 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h3><p>PyTorch构建模型大致有以下3种方式。</p><ol><li>继承nn.Module基类构建模型。</li><li>使用nn.Sequential按层顺序构建模型。</li><li>继承nn.Module基类构建模型，又使用相关模型容器(如nn.Sequential,nn.ModuleList,nn.ModuleDict等）进行封装。</li></ol><p>在这3种方法中，第1种方式最为常见；第2种方式比较简单，非常适合与初学者；第3种方式较灵活但复杂一些。</p><h4 id="继承nn-Module基类构建模型"><a href="#继承nn-Module基类构建模型" class="headerlink" title="继承nn.Module基类构建模型"></a>继承nn.Module基类构建模型</h4><p>先定义一个类，使之继承nn.Module基类。把模型中需要用到的层放在构造函数__init__()中，在forward方法中实现模型的正向传播。具体代码如下。</p><ol><li>导入模块</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br></pre></td></tr></table></figure><ol start="2"><li>构建模型</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Model_Seq</span>(nn.Module):</span><br><span class="line">   <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">   通过继承基类nn.Module来构建模型</span></span><br><span class="line"><span class="string">   &quot;&quot;&quot;</span></span><br><span class="line">   <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, n_hidden_1, n_hidden_2, out_dim</span>):</span><br><span class="line">       <span class="built_in">super</span>(Model_Seq, self).__init__()</span><br><span class="line">       self.flatten = nn.Flatten()</span><br><span class="line">       self.linear1= nn.Linear(in_dim, n_hidden_1)</span><br><span class="line">       self.bn1=nn.BatchNorm1d(n_hidden_1)</span><br><span class="line">       self.linear2= nn.Linear(n_hidden_1, n_hidden_2)</span><br><span class="line">       self.bn2 = nn.BatchNorm1d(n_hidden_2)</span><br><span class="line">       self.out = nn.Linear(n_hidden_2, out_dim)</span><br><span class="line">       </span><br><span class="line"></span><br><span class="line">   <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">       x=self.flatten(x)</span><br><span class="line">       x=self.linear1(x)</span><br><span class="line">       x=self.bn1(x)</span><br><span class="line">       x = F.relu(x)</span><br><span class="line">       x=self.linear2(x)</span><br><span class="line">       x=self.bn2(x)</span><br><span class="line">       x = F.relu(x)</span><br><span class="line">       x=self.out(x)</span><br><span class="line">       x = F.softmax(x,dim=<span class="number">1</span>)</span><br><span class="line">       <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>3.查看模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##对一些超参数赋值</span></span><br><span class="line">in_dim, n_hidden_1, n_hidden_2, out_dim=<span class="number">28</span> * <span class="number">28</span>, <span class="number">300</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line">model_seq= Model_Seq(in_dim, n_hidden_1, n_hidden_2, out_dim)</span><br><span class="line"><span class="built_in">print</span>(model_seq)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Model_Seq(</span><br><span class="line">  (flatten): Flatten(start_dim=<span class="number">1</span>, end_dim=-<span class="number">1</span>)</span><br><span class="line">  (linear1): Linear(in_features=<span class="number">784</span>, out_features=<span class="number">300</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (bn1): BatchNorm1d(<span class="number">300</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">  (linear2): Linear(in_features=<span class="number">300</span>, out_features=<span class="number">100</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (bn2): BatchNorm1d(<span class="number">100</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">  (out): Linear(in_features=<span class="number">100</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="使用nn-Sequential按层顺序构建模型"><a href="#使用nn-Sequential按层顺序构建模型" class="headerlink" title="使用nn.Sequential按层顺序构建模型"></a>使用nn.Sequential按层顺序构建模型</h4><p>使用nn.Sequential构建模型，因其内部实现了forward函数，因此可以不用写forward函数。nn.Sequential里面的模块按照先后顺序进行排列的，所以必须确保前一个模块的输出大小和下一个模块的输入大小是一致的。使用这种方法一般构建较简单的模型。 以下是使用nn.Sequential搭建模型的几种等价方法。</p><h5 id="利用可变参数"><a href="#利用可变参数" class="headerlink" title="利用可变参数"></a>利用可变参数</h5><p>Python中的函数参数个数是可变（或称为不定长参数），PyTorch中的有些函数也类似，如nn.Sequential(*args)就是一例。</p><ol><li>导入模块</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br></pre></td></tr></table></figure><ol start="2"><li>构建模型</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Seq_arg = nn.Sequential(</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(in_dim,n_hidden_1),</span><br><span class="line">    nn.BatchNorm1d(n_hidden_1),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Linear(n_hidden_1, n_hidden_2),</span><br><span class="line">    nn.BatchNorm1d(n_hidden_2),</span><br><span class="line">    nn.ReLU(),         </span><br><span class="line">    nn.Linear(n_hidden_2, out_dim),</span><br><span class="line">    nn.Softmax(dim=<span class="number">1</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ol start="3"><li>查看模型</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">in_dim, n_hidden_1, n_hidden_2, out_dim=<span class="number">28</span> * <span class="number">28</span>, <span class="number">300</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"><span class="built_in">print</span>(Seq_arg)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Sequential(</span><br><span class="line">(<span class="number">0</span>): Flatten(start_dim=<span class="number">1</span>, end_dim=-<span class="number">1</span>)</span><br><span class="line">(<span class="number">1</span>): Linear(in_features=<span class="number">784</span>, out_features=<span class="number">300</span>, bias=<span class="literal">True</span>)</span><br><span class="line">(<span class="number">2</span>): BatchNorm1d(<span class="number">300</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">(<span class="number">3</span>): ReLU()</span><br><span class="line">(<span class="number">4</span>): Linear(in_features=<span class="number">300</span>, out_features=<span class="number">100</span>, bias=<span class="literal">True</span>)</span><br><span class="line">(<span class="number">5</span>): BatchNorm1d(<span class="number">100</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">(<span class="number">6</span>): ReLU()</span><br><span class="line">(<span class="number">7</span>): Linear(in_features=<span class="number">100</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">(<span class="number">8</span>): Softmax(dim=<span class="number">1</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h5 id="使用add-module方法"><a href="#使用add-module方法" class="headerlink" title="使用add_module方法"></a>使用add_module方法</h5><ol start="2"><li>构建模型</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Seq_module = nn.Sequential()</span><br><span class="line">Seq_module.add_module(<span class="string">&quot;flatten&quot;</span>,nn.Flatten())</span><br><span class="line">Seq_module.add_module(<span class="string">&quot;linear1&quot;</span>,nn.Linear(in_dim,n_hidden_1))</span><br><span class="line">Seq_module.add_module(<span class="string">&quot;bn1&quot;</span>,nn.BatchNorm1d(n_hidden_1))</span><br><span class="line">Seq_module.add_module(<span class="string">&quot;relu1&quot;</span>,nn.ReLU())</span><br><span class="line">Seq_module.add_module(<span class="string">&quot;linear2&quot;</span>,nn.Linear(n_hidden_1, n_hidden_2))</span><br><span class="line">Seq_module.add_module(<span class="string">&quot;bn2&quot;</span>,nn.BatchNorm1d(n_hidden_2))</span><br><span class="line">Seq_module.add_module(<span class="string">&quot;relu2&quot;</span>,nn.ReLU())         </span><br><span class="line">Seq_module.add_module(<span class="string">&quot;out&quot;</span>,nn.Linear(n_hidden_2, out_dim))</span><br><span class="line">Seq_module.add_module(<span class="string">&quot;softmax&quot;</span>,nn.Softmax(dim=<span class="number">1</span>))</span><br></pre></td></tr></table></figure><ol start="3"><li>查看模型</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">in_dim, n_hidden_1, n_hidden_2, out_dim=<span class="number">28</span> * <span class="number">28</span>, <span class="number">300</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"><span class="built_in">print</span>(Seq_module)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Sequential(</span><br><span class="line">(flatten): Flatten(start_dim=<span class="number">1</span>, end_dim=-<span class="number">1</span>)</span><br><span class="line">(linear1): Linear(in_features=<span class="number">784</span>, out_features=<span class="number">300</span>, bias=<span class="literal">True</span>)</span><br><span class="line">(bn1): BatchNorm1d(<span class="number">300</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">(relu1): ReLU()</span><br><span class="line">(linear2): Linear(in_features=<span class="number">300</span>, out_features=<span class="number">100</span>, bias=<span class="literal">True</span>)</span><br><span class="line">(bn2): BatchNorm1d(<span class="number">100</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">(relu2): ReLU()</span><br><span class="line">(out): Linear(in_features=<span class="number">100</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">(softmax): Softmax(dim=<span class="number">1</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h5 id="使用OrderedDict"><a href="#使用OrderedDict" class="headerlink" title="使用OrderedDict"></a>使用OrderedDict</h5><ol><li>导入模块</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br></pre></td></tr></table></figure><ol start="2"><li>构建模型</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Seq_dict = nn.Sequential(OrderedDict([</span><br><span class="line">(<span class="string">&quot;flatten&quot;</span>,nn.Flatten()),</span><br><span class="line">(<span class="string">&quot;linear1&quot;</span>,nn.Linear(in_dim,n_hidden_1)),</span><br><span class="line">(<span class="string">&quot;bn1&quot;</span>,nn.BatchNorm1d(n_hidden_1)),</span><br><span class="line">(<span class="string">&quot;relu1&quot;</span>,nn.ReLU()),</span><br><span class="line">(<span class="string">&quot;linear2&quot;</span>,nn.Linear(n_hidden_1, n_hidden_2)),</span><br><span class="line">(<span class="string">&quot;bn2&quot;</span>,nn.BatchNorm1d(n_hidden_2)),</span><br><span class="line">(<span class="string">&quot;relu2&quot;</span>,nn.ReLU()),       </span><br><span class="line">(<span class="string">&quot;out&quot;</span>,nn.Linear(n_hidden_2, out_dim)),</span><br><span class="line">(<span class="string">&quot;softmax&quot;</span>,nn.Softmax(dim=<span class="number">1</span>))]))</span><br></pre></td></tr></table></figure><ol start="3"><li>查看模型</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">in_dim, n_hidden_1, n_hidden_2, out_dim=<span class="number">28</span> * <span class="number">28</span>, <span class="number">300</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"><span class="built_in">print</span>(Seq_dict)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Sequential(</span><br><span class="line">(flatten): Flatten(start_dim=<span class="number">1</span>, end_dim=-<span class="number">1</span>)</span><br><span class="line">(linear1): Linear(in_features=<span class="number">784</span>, out_features=<span class="number">300</span>, bias=<span class="literal">True</span>)</span><br><span class="line">(bn1): BatchNorm1d(<span class="number">300</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">(relu1): ReLU()</span><br><span class="line">(linear2): Linear(in_features=<span class="number">300</span>, out_features=<span class="number">100</span>, bias=<span class="literal">True</span>)</span><br><span class="line">(bn2): BatchNorm1d(<span class="number">100</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">(relu2): ReLU()</span><br><span class="line">(out): Linear(in_features=<span class="number">100</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">(softmax): Softmax(dim=<span class="number">1</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="继承nn-Module基类并应用模型容器来构建模型"><a href="#继承nn-Module基类并应用模型容器来构建模型" class="headerlink" title="继承nn.Module基类并应用模型容器来构建模型"></a>继承nn.Module基类并应用模型容器来构建模型</h4><p>当模型的结构比较复杂时，可以应用模型容器（如nn.Sequential,nn.ModuleList,nn.ModuleDict）对模型的部分结构进行封装，以增强模型的可读性，或减少代码量。</p><p>使用nn.Sequential模型容器</p><ol><li>导入模块</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br></pre></td></tr></table></figure><ol start="2"><li>构建模型</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Model_lay</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用sequential构建网络，Sequential()函数的功能是将网络的层组合到一起</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, n_hidden_1, n_hidden_2, out_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model_lay, self).__init__()</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line">        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1),nn.BatchNorm1d(n_hidden_1))</span><br><span class="line">        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1, n_hidden_2),nn.BatchNorm1d(n_hidden_2))</span><br><span class="line">        self.out = nn.Sequential(nn.Linear(n_hidden_2, out_dim))</span><br><span class="line">        </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x=self.flatten(x)</span><br><span class="line">        x = F.relu(self.layer1(x))</span><br><span class="line">        x = F.relu(self.layer2(x))</span><br><span class="line">        x = F.softmax(self.out(x),dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><ol start="3"><li>查看模型</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">in_dim, n_hidden_1, n_hidden_2, out_dim=<span class="number">28</span> * <span class="number">28</span>, <span class="number">300</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line">model_lay= Model_lay(in_dim, n_hidden_1, n_hidden_2, out_dim)</span><br><span class="line"><span class="built_in">print</span>(model_lay)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Model_lay(</span><br><span class="line">(flatten): Flatten(start_dim=<span class="number">1</span>, end_dim=-<span class="number">1</span>)</span><br><span class="line">(layer1): Sequential(</span><br><span class="line">(<span class="number">0</span>): Linear(in_features=<span class="number">784</span>, out_features=<span class="number">300</span>, bias=<span class="literal">True</span>)</span><br><span class="line">(<span class="number">1</span>): BatchNorm1d(<span class="number">300</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">)</span><br><span class="line">(layer2): Sequential(</span><br><span class="line">(<span class="number">0</span>): Linear(in_features=<span class="number">300</span>, out_features=<span class="number">100</span>, bias=<span class="literal">True</span>)</span><br><span class="line">(<span class="number">1</span>): BatchNorm1d(<span class="number">100</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">)</span><br><span class="line">(out): Sequential(</span><br><span class="line">(<span class="number">0</span>): Linear(in_features=<span class="number">100</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="自定义网络模块"><a href="#自定义网络模块" class="headerlink" title="自定义网络模块"></a>自定义网络模块</h4><p>利用以上方法，自定义一些典型的网络模块，如残差网络（ResNet18）中的残差块</p><p><img src="/../img/Pytorch1/pytorch7/3.png" alt="3"></p><p>​                                                                                         残差块网络结构</p><p>残差块有两种，一种是正常的模块方式，如图左图，将输入与输出相加，然后应用激活函数ReLU。 另一种是为使输入与输出形状一致，需添加通过1×1卷积调整通道和分辨率，如图中的右图所示。这些模块中用到卷积层、批量规范化层，具体将在第6章详细介绍，这里我们只需要了解这些是网络层即可。</p><h5 id="定义左图的残差模块"><a href="#定义左图的残差模块" class="headerlink" title="定义左图的残差模块"></a>定义左图的残差模块</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RestNetBasicBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, stride</span>):</span><br><span class="line">        <span class="built_in">super</span>(RestNetBasicBlock, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(out_channels)</span><br><span class="line">        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(out_channels)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        output = self.conv1(x)</span><br><span class="line">        output = F.relu(self.bn1(output))</span><br><span class="line">        output = self.conv2(output)</span><br><span class="line">        output = self.bn2(output)</span><br><span class="line">        <span class="keyword">return</span> F.relu(x + output)</span><br></pre></td></tr></table></figure><h5 id="定义右图残差模块"><a href="#定义右图残差模块" class="headerlink" title="定义右图残差模块"></a>定义右图残差模块</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RestNetDownBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, stride</span>):</span><br><span class="line">        <span class="built_in">super</span>(RestNetDownBlock, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, stride=stride[<span class="number">0</span>], padding=<span class="number">1</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(out_channels)</span><br><span class="line">        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, stride=stride[<span class="number">1</span>], padding=<span class="number">1</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(out_channels)</span><br><span class="line">        self.extra = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>, stride=stride[<span class="number">0</span>], padding=<span class="number">0</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels)</span><br><span class="line">        )</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        extra_x = self.extra(x)</span><br><span class="line">        output = self.conv1(x)</span><br><span class="line">        out = F.relu(self.bn1(output))</span><br><span class="line"> </span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">        <span class="keyword">return</span> F.relu(extra_x + out)</span><br></pre></td></tr></table></figure><h5 id="组合这两个模块得到现代经典RetNet18网络结构。"><a href="#组合这两个模块得到现代经典RetNet18网络结构。" class="headerlink" title="组合这两个模块得到现代经典RetNet18网络结构。"></a>组合这两个模块得到现代经典RetNet18网络结构。</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RestNet18</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(RestNet18, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">        self.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line">        self.layer1 = nn.Sequential(RestNetBasicBlock(<span class="number">64</span>, <span class="number">64</span>, <span class="number">1</span>),</span><br><span class="line">                                    RestNetBasicBlock(<span class="number">64</span>, <span class="number">64</span>, <span class="number">1</span>))</span><br><span class="line"> </span><br><span class="line">        self.layer2 = nn.Sequential(RestNetDownBlock(<span class="number">64</span>, <span class="number">128</span>, [<span class="number">2</span>, <span class="number">1</span>]),</span><br><span class="line">                                    RestNetBasicBlock(<span class="number">128</span>, <span class="number">128</span>, <span class="number">1</span>))</span><br><span class="line"> </span><br><span class="line">        self.layer3 = nn.Sequential(RestNetDownBlock(<span class="number">128</span>, <span class="number">256</span>, [<span class="number">2</span>, <span class="number">1</span>]),</span><br><span class="line">                                    RestNetBasicBlock(<span class="number">256</span>, <span class="number">256</span>, <span class="number">1</span>))</span><br><span class="line"> </span><br><span class="line">        self.layer4 = nn.Sequential(RestNetDownBlock(<span class="number">256</span>, <span class="number">512</span>, [<span class="number">2</span>, <span class="number">1</span>]),</span><br><span class="line">                                    RestNetBasicBlock(<span class="number">512</span>, <span class="number">512</span>, <span class="number">1</span>))</span><br><span class="line"> </span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"> </span><br><span class="line">        self.fc = nn.Linear(<span class="number">512</span>, <span class="number">10</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.layer1(out)</span><br><span class="line">        out = self.layer2(out)</span><br><span class="line">        out = self.layer3(out)</span><br><span class="line">        out = self.layer4(out)</span><br><span class="line">        out = self.avgpool(out)</span><br><span class="line">        out = out.reshape(x.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line">        out = self.fc(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><p>构建模型（假设为model）后，接下来就是训练模型。PyTorch训练模型主要包括加载数据集、损失计算、定义优化算法、反向传播、参数更新等主要步骤。<br>1.加载预处理数据集<br>加载和预处理数据集，可以使用PyTorch的数据处理工具，如torch.utils和torchvision等，这些工具将在第4章详细介绍。<br>2.定义损失函数<br>定义损失函数可以通过自定义方法或使用PyTorch内置的损失函数，如回归使用的losss_fun&#x3D;nn.MSELoss()，分类使用的nn.BCELoss等损失函数，更多内容可参考本书5.2.4节。<br>3.定义优化方法<br>Pytoch常用的优化方法都封装在torch.optim里面，其设计很灵活，可以扩展为自定义的优化方法。所有的优化方法都是继承了基类optim.Optimizer，并实现了自己的优化步骤。<br>最常用的优化算法就是梯度下降法及其各种变种，具体将在5.4节详细介绍，这些优化算法大多使用梯度更新参数。<br>如使用SGD优化器时，可设置为optimizer &#x3D; torch.optim.SGD(params,lr &#x3D; 0.001)。<br>4.循环训练模型<br>1）设置为训练模式：<br>model.train()<br>调用model.train()会把所有的module设置为训练模式。<br>2）梯度清零：<br>optimizer. zero_grad()<br>在默认情况下梯度是累加的，需要手工把梯度初始化或清零，调用optimizer.zero_grad() 即可。<br>3）求损失值：<br>y_prev&#x3D;model(x)<br>loss&#x3D;loss_fun(y_prev,y_true)<br>4）自动求导，实现梯度的反向传播：<br>loss.backward()<br>5）更新参数：<br>optimizer.step()<br>5.循环测试或验证模型<br>1）设置为测试或验证模式：<br>model.eval()<br>调用model.eval()会把所有的training属性设置为False。<br>2）在不跟踪梯度模式下计算损失值、预测值等：<br>with.torch.no_grad():<br>6.可视化结果<br>下面我们通过实例来说明如何使用nn来构建网络模型、训练模型。<br>【说明】model.train()与model.eval()的使用<br>如果模型中有BN (Batch Normalization）层和Dropout，需要在训练时添加model.train()，<br>在测试时添加model.eval()。其中model.train()是保证BN层用每一批数据的均值和方差，而model.eval()是保证BN用全部训练数据的均值和方差；而对于Dropout，model.train()是随机取一部分网络连接来训练更新参数，而model.eval()是利用到了所有网络连接。</p><h3 id="实现神经网络实例"><a href="#实现神经网络实例" class="headerlink" title="实现神经网络实例"></a>实现神经网络实例</h3><p>通过一个构建神经网络的实例把这些内容有机结合起来。</p><h4 id="背景说明"><a href="#背景说明" class="headerlink" title="背景说明"></a>背景说明</h4><p>利用神经网络完成对手写数字进行识别的实例，来说明如何借助nn工具箱来实现一个神经网络，并对神经网络有个直观了解。在这个基础上，后续我们将对nn的各模块进行详细介绍。实例环境使用PyTorch1.5+，GPU或CPU,源数据集为MNIST。<br>主要步骤如下。</p><p>利用PyTorch内置函数mnist下载数据。</p><ol><li><p>利用torchvision对数据进行预处理，调用torch.utils建立一个数据迭代器。</p></li><li><p>可视化源数据。</p></li><li><p>利用nn工具箱构建神经网络模型。</p></li><li><p>实例化模型，并定义损失函数及优化器。</p></li><li><p>训练模型。</p></li><li><p>可视化结果。</p></li></ol><p>神经网络的结构如图</p><p>使用两个隐含层，每层使用ReLU激活函数，输出层使用softmax激活函数，最后使用torch.max(out,1)找出张量out最大值对应索引作为预测值。</p><h4 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h4><p>导人必要的模块</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># 导入 pytorch 内置的 mnist 数据</span></span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> mnist </span><br><span class="line"><span class="comment">#导入预处理模块</span></span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="comment">#导入nn及优化器</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br></pre></td></tr></table></figure><p>定义一些超参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">train_batch_size = <span class="number">64</span></span><br><span class="line">test_batch_size = <span class="number">128</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">num_epoches = <span class="number">20</span></span><br><span class="line">lr = <span class="number">0.01</span></span><br><span class="line">momentum = <span class="number">0.5</span></span><br></pre></td></tr></table></figure><p>下载数据并进行预处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义预处理函数</span></span><br><span class="line">transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([<span class="number">0.5</span>], [<span class="number">0.5</span>])])</span><br><span class="line"><span class="comment">#下载数据，并对数据进行预处理</span></span><br><span class="line">train_dataset = mnist.MNIST(<span class="string">&#x27;../data/&#x27;</span>, train=<span class="literal">True</span>, transform=transform, download=<span class="literal">False</span>)</span><br><span class="line">test_dataset = mnist.MNIST(<span class="string">&#x27;../data/&#x27;</span>, train=<span class="literal">False</span>, transform=transform)</span><br><span class="line"><span class="comment">#得到一个生成器</span></span><br><span class="line">train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>【说明】<br>\1) transforms.Compose可以把一些转换函数组合在一起。<br>\2) Normalize([0.5], [0.5])对张量进行归一化，这里两个0.5分别表示对张量进行归一化的全局平均值和方差。因图像是灰色的只有一个通道，如果有多个通道，需要有多个数字，如三个通道，应该是Normalize([m1,m2,m3], [n1,n2,n3])。<br>\3) download参数控制是否需要下载，如果.&#x2F;data目录下已有MNIST，可选择False。<br>\4) 用DataLoader得到生成器，这可节省内存。<br>\5) torchvision及data的使用第4章将详细介绍。</p><h4 id="可视化源数据"><a href="#可视化源数据" class="headerlink" title="可视化源数据"></a>可视化源数据</h4><p>对数据集  中部分数据进行可视化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">examples = <span class="built_in">enumerate</span>(test_loader)</span><br><span class="line">batch_idx, (example_data, example_targets) = <span class="built_in">next</span>(examples)</span><br><span class="line"> </span><br><span class="line">fig = plt.figure()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">  plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">  plt.tight_layout()</span><br><span class="line">  plt.imshow(example_data[i][<span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>, interpolation=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">  plt.title(<span class="string">&quot;Ground Truth: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(example_targets[i]))</span><br><span class="line">  plt.xticks([])</span><br><span class="line">  plt.yticks([])</span><br></pre></td></tr></table></figure><h4 id="构建模型-1"><a href="#构建模型-1" class="headerlink" title="构建模型"></a>构建模型</h4><p>构建网络</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用sequential构建网络，Sequential()函数的功能是将网络的层组合到一起</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, n_hidden_1, n_hidden_2, out_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line">        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1),nn.BatchNorm1d(n_hidden_1))</span><br><span class="line">        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1, n_hidden_2),nn.BatchNorm1d(n_hidden_2))</span><br><span class="line">        self.out = nn.Sequential(nn.Linear(n_hidden_2, out_dim))</span><br><span class="line">        </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x=self.flatten(x)</span><br><span class="line">        x = F.relu(self.layer1(x))</span><br><span class="line">        x = F.relu(self.layer2(x))</span><br><span class="line">        x = F.softmax(self.out(x),dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>实例化网络</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#检测是否有可用的GPU，有则使用，否则使用CPU</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="comment">#实例化网络</span></span><br><span class="line">model = Net(<span class="number">28</span> * <span class="number">28</span>, <span class="number">300</span>, <span class="number">100</span>, <span class="number">10</span>)</span><br><span class="line">model.to(device)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 定义损失函数和优化器</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)</span><br></pre></td></tr></table></figure><h4 id="训练模型-1"><a href="#训练模型-1" class="headerlink" title="训练模型"></a>训练模型</h4><p>这里使用for循环进行迭代。其中包括对训练数据的训练模型，然后用测试数据验证模型</p><p>1）训练模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line">losses = []</span><br><span class="line">acces = []</span><br><span class="line">eval_losses = []</span><br><span class="line">eval_acces = []</span><br><span class="line">writer = SummaryWriter(log_dir=<span class="string">&#x27;logs&#x27;</span>,comment=<span class="string">&#x27;train-loss&#x27;</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoches):</span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    train_acc = <span class="number">0</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="comment">#动态修改参数学习率</span></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">5</span>==<span class="number">0</span>:</span><br><span class="line">        optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>]*=<span class="number">0.9</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;学习率:&#123;:.6f&#125;&quot;</span>.<span class="built_in">format</span>(optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>]))</span><br><span class="line">    <span class="keyword">for</span> img, label <span class="keyword">in</span> train_loader:</span><br><span class="line">        img=img.to(device)</span><br><span class="line">        label = label.to(device)</span><br><span class="line">        <span class="comment"># 正向传播</span></span><br><span class="line">        out = model(img)</span><br><span class="line">        loss = criterion(out, label)</span><br><span class="line">        <span class="comment"># 反向传播</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment"># 记录误差</span></span><br><span class="line">        train_loss += loss.item()</span><br><span class="line">        <span class="comment"># 保存loss的数据与epoch数值</span></span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;Train&#x27;</span>, train_loss/<span class="built_in">len</span>(train_loader), epoch)</span><br><span class="line">        <span class="comment"># 计算分类的准确率</span></span><br><span class="line">        _, pred = out.<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">        num_correct = (pred == label).<span class="built_in">sum</span>().item()</span><br><span class="line">        acc = num_correct / img.shape[<span class="number">0</span>]</span><br><span class="line">        train_acc += acc</span><br><span class="line">        </span><br><span class="line">    losses.append(train_loss / <span class="built_in">len</span>(train_loader))</span><br><span class="line">    acces.append(train_acc / <span class="built_in">len</span>(train_loader))</span><br><span class="line">    <span class="comment"># 在测试集上检验效果</span></span><br><span class="line">    eval_loss = <span class="number">0</span></span><br><span class="line">    eval_acc = <span class="number">0</span></span><br><span class="line">    <span class="comment">#net.eval() # 将模型改为预测模式</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">for</span> img, label <span class="keyword">in</span> test_loader:</span><br><span class="line">        img=img.to(device)</span><br><span class="line">        label = label.to(device)</span><br><span class="line">        img = img.view(img.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        out = model(img)</span><br><span class="line">        loss = criterion(out, label)</span><br><span class="line">        <span class="comment"># 记录误差</span></span><br><span class="line">        eval_loss += loss.item()</span><br><span class="line">        <span class="comment"># 记录准确率</span></span><br><span class="line">        _, pred = out.<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">        num_correct = (pred == label).<span class="built_in">sum</span>().item()</span><br><span class="line">        acc = num_correct / img.shape[<span class="number">0</span>]</span><br><span class="line">        eval_acc += acc</span><br><span class="line">        </span><br><span class="line">    eval_losses.append(eval_loss / <span class="built_in">len</span>(test_loader))</span><br><span class="line">    eval_acces.append(eval_acc / <span class="built_in">len</span>(test_loader))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;epoch: &#123;&#125;, Train Loss: &#123;:.4f&#125;, Train Acc: &#123;:.4f&#125;, Test Loss: &#123;:.4f&#125;, Test Acc: &#123;:.4f&#125;&#x27;</span></span><br><span class="line">          .<span class="built_in">format</span>(epoch, train_loss / <span class="built_in">len</span>(train_loader), train_acc / <span class="built_in">len</span>(train_loader), </span><br><span class="line">                     eval_loss / <span class="built_in">len</span>(test_loader), eval_acc / <span class="built_in">len</span>(test_loader)))</span><br></pre></td></tr></table></figure><p>最后5次迭代的结果如下：<br>学习率:0.006561<br>epoch: 15, Train Loss: 1.4681, Train Acc: 0.9950, Test Loss: 1.4801, Test Acc: 0.9830<br>epoch: 16, Train Loss: 1.4681, Train Acc: 0.9950, Test Loss: 1.4801, Test Acc: 0.9833<br>epoch: 17, Train Loss: 1.4673, Train Acc: 0.9956, Test Loss: 1.4804, Test Acc: 0.9826<br>epoch: 18, Train Loss: 1.4668, Train Acc: 0.9960, Test Loss: 1.4798, Test Acc: 0.9835<br>epoch: 19, Train Loss: 1.4666, Train Acc: 0.9962, Test Loss: 1.4795, Test Acc: 0.9835<br>这个神经网络的结构比较简单，只用了两层，也没有使用dropout层，迭代20次，测试准确率达到98%左右，效果还可以。不过，还是有提升空间，如果采用cnn，dropout等层，应该还可以提升模型性能。</p><p>2）可视化训练及测试损失值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">&#x27;train loss&#x27;</span>)</span><br><span class="line">plt.plot(np.arange(<span class="built_in">len</span>(losses)), losses)</span><br><span class="line">plt.legend([<span class="string">&#x27;Train Loss&#x27;</span>], loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="/../img/Pytorch1/pytorch7/4.png" alt="4"></p>]]></content>
      
      
      
        <tags>
            
            <tag> machine-learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础学习</title>
      <link href="/2024/06/26/Java%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/"/>
      <url>/2024/06/26/Java%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<p>这个博客是我整理的 Java 基础知识的学习笔记(并不是我原创的，我也没实力原创，仅供自己和大家学习)，内容包括：Java 数据类型、Java 关键字、Java的三大特性、Java 中的 String、StringBuffer 和 StringBuilder、Java 反射、Java 异常、Java IO 流、Java 注解、Java 泛型、Java 枚举、Java 8 新特性、Java 常见的集合框架源码解析。</p><h1 id="1-Java-数据类型详解"><a href="#1-Java-数据类型详解" class="headerlink" title="1. Java 数据类型详解"></a>1. Java 数据类型详解</h1><p>Java 数据类型有很多，本文主要从基本类型、包装类型、引用类型和缓存池四个方面来总结。</p><h2 id="1-1-基本数据类型"><a href="#1-1-基本数据类型" class="headerlink" title="1.1 基本数据类型"></a>1.1 基本数据类型</h2><p>基本数据类型有 byte、short、int、long、float、double、boolean、char，关于它们的分类，我画了个图。</p><p><img src="/../img/java/1.jpg" alt="1"></p><p>接下来我主要从字节数、数据范围、默认值、以及用途等方面给大家总结成一个表格，一目了然。</p><table><thead><tr><th>数据类 型</th><th>字节数</th><th>位 数</th><th>最小值</th><th>最大值</th><th>默认 值</th><th>用途</th></tr></thead><tr><td>byte</td><td>1</td><td>8</td><td>-128</td><td>127</td><td>0</td><td>byte 类型用在大型数组中节约空 间，主要代替整数。因为 byte 变 量占用的空间只有 int 类型的四分 之一</td></tr><tr><td>short</td><td>2</td><td>16</td><td>-32768</td><td>32767</td><td>0</td><td>Short 数据类型也可以像 byte 那 样节省空间。一个short变量是int 型变量所占空间的二分之一</td></tr><tr><td>int</td><td>4</td><td>32</td><td>-2^31</td><td>2^31 - 1</td><td>0</td><td>一般地整型变量默认为 int 类型</td></tr><tr><td>long</td><td>8</td><td>64</td><td>-2^63</td><td>2^63-1</td><td>OL</td><td>这种类型主要使用在需要比较大 整数的系统上</td></tr><tr><td>float</td><td>4</td><td>32</td><td>1.4e-45</td><td>3.4e38</td><td>0.0F</td><td>float 在储存大型浮点数组的时候 可节省内存空间。浮点数不能用 来表示精确的值，如货币</td></tr></table><table><thead><tr><th>数据类 型</th><th>字节数</th><th>位数</th><th>最小值</th><th>最大值</th><th>默认 值</th><th>用途</th></tr></thead><tr><td>double</td><td>8</td><td>64</td><td>4.9e- 324</td><td>1.8e308</td><td>0.0D</td><td>浮点数的默认类型为double类 型。double类型同样不能表示精 确的值，如货币</td></tr><tr><td>boolean</td><td>\( \times \)</td><td>\( \times \)</td><td>\( \times \)</td><td>\( \times \)</td><td>false</td><td>true和false</td></tr><tr><td>char</td><td>2</td><td>16</td><td>\\u0000</td><td>\\uffff</td><td></td><td>char 数据类型可以储存任何字符</td></tr></table><h2 id="1-2-包装数据类型"><a href="#1-2-包装数据类型" class="headerlink" title="1.2 包装数据类型"></a>1.2 包装数据类型</h2><p>上面提到的基本类型都有对应的包装类型，为了方便读者查看，我也整了一个表格。</p><table><thead><tr><th>基本类型</th><th>包装类型</th><th>最小值</th><th>最大值</th></tr></thead><tr><td>byte</td><td>Byte</td><td>Byte.MIN_VALUE</td><td>Byte.MAX_VALUE</td></tr><tr><td>short</td><td>Short</td><td>Short.MIN_VALUE</td><td>Short.MAX_VALUE</td></tr><tr><td>int</td><td>Integer</td><td>Integer.MIN_VALUE</td><td>Integer.MAX_VALUE</td></tr><tr><td>long</td><td>Long</td><td>Long.MIN_VALUE</td><td>Long.MAX_VALUE</td></tr><tr><td>float</td><td>Float</td><td>Float.MIN_VALUE</td><td>Float.MAX_VALUE</td></tr><tr><td>double</td><td>Double</td><td>Double.MIN_VALUE</td><td>Double.MAX_VALUE</td></tr><tr><td>boolean</td><td>Boolean</td><td>Boolean.MIN_VALUE</td><td>Boolean.MAX_VALUE</td></tr><tr><td>char</td><td>Char</td><td>CHAR.MIN_VALUE</td><td>Char.MAX_VALUE</td></tr></table><h2 id="1-3-引用类型"><a href="#1-3-引用类型" class="headerlink" title="1.3 引用类型"></a>1.3 引用类型</h2><p>在Java中，引用类型的变量非常类似于 C&#x2F;C++ 的指针。引用类型指向一个对象，指向对象的变量是引用变量。这些变量在声明时被指定为一个特定的类型，比如 Student、Dog 等。变量一旦声明后，类型就不能被改变了。</p><p>对象、数组都是引用数据类型。所有引用类型的默认值都是null。一个引用变量可以用来引用任何与之兼容的类型。例如:</p><p>Dog dog &#x3D; new Dog(“旺财”)。</p><h2 id="1-4-数据类型转换"><a href="#1-4-数据类型转换" class="headerlink" title="1.4 数据类型转换"></a>1.4 数据类型转换</h2><p>包装类型和基本类型之间如何转化呢?</p><table><tr><td>Integer \( x = 2 \) ;</td><td>// 装箱 调用了 Integer.valueOf(2)</td></tr><tr><td>int \( y = x \) ;</td><td>// 拆箱 调用了 x.intvalue()</td></tr></table><ol><li><p>把大容量的类型转换为小容量的类型时必须使用强制类型转换。</p></li><li><p>把小容量的类型转换为大容量的类型可以自动转换。</p></li></ol><p>比如:</p><p>int ( i &#x3D; {128} ) ;</p><p>byte ( b &#x3D; ) (byte) ( i ) ;</p><p>long ( c &#x3D; i ) ;</p><h2 id="1-5-缓存池"><a href="#1-5-缓存池" class="headerlink" title="1.5 缓存池"></a>1.5 缓存池</h2><p>大家思考一个问题: new Integer(123) 与 Integer.valueof(123) 有什么区别?</p><p>有些人可能知道，有些人可能不知道。其实他们的区别很大。</p><ol><li><p>new Integer(123) 每次都会新建一个对象;</p></li><li><p>Integer.valueOf(123) 会使用缓存池中的对象，多次调用会取得同一个对象的引用。 我写个demo大家就知道了</p></li></ol><p>Integer ( x &#x3D; ) new Integer(123);</p><p>Integer ( y &#x3D; ) new Integer(123);</p><p>System.out.println(x &#x3D;&#x3D; y); &#x2F;&#x2F; false</p><p>Integer ( z &#x3D; ) Integer.valueOf ( \left( {123}\right) ) ;</p><p>Integer ( k &#x3D; ) Integer.valueOf(123);</p><p>System.out.println(z &#x3D;&#x3D; k); &#x2F;&#x2F; true</p><p>编译器会在自动装箱过程调用 valueof () 方法，因此多个值相同且值在缓存池范围内的 Integer 实例使用自动装箱来创建，那么就会引用相同的对象。如:</p><hr><p>Integer ( m &#x3D; {123} ) ;</p><p>Integer ( n &#x3D; {123} ) ;</p><p>System.out.println(m &#x3D;&#x3D; n); &#x2F;&#x2F; true</p><hr><p>valueof() 方法的实现比较简单，就是先判断值是否在缓存池中，如果在的话就直接返回缓存池的内容。我们看下源码就知道。</p><p>public static Integer valueOf(int i) {</p><p>if (i &gt;&#x3D; IntegerCache.low &amp;&amp; i &lt;&#x3D; IntegerCache.high)</p><p>return IntegerCache.cache[i + (-IntegerCache.low)];</p><p>return new Integer(i);</p><p>}</p><p>根据数据类型的不一样，这个缓存池的上下限也不同，比如这个 Integer，就是 -128~127。不过这个上界是可调的，在启动 jvm 的时候，通过 -XX:AutoBoxCacheMax&#x3D; 来指定这个缓冲池的大小，该选项在 JVM 初始化的时候会设定一个名为 java.lang.IntegerCache.high 系统属性，然后 IntegerCache 初始化的时候就会读取该系统属性来决定上界。</p><p>参考自：StackOverflow : Differences between new Integer(123), Integer.valueOf(123) and just 123</p><p>OK，这篇文章就分享到这，Java 的数据类型虽然简单，但是里面还是有很多小细节值得我们玩味的，希望这篇文章能给大家带来一些帮助。</p><h1 id="2-Java-关键字详解"><a href="#2-Java-关键字详解" class="headerlink" title="2. Java 关键字详解"></a>2. Java 关键字详解</h1><p>Java 有一系列的关键字，在代码中各自有自己的重要用途与意义，今天就带着大家一起来了解一下 Java 的关键字!</p><p>Java 的关键字特别多，本文先主要介绍一下各个关键字的用途，然后重点介绍一下 final、static 和 this 这三个常用的关键字，其他的关键字大家用到的时候可以去网上查一下。</p><h2 id="2-1-Java-关键字汇总"><a href="#2-1-Java-关键字汇总" class="headerlink" title="2.1 Java 关键字汇总"></a>2.1 Java 关键字汇总</h2><table><thead><tr><th>数据类型</th><th>含义</th></tr></thead><tr><td>abstract</td><td>表明类或者成员方法具有抽象属性</td></tr><tr><td>assert</td><td>断言，用来进行程序调试</td></tr><tr><td>boolean</td><td>基本数据类型之一，布尔类型</td></tr><tr><td>break</td><td>提前跳出一个块</td></tr><tr><td>byte</td><td>基本数据类型之一，字节类型</td></tr><tr><td>case</td><td>用在switch语句之中，表示其中的一个分支</td></tr><tr><td>catch</td><td>用在异常处理中，用来捕捉异常</td></tr><tr><td>char</td><td>基本数据类型之一，字符类型</td></tr><tr><td>class</td><td>声明一个类</td></tr><tr><td>const</td><td>保留关键字，没有具体含义</td></tr><tr><td>continue</td><td>回到一个块的开始处</td></tr><tr><td>default</td><td>默认，例如，用在switch语句中，表明一个默认的分支</td></tr><tr><td>do</td><td>用在do-while循环结构中</td></tr><tr><td>double</td><td>基本数据类型之一，双精度浮点数类型</td></tr><tr><td>else</td><td>用在条件语句中，表明当条件不成立时的分支</td></tr><tr><td>enum</td><td>枚举</td></tr><tr><td>extends</td><td>表明一个类型是另一个类型的子类型，这里常见的类型有类和接口</td></tr><tr><td>final</td><td>用来说明最终属性，表明一个类不能派生出子类，或者成员方法不能被覆盖，或 者成员域的值不能被改变，用来定义常量</td></tr><tr><td>finally</td><td>用于处理异常情况，用来声明一个基本肯定会被执行到的语句块</td></tr><tr><td>float</td><td>基本数据类型之一，单精度浮点数类型</td></tr><tr><td>for</td><td>一种循环结构的引导词</td></tr><tr><td>goto</td><td>保留关键字，没有具体含义</td></tr><tr><td>if</td><td>条件语句的引导词</td></tr></table><table><thead><tr><th>数据类型</th><th>含义</th></tr></thead><tr><td>implements</td><td>表明一个类实现了给定的接口</td></tr><tr><td>import</td><td>表明要访问指定的类或包</td></tr><tr><td>instanceof</td><td>用来测试一个对象是否是指定类型的实例对象</td></tr><tr><td>int</td><td>基本数据类型之一，整数类型</td></tr><tr><td>interface</td><td>接口</td></tr><tr><td>long</td><td>基本数据类型之一，长整数类型</td></tr><tr><td>native</td><td>用来声明一个方法是由与计算机相关的语言（如C/C++/FORTRAN语言）实现的</td></tr><tr><td>new</td><td>用来创建新实例对象</td></tr><tr><td>package</td><td>包</td></tr><tr><td>private</td><td>一种访问控制方式：私用模式</td></tr><tr><td>protected</td><td>一种访问控制方式：保护模式</td></tr><tr><td>public</td><td>一种访问控制方式：共用模式</td></tr><tr><td>return</td><td>从成员方法中返回数据</td></tr><tr><td>short</td><td>基本数据类型之一,短整数类型</td></tr><tr><td>static</td><td>表明具有静态属性</td></tr><tr><td>strictfp</td><td>用来声明FP_strict（单精度或双精度浮点数）表达式遵循IEEE 754算术规范 [1</td></tr><tr><td>super</td><td>表明当前对象的父类型的引用或者父类型的构造方法</td></tr><tr><td>switch</td><td>分支语句结构的引导词</td></tr><tr><td>synchronized</td><td>表明一段代码需要同步执行</td></tr><tr><td>this</td><td>指向当前实例对象的引用</td></tr><tr><td>throw</td><td>抛出一个异常</td></tr><tr><td>throws</td><td>声明在当前定义的成员方法中所有需要抛出的异常</td></tr><tr><td>transient</td><td>声明不用序列化的成员域</td></tr><tr><td>try</td><td>尝试一个可能抛出异常的程序块</td></tr><tr><td>void</td><td>声明当前成员方法没有返回值</td></tr><tr><td>volatile</td><td>表明两个或者多个变量必须同步地发生变化</td></tr><tr><td>while</td><td>用在循环结构中</td></tr></table><p>是不是不列不知道，一列吓一跳，原来 Java 里还有这么多关键字，大部分我们平时都在用，只是没有特意去注意这个而已。所以大部分大家都很熟了，有些不常用的我也不总结了，我接下来主要总结几个比较有代表性的关键字。</p><h2 id="2-2-final-关键字"><a href="#2-2-final-关键字" class="headerlink" title="2.2 final 关键字"></a>2.2 final 关键字</h2><p>Java 中的 final 关键字可以用来修饰类、方法和变量 (包括实例变量和局部变量)</p><h2 id="2-2-1-final-修饰类"><a href="#2-2-1-final-修饰类" class="headerlink" title="2.2.1 final 修饰类"></a>2.2.1 final 修饰类</h2><p>使用final修饰类则该类不能被继承，同时类中的所有成员方法都会被隐式定义为final方法（只有在需要确保类中的所有方法都不被重写时才使用final修饰类）。final修饰类的成员变量是可以更改的</p><p>public final class FinalClass{</p><p>int ( i &#x3D; 1 ) ;</p><p>void test(){</p><p>System.out.println(“FinalClass:test”);</p><p>}</p><p>public static void main( String[] args ){</p><p>FinalClass ficl &#x3D; new FinalClass();</p><p>System.out.println(“ficl.i &#x3D; “ + ficl.i);</p><p>fic1.i ( &#x3D; 2 ) ;</p><p>System.out.println(“ficl.i &#x3D; “ + ficl.i);</p><p>}</p><p>}</p><h2 id="2-2-2-final-修饰方法"><a href="#2-2-2-final-修饰方法" class="headerlink" title="2.2.2 final 修饰方法"></a>2.2.2 final 修饰方法</h2><p>使用final修饰方法可以将方法“锁定”，以防止任何继承类对方法的修改，也即使用final修饰方法，则子类无法重写 (但并不影响继承和重载，即子类调用父类方法不受影响)。</p><h2 id="2-2-3-final-修饰变量"><a href="#2-2-3-final-修饰变量" class="headerlink" title="2.2.3 final 修饰变量"></a>2.2.3 final 修饰变量</h2><p>使用final关键字修饰变量是使用最多的情况。</p><p>使用final修饰变量的值不能做再次更改，即不能重新赋值。</p><ol><li><p>如果final修饰的变量是基本数据类型，则变量的值不可更改;</p></li><li><p>如果final修饰的变量是引用数据类型，则该变量不能再次指向其他引用（如重新指向新的对象或数组) 但是该变量本身的内容可以再做修改 (如数组本身的内容，或者对象的属性的修改）。</p></li></ol><p>无论final修饰实例变量还是局部变量，都必须在使用前显式赋初值。</p><ol><li><p>Java中的实例变量系统会对其默认赋初值，但是局部变量必须先声明后赋值再使用。</p></li><li><p>虽然对于实例变量，系统会默认赋初值，但是Java仍然规定final修饰的实例变量必须显式赋初值。实例变量显式赋值的时机可以是在声明时直接赋值，也可以先声明，后在构造方法中赋</p></li></ol><p>值（对于含有多个构造方法，必须在每个构造方法中都显示赋值）。</p><p>我们来看个例子:</p><p>public void fun(){</p><p>&#x2F;&#x2F;BufferedImage src &#x3D; null;&#x2F;&#x2F;0. 声明的同时赋值</p><p>BufferedImage ( \operatorname{src};&#x2F;&#x2F;1 ) . 这里不用赋初值,也不会出错</p><p>try{</p><p>src &#x3D; ImageIO.read(new File(“1.jpg”));&#x2F;&#x2F;2.</p><p>} catch (Exception e){</p><p>&#x2F;&#x2F;3. 如果出异常了就会进入这里, 那么src可能无法被赋值</p><p>}</p><p>System.out.println(src.getHeight()); &#x2F;&#x2F;4. src不一定有值, 所以无法使用 }</p><p>如果静态变量同时被final修饰则可以将变量视为全局变量，即在整个类加载期间，其值不变。（static保证变量属于整个类，在类加载时只对其分配一次内存；final保证变量的值不被改变)</p><h2 id="2-3-static-关键字"><a href="#2-3-static-关键字" class="headerlink" title="2.3 static 关键字"></a>2.3 static 关键字</h2><p>static方法一般称作静态方法，由于静态方法不依赖于任何对象就可以进行访问，因此对于静态方法来说，是没有this的，因为它不依附于任何对象，既然都没有对象，就谈不上this了。并且由于这个特性， 在静态方法中不能访问类的非静态成员变量和非静态成员方法，因为非静态成员方法&#x2F;变量都是必须依赖具体的对象才能够被调用。</p><p>但是要注意的是，虽然在静态方法中不能访问非静态成员方法和非静态成员变量，但是在非静态成员方法中是可以访问静态成员方法&#x2F;变量的。也就是说，反过来是可以的。</p><p>如果说想在不创建对象的情况下调用某个方法，就可以将这个方法设置为static。static修饰成员方法最大的作用，就是可以使用”类名.方法名”的方式调用方法，避免了new出对象的繁琐和资源消耗。</p><p>我们最常见的static方法就是main方法。至于为什么main方法必须是static的，这是因为程序在执行 main方法的时候没有创建任何对象，因此只有通过类名来访问。</p><h2 id="2-3-1-static-变量"><a href="#2-3-1-static-变量" class="headerlink" title="2.3.1 static 变量"></a>2.3.1 static 变量</h2><p>static变量也称作静态变量，静态变量和非静态变量的区别是：静态变量被所有的对象所共享，在内存中只有一个副本，它当且仅当在类初次加载时会被初始化。而非静态变量是对象所拥有的，在创建对象的时候被初始化，存在多个副本，各个对象拥有的副本互不影响。</p><p>static成员变量的初始化顺序按照定义的顺序进行初始化。</p><h2 id="2-3-2-static-代码块"><a href="#2-3-2-static-代码块" class="headerlink" title="2.3.2 static 代码块"></a>2.3.2 static 代码块</h2><p>static块可以置于类中的任何地方，类中可以有多个static块。在类初次被加载的时候，会按照static块的顺序来执行每个static块，并且只会执行一次。为什么说static块可以用来优化程序性能，是因为它的特性:只会在类加载的时候执行一次。</p><p>所谓的代码块就是当我们初始化static修饰的成员时，可以将他们统一放在一个以static开始，用花括号包裹起来的块状语句中。例如：</p><hr><p>class Person{</p><p>private Date birthDate;</p><p>public Person(Date birthDate){</p><p>this.birthDate ( &#x3D; ) birthDate;</p><p>}</p><p>boolean isBornBoomer(){</p><p>Date startDate ( &#x3D; ) Date.valueOf(“1946”);</p><p>Date endDate ( &#x3D; ) Date.valueOf(“1964”);</p><p>return birthDate.compareTo(startDate) ( &gt; &#x3D; 0&amp; ) birthDate.compareTo(endDate)</p><p>( &lt; 0 ) ;</p><p>}</p><p>}</p><hr><p>isBornBoomer是用来这个人是否是1946-1964年出生的，而每次isBornBoomer被调用的时候，都会生成startDate和birthDate两个对象，造成了空间浪费，如果改成这样效率会更好:</p><hr><p>class Person{</p><p>private Date birthDate;</p><p>private static Date startDate, endDate;</p><p>static{</p><p>startDate ( &#x3D; ) Date.valueOf(“1946”);</p><p>endDate ( &#x3D; ) Date.valueOf(“1964”);</p><p>}</p><p>public Person(Date birthDate){</p><p>this.birthDate ( &#x3D; ) birthDate;</p><p>}</p><p>boolean isBornBoomer(){</p><p>return birthDate.compareTo(startDate)&gt;&#x3D;0 &amp;&amp; birthDate.compareTo(endDate)</p><p>( &lt; 0 ) ;</p><p>}</p><p>}</p><hr><p>将一些只需要进行一次的初始化操作都放在static代码块中进行。</p><h2 id="2-4-this-关键字"><a href="#2-4-this-关键字" class="headerlink" title="2.4 this 关键字"></a>2.4 this 关键字</h2><p>this代表它所在函数所属对象的引用。简单说：哪个对象在调用this所在的函数，this就代表哪个对象。 this关键字主要有以下三个作用:</p><ol><li><p>this调用本类中的属性，也就是类中的成员变量;</p></li><li><p>this调用本类中的其他方法;</p></li><li><p>this调用本类中的其他构造方法，调用时要放在构造方法的首行。(this语句只能定义在构造函数的第一行，因为在初始化时须先执行)</p></li></ol><h2 id="2-4-1-引用成员变量"><a href="#2-4-1-引用成员变量" class="headerlink" title="2.4.1 引用成员变量"></a>2.4.1 引用成员变量</h2><p>public class Person{</p><p>String name; &#x2F;&#x2F;定义成员变量name</p><p>private void SetName(String name) { &#x2F;&#x2F;定义一个参数(局部变量)name</p><p>this. name&#x3D;name; &#x2F;&#x2F;将局部变量的值传递给成员变量</p><p>}</p><p>}</p><p>虽然我们可以看明白这个代码的含义，但是作为Java编译器它是怎么判断的呢?到底是将形式参数name 的值传递给成员变量name，还是反过来将成员变量name的值传递给形式参数name呢?也就是说，两个变量名字如果相同的话，那么Java如何判断使用哪个变量？此时this这个关键字就起到作用了。this这个关键字其代表的就是对象中的成员变量或者方法。也就是说，如果在某个变量前面加上一个this关键字， 其指的就是这个对象的成员变量或者方法，而不是指成员方法的形式参数或者局部变量。</p><h2 id="2-4-2-调用类的构造器方法"><a href="#2-4-2-调用类的构造器方法" class="headerlink" title="2.4.2 调用类的构造器方法"></a>2.4.2 调用类的构造器方法</h2><p>public class Person {</p><p>public Person(){ &#x2F;&#x2F;无参构造器方法</p><p>this(“Hello!”);</p><p>}</p><p>public Person(String name){ &#x2F;&#x2F;定义一个带形式参数的构造方法</p><p>}</p><p>}</p><p>在上述代码中，定义了两个构造方法，一个带参数，另一个没有带参数。在第一个没有带参数的构造方法中，使用了this(“Hello!”)这句代码，这句代码表示什么含义呢?在构造方法中使this关键字表示调用类中的构造方法。</p><p>如果一个类中有多个构造方法，因为其名字都相同，跟类名一致，那么这个this到底是调用哪个构造方法呢?其实，这跟采用其他方法引用构造方法一样，都是通过形式参数来调用构造方法的。</p><p>注意的是：利用this关键字来调用构造方法，只有在无参数构造方法中第一句使用this调用有参数的构造方法。否则的话，翻译的时候，就会有错误信息。这跟引用成员变量不同。如果引用成员变量的话，this 关键字是没有位置上的限制的。</p><h2 id="2-4-3-返回对象的引用"><a href="#2-4-3-返回对象的引用" class="headerlink" title="2.4.3 返回对象的引用"></a>2.4.3 返回对象的引用</h2><p>public HttpConfig url(String url) {</p><p>urls.set(url);</p><p>&#x2F;&#x2F;return this就是返回当前对象的引用(就是实际调用这个方法的实例化对象)</p><p>return this;</p><p>}</p><p>return this就是返回当前对象的引用(就是实际调用这个方法的实例化对象)，就像我们平时使用 StringBuilder一样，可以一直 ( {}^{.;} ) append ( ○ ) ，因为每次调用，返回的都是该对象的引用。</p><p>关于关键字，这篇文章就总结这么多，如有错误，欢迎指正，我们一起进步。</p><h1 id="3-Java的三大特性详解"><a href="#3-Java的三大特性详解" class="headerlink" title="3. Java的三大特性详解"></a>3. Java的三大特性详解</h1><h2 id="3-1-封装"><a href="#3-1-封装" class="headerlink" title="3.1 封装"></a>3.1 封装</h2><h2 id="3-1-1-public、private、protected修饰符"><a href="#3-1-1-public、private、protected修饰符" class="headerlink" title="3.1.1 public、private、protected修饰符"></a>3.1.1 public、private、protected修饰符</h2><p>说到封装，Java 中有三个访问权限修饰符：private、protected 以及 public，如果不加访问修饰符，表示包级可见。我们先来看下这三个修饰符的作用。</p><table><thead><tr><th>修饰符</th><th>当前类</th><th>同包</th><th>子类</th><th>其他包</th></tr></thead><tr><td>public</td><td>\( \sqrt{} \)</td><td>\( \sqrt{} \)</td><td>\( \sqrt{} \)</td><td>\( \sqrt{} \)</td></tr><tr><td>protected</td><td>\( \sqrt{} \)</td><td>\( \sqrt{} \)</td><td>\( \sqrt{} \)</td><td>\( \times \)</td></tr><tr><td>default</td><td>\( \sqrt{} \)</td><td>\( \sqrt{} \)</td><td>\( \times \)</td><td>\( \times \)</td></tr><tr><td>private</td><td>\( \sqrt{} \)</td><td>\( \times \)</td><td>\( \times \)</td><td>\( \times \)</td></tr></table><p>设计良好的模块会隐藏所有的实现细节，把它的 API 与它的实现清晰地隔离开来。模块之间只通过它们的 API 进行通信，一个模块不需要知道其他模块的内部工作情况，这个概念被称为信息隐藏或封装。因此访问权限应当尽可能地使每个类或者成员不被外界访问。</p><p>如果子类的方法重写了父类的方法，那么子类中该方法的访问级别不允许低于父类的访问级别。这是为了确保可以使用父类实例的地方都可以使用子类实例去代替，也就是确保满足里氏替换原则。</p><h2 id="3-1-2-规范"><a href="#3-1-2-规范" class="headerlink" title="3.1.2 规范"></a>3.1.2 规范</h2><p>字段决不能是公有的，因为这么做的话就失去了对这个字段修改行为的控制，客户端可以对其随意修改。例如下面的例子中，AccessExample 拥有 id 公有字段，如果在某个时刻，我们想要使用 int 存储 id 字段，那么就需要修改所有的客户端代码。</p><p>public class AccessExample {</p><p>public String id;</p><p>}</p><p>可以使用公有的 getter 和 setter 方法来替换公有字段，这样的话就可以控制对字段的修改行为。</p><p>public class AccessExample {</p><p>private int id;</p><p>public string ( \operatorname{getId()}{ )</p><p>return ( \mathrm + ) “”;</p><p>}</p><p>public void setId(String id) {</p><p>this.id ( &#x3D; ) Integer.valueOf(id);</p><p>}</p><p>}</p><h2 id="3-1-3-封装的好处"><a href="#3-1-3-封装的好处" class="headerlink" title="3.1.3 封装的好处"></a>3.1.3 封装的好处</h2><ol><li><p>提高数据的安全性。</p></li><li><p>操作简单。</p></li><li><p>隐藏了实现。</p></li></ol><h2 id="3-2-继承"><a href="#3-2-继承" class="headerlink" title="3.2 继承"></a>3.2 继承</h2><p>继承是类与类的一种关系，是一种“is a”的关系。比如“狗”继承“动物”，这里动物类是狗类的父类或者基类，狗类是动物类的子类或者派生类。如下图所示:</p><p><img src="/../img/java/2.jpg" alt="2"> 父类、基类子类、派生类</p><p>注: java中的继承是单继承，即一个类只有一个父类。</p><h2 id="3-2-1-继承的初始化顺序"><a href="#3-2-1-继承的初始化顺序" class="headerlink" title="3.2.1 继承的初始化顺序"></a>3.2.1 继承的初始化顺序</h2><ol><li><p>初始化父类再初始化子类</p></li><li><p>先执行初始化对象中属性，再执行构造方法中的初始化。</p></li></ol><p>基于上面两点，我们就知道实例化一个子类，java程序的执行顺序是:</p><p>父类对象属性初始化—-&gt;父类对象构造方法—-&gt;子类对象属性初始化—&gt;子类对象构造方法继承这块大家都比较熟，我来举个例子:</p><h2 id="3-2-2-继承示例"><a href="#3-2-2-继承示例" class="headerlink" title="3.2.2 继承示例"></a>3.2.2 继承示例</h2><p>Animal动物:</p><p>public class Animal {</p><p>&#x2F;*<em>名称</em>&#x2F;</p><p>public String name;</p><p>&#x2F;*<em>颜色</em>&#x2F;</p><p>public string color;</p><p>&#x2F;*<em>显示信息</em>&#x2F;</p><p>public void show(){</p><p>System.out.println(“名称: “+name+”, 颜色: “+color);</p><p>}</p><p>}</p><p>&#x2F;*<em>狗继承自动物, 子类 is a 父类</em>&#x2F;</p><p>public class Dog extends Animal {</p><p>&#x2F;*<em>价格</em>&#x2F;</p><p>public double price;</p><p>}</p><p>dog并没有定义color属性，但在使用中可以调用，是因为dog继承了父类Animal，父类的非私有成员将被子类继承。如果再定义其它的动物类则无须再反复定义name，color与show方法。</p><h2 id="3-3-多态"><a href="#3-3-多态" class="headerlink" title="3.3 多态"></a>3.3 多态</h2><p>多态这块，我要跟大家好好唠叨唠叨，首先来看下概念:</p><h2 id="3-3-1-多态概念"><a href="#3-3-1-多态概念" class="headerlink" title="3.3.1 多态概念"></a>3.3.1 多态概念</h2><p>多态: 一个对象具备多种形态。</p><p>①父类的引用类型变量指向了子类的对象</p><p>②接口的引用类型变量指向了接口实现类的对象</p><p>多态的前提: 必须存在继承或者实现关系。</p><p>动物 ( a &#x3D; ) new 狗 ( O ) ;</p><h2 id="3-3-2-多态要注意的细节"><a href="#3-3-2-多态要注意的细节" class="headerlink" title="3.3.2 多态要注意的细节"></a>3.3.2 多态要注意的细节</h2><ol><li><p>多态情况下，子父类存在同名的成员变量时，访问的是父类的成员变量。</p></li><li><p>多态情况下，子父类存在同名的非静态的成员函数时，访问的是子类的成员函数。</p></li><li><p>多态情况下，子父类存在同名的静态的成员函数时，访问的是父类的成员函数。</p></li><li><p>多态情况下，不能访问子类特有的成员。</p></li></ol><p>总结: 多态情况下，子父类存在同名的成员时，访问的都是父类的成员，除了在同名非静态函数时才是访问子类的。</p><p>注意：java编译器在编译的时候，会检查引用类型变量所属的类是否具备指定的成员，如果不具备马上编译报错。（编译看左边）</p><h2 id="3-3-3-多态的应用"><a href="#3-3-3-多态的应用" class="headerlink" title="3.3.3 多态的应用"></a>3.3.3 多态的应用</h2><ol><li><p>多态用于形参类型的时候，可以接收更多类型的数据。</p></li><li><p>多态用于返回值类型的时候，可以返回更多类型的数据。</p></li></ol><p>多态的好处：提高了代码的拓 展性。</p><p>我们想想，平时写MVC三层模型的时候，service为什么要写接口呢？因为可能有个service会有多种不同的实现。service就是我们平时用多态最多的地方。</p><h1 id="4-Java-中的-String-详解"><a href="#4-Java-中的-String-详解" class="headerlink" title="4. Java 中的 String 详解"></a>4. Java 中的 String 详解</h1><h2 id="4-1-看看源码"><a href="#4-1-看看源码" class="headerlink" title="4.1 看看源码"></a>4.1 看看源码</h2><p>大家都知道，String 被声明为 final，因此它不可被继承。(Integer 等包装类也不能被继承) 。我们先来看看 String 的源码。</p><p>在 Java 8 中，String 内部使用 char 数组存储数据。</p><p>public final class string</p><p>implements java.io.serializable, Comparable<String>, Charsequence {</p><p>&#x2F;** The value is used for character storage. *&#x2F;</p><p>private final char value[];</p><p>}</p><p>在 Java 9 之后，String 类的实现改用 byte 数组存储字符串，同时使用 coder 来标识使用了哪种编码。</p><p>public final class String</p><p>implements java.io.serializable, Comparable<String>, Charsequence {</p><p>&#x2F;** The value is used for character storage. *&#x2F;</p><p>private final byte[] value;</p><p>&#x2F;** The identifier of the encoding used to encode the bytes in {@code value}.</p><p>*&#x2F;</p><p>private final byte coder;</p><p>}</p><p>value 数组被声明为 final，这意味着 value 数组初始化之后就不能再引用其它数组。并且 String 内部没有改变 value 数组的方法，因此可以保证 String 不可变。</p><h2 id="4-2-不可变有什么好处呢"><a href="#4-2-不可变有什么好处呢" class="headerlink" title="4.2 不可变有什么好处呢"></a>4.2 不可变有什么好处呢</h2><h2 id="4-2-1-可以缓存-hash-值"><a href="#4-2-1-可以缓存-hash-值" class="headerlink" title="4.2.1 可以缓存 hash 值"></a>4.2.1 可以缓存 hash 值</h2><p>因为 String 的 hash 值经常被使用，例如 String 用做 HashMap 的 key。不可变的特性可以使得 hash 值也不可变，因此只需要进行一次计算。</p><h2 id="4-2-2-String-Pool-的使用"><a href="#4-2-2-String-Pool-的使用" class="headerlink" title="4.2.2 String Pool 的使用"></a>4.2.2 String Pool 的使用</h2><p>如果一个 String 对象已经被创建过了，那么就会从 String Pool 中取得引用。只有 String 是不可变的， 才可能使用 String Pool。</p><h2 id="4-2-3-安全性"><a href="#4-2-3-安全性" class="headerlink" title="4.2.3 安全性"></a>4.2.3 安全性</h2><p>String 经常作为参数，String 不可变性可以保证参数不可变。例如在作为网络连接参数的情况下如果 String 是可变的，那么在网络连接过程中，String 被改变，改变 String 的那一方以为现在连接的是其它主机，而实际情况却不一定是。</p><h2 id="4-2-4-线程安全"><a href="#4-2-4-线程安全" class="headerlink" title="4.2.4 线程安全"></a>4.2.4 线程安全</h2><p>String 不可变性天生具备线程安全，可以在多个线程中安全地使用。</p><h2 id="4-3-再来深入了解一下-String"><a href="#4-3-再来深入了解一下-String" class="headerlink" title="4.3 再来深入了解一下 String"></a>4.3 再来深入了解一下 String</h2><h2 id="4-3-1-“-”-连接符"><a href="#4-3-1-“-”-连接符" class="headerlink" title="4.3.1 “+” 连接符"></a>4.3.1 “+” 连接符</h2><p>字符串对象可以使用“+”连接其他对象，其中字符串连接是通过 StringBuilder（或 StringBuffer）类及其 append 方法实现的，对象转换为字符串是通过 toString 方法实现的。可以通过反编译验证一下:</p><hr><p>&#x2F;**</p><ul><li>测试代码</li></ul><p>*&#x2F;</p><p>public class Test {</p><p>public static void main(String[] args) {</p><p>int ( i &#x3D; {10} ) ;</p><p>String ( s &#x3D; ) “abc”;</p><p>System.out.println(s + i);</p><p>}</p><p>}</p><p>&#x2F;**</p><ul><li>反编译后</li></ul><p>*&#x2F;</p><p>public class Test {</p><p>public static void main(String args[]) { &#x2F;&#x2F;删除了默认构造函数和字节码</p><p>byte byte0 ( &#x3D; {10} ) ;</p><p>String ( s &#x3D; ) “abc”;</p><p>System.out.println((new</p><p>StringBuilder()).append(s).append(byte0).toString());</p><p>}</p><p>}</p><hr><p>由上可以看出，Java中使用”+”连接字符串对象时，会创建一个StringBuilder()对象，并调用append()方法将数据拼接，最后调用toString()方法返回拼接好的字符串。那这个 “+” 的效率怎么样呢?</p><h2 id="4-3-2-“-”连接符的效率"><a href="#4-3-2-“-”连接符的效率" class="headerlink" title="4.3.2 “+”连接符的效率"></a>4.3.2 “+”连接符的效率</h2><p>使用“+”连接符时，JVM会隐式创建StringBuilder对象，这种方式在大部分情况下并不会造成效率的损失，不过在进行大量循环拼接字符串时则需要注意。比如：</p><p>String ( s &#x3D; ) “abc”;</p><p>for (int i&#x3D;0; i&lt;10000; i++) {</p><p>( \mathrm{s} + &#x3D; ) “abc”;</p><p>}</p><p>这样由于大量StringBuilder创建在堆内存中，肯定会造成效率的损失，所以在这种情况下建议在循环体外创建一个StringBuilder对象调用append()方法手动拼接（如上面例子如果使用手动拼接运行时间将缩小到1&#x2F;200左右）。</p><p>与此之外还有一种特殊情况，也就是当”+”两端均为编译期确定的字符串常量时，编译器会进行相应的优化，直接将两个字符串常量拼接好，例如:</p><p>System.out.println(“Hello” + “world”);</p><p>&#x2F;**</p><ul><li>反编译后</li></ul><p>*&#x2F;</p><p>System.out.println(“Helloworld”);</p><h2 id="4-4-字符串常量"><a href="#4-4-字符串常量" class="headerlink" title="4.4 字符串常量"></a>4.4 字符串常量</h2><p>JVM为了提高性能和减少内存的开销，在实例化字符串的时候进行了一些优化：使用字符串常量池。每当创建字符串常量时，JVM会首先检查字符串常量池，如果该字符串已经存在常量池中，那么就直接返回常量池中的实例引用。如果字符串不存在常量池中，就会实例化该字符串并且将其放到常量池中。由于 String字符串的不可变性，常量池中一定不存在两个相同的字符串。</p><p><img src="/../img/java/3.jpg" alt="3"></p><p>我们来看一个例子:</p><p>&#x2F;**</p><ul><li>运行结果为true false</li></ul><p>*&#x2F;</p><p>String ( {s1} &#x3D; ) “abc”;</p><p>string ( {s2} &#x3D; ) “abc”;</p><p>String ( {s3} &#x3D; ) new String(“abc”);</p><p>System.out.println(s1 &#x3D;&#x3D; s2);</p><p>System.out.println(s1 &#x3D;&#x3D; s3);</p><p>由于常量池中不存在两个相同的对象，所以s1和s2都是指向JVM字符串常量池中的”AB”对象。new关键字一定会产生一个对象，并且这个对象存储在堆中。所以string s3 &#x3D; new string(“AB”); 产生了两个对象：保存在栈中的s3和保存堆中的String对象。</p><h1 id="5-StringBuffer-和-StringBuilder-详解"><a href="#5-StringBuffer-和-StringBuilder-详解" class="headerlink" title="5. StringBuffer 和 StringBuilder 详解"></a>5. StringBuffer 和 StringBuilder 详解</h1><p>StringBuilder 和 StringBuffer 的问题已经是老生常谈了，但是为什么还有那么多面试官喜欢问这个问题呢? 不知道，我觉得是面试官太low了……</p><p>不过我也来把这个知识点给大家总结一下，先说说他们的相同点。</p><h2 id="5-1-相同点"><a href="#5-1-相同点" class="headerlink" title="5.1 相同点"></a>5.1 相同点</h2><p>说到这单，我又忍不住要跟大家唠叨唠叨 String 了，我们先看下 String 的一个例子:</p><p>String a &#x3D; “123”;</p><p>a ( &#x3D; ) “456”;</p><p>&#x2F;&#x2F; 打印出来的a为456</p><p>System.out.println(a)</p><p>不是说 String 是不可改变的吗? 这怎么就变了呢? 逗我吗? 其实是没变的，原来那个 123 没变，相当于重新创建了一个 456，然后把 a 指向了这个 456，那个 123 会被回收掉。看看我给大家画的图：</p><p><img src="/../img/java/4.jpg" alt="4"></p><p>而 StringBuffer 和 StringBuilder 就不一样了，他们是可变的，当一个对象被创建以后，通过 append()、insert()、reverse()、setcharAt()、setLength()等方法可以改变这个字符串对象</p><p>的字符序列。也来看个例子:</p><p>StringBuffer ( b &#x3D; ) new StringBuffer(“123”);</p><p>b.append(“456”);</p><p>&#x2F;&#x2F; b打印结果为: 123456</p><p>System.out.println(b);</p><p><img src="/../img/java/5.jpg" alt="5"></p><p>OK，那现在我们知道了，StringBuffer 和 StringBuilder 有个共同点，那就是它们代表一个字符可变的字符串。那除此之外，还有没有其他相同点呢?</p><p>肯定是有的，比如:</p><ol><li><p>StringBuilder 与 StringBuffer 有公共父类 AbstractStringBuilder (抽象类);</p></li><li><p>StringBuilder、StringBuffer 的方法都会调用 AbstractStringBuilder 中的公共方法，如 super.append(…)。</p></li></ol><h2 id="5-2-不同点"><a href="#5-2-不同点" class="headerlink" title="5.2 不同点"></a>5.2 不同点</h2><p>StringBuffer 是线程安全的，StringBuilder 是非线程安全的。我们看源码都知道，StringBuffer 的方法上面都加了 synchronized 关键字，所以没有线程安全问题，但是性能会受影响，所以 StringBuilder 会比 StringBuffer 快，在单线程环境下，建议使用 StringBuilder。</p><p>另外还有个不同点是缓冲区。</p><p>先看下 StringBuilder 的 tostring() 方法:</p><p>@override</p><p>public string toString() {</p><p>&#x2F;&#x2F; Create a copy, don’t share the array</p><p>return new String(value, 0, count);</p><p>}</p><p>再看下 StringBuffer 的 tostring () 方法:</p><p>@override</p><p>public synchronized String toString() {</p><p>if (tostringCache ( &#x3D; &#x3D; ) null) {</p><p>toStringCache ( &#x3D; ) Arrays.copyOfRange(value, 0, count);</p><p>}</p><p>return new String(toStringCache, true);</p><p>}</p><p>可以看出：StringBuffer 每次获取 toString 都会直接使用缓存区的 toStringCache 值来构造一个字符串。而 StringBuilder 则每次都需要复制一次字符数组，再构造一个字符串。</p><p>所以，StringBuffer 对缓存区优化，不过 StringBuffer 的这个toString 方法仍然是同步的。</p><p>OK，StringBuffer 和 StringBuilder 就总结这么多吧，如有问题，欢迎指正。</p><h1 id="6-Java-反射详解"><a href="#6-Java-反射详解" class="headerlink" title="6. Java 反射详解"></a>6. Java 反射详解</h1><p>反射是框架设计的灵魂要素！</p><h2 id="6-1-反射是什么"><a href="#6-1-反射是什么" class="headerlink" title="6.1 反射是什么?"></a>6.1 反射是什么?</h2><p>所谓的反射就是java语言在运行时拥有的一种自观的能力,反射使您的程序代码能够得到装载到VM中的类的内部信息,允许您执行程序时才得到需要类的内部信息，而不是在编写代码的时候就必须要知道所需类的内部信息;也可以通俗的将这种动态获取信息以及动态调用对象的方法称为Java的反射机制.</p><p>通过Java的反射机制,程序猿们可以更深入的控制程序的运行过程,如在程序运行时对用户输入的信息进行验证,还可以逆向控制程序的执行过程，这也使反射成为构建灵活的应用的主要工具。</p><h2 id="6-2-反射原理大解析"><a href="#6-2-反射原理大解析" class="headerlink" title="6.2 反射原理大解析"></a>6.2 反射原理大解析</h2><h2 id="6-2-1-反射的常用类和函数"><a href="#6-2-1-反射的常用类和函数" class="headerlink" title="6.2.1 反射的常用类和函数"></a>6.2.1 反射的常用类和函数</h2><p>Java反射机制的实现要借助于4个类:</p><ul><li><p>Class 类对象</p></li><li><p>Constructor 类的构造器对象</p></li><li><p>Field 类的属性对象</p></li><li><p>Method 类的方法对象</p></li></ul><h2 id="6-2-2-Class-类包含的方法"><a href="#6-2-2-Class-类包含的方法" class="headerlink" title="6.2.2 Class 类包含的方法"></a>6.2.2 Class 类包含的方法</h2><p>通过这四个对象我们可以粗略的看到一个类的各个组成部分。其中最核心的就是Class类，它是实现反射的基础，Class类包含的方法主要有:</p><table><thead><tr><th>序号</th><th>名称</th><th>功能</th></tr></thead><tr><td>1</td><td>getName()</td><td>获取此类型的全限定名</td></tr><tr><td>2</td><td>getSuperClass()</td><td>得到此类型的直接超类的全限定名</td></tr><tr><td>3</td><td>isInterface()</td><td>判断此类型是类类型还是接口类型</td></tr><tr><td>4</td><td>getTypeParamters()</td><td>获取这个类型的访问修饰符</td></tr><tr><td>5</td><td>getInterfaces()</td><td>获取任何直接超接口的全限定名的有序列表</td></tr><tr><td>6</td><td>getFields()</td><td>获取字段信息</td></tr><tr><td>7</td><td>getMethods()</td><td>获取方法信息</td></tr></table><h2 id="6-2-3-反射的主要方法"><a href="#6-2-3-反射的主要方法" class="headerlink" title="6.2.3 反射的主要方法"></a>6.2.3 反射的主要方法</h2><p>应用反射时我们最关心的一般是一个类的构造器、属性和方法，下面我们主要介绍Class类中针对这三个元素的方法:</p><h2 id="6-2-3-1-得到构造器的方法"><a href="#6-2-3-1-得到构造器的方法" class="headerlink" title="6.2.3.1 得到构造器的方法"></a>6.2.3.1 得到构造器的方法</h2><table><thead><tr><th>语法</th><th>功能</th></tr></thead><tr><td>Constructor getConstructor(Class[] params)</td><td>获得使用特殊的参数类型的公共构造函数</td></tr><tr><td>Constructor[] getConstructors()</td><td>获得类的所有公共构造函数</td></tr><tr><td>Constructor getDeclaredConstructor(Class[] params)</td><td>获得使用特定参数类型的构造函数(与接入 级别无关）</td></tr><tr><td>Constructor[] getDeclaredConstructors()</td><td>获得类的所有构造函数(与接入级别无关)</td></tr></table><h2 id="6-2-3-2-获得字段信息的方法"><a href="#6-2-3-2-获得字段信息的方法" class="headerlink" title="6.2.3.2 获得字段信息的方法"></a>6.2.3.2 获得字段信息的方法</h2><table><thead><tr><th>语法</th><th>功能</th></tr></thead><tr><td>Field getField(String name)</td><td>获得命名的公共字段</td></tr><tr><td>Field[] getFields()</td><td>获得类的所有公共字段</td></tr><tr><td>Field getDeclaredField(String name)</td><td>获得类声明的命名的字段</td></tr><tr><td>Field[] getDeclaredFields()</td><td>获得类声明的所有字段</td></tr></table><h2 id="6-2-3-3-获得方法信息的方法"><a href="#6-2-3-3-获得方法信息的方法" class="headerlink" title="6.2.3.3 获得方法信息的方法"></a>6.2.3.3 获得方法信息的方法</h2><table><thead><tr><th>语法</th><th>功能</th></tr></thead><tr><td>Method getMethod(String name, Class[] params)</td><td>使用特定的参数类型，获得命名的公共 方法</td></tr><tr><td>Method[] getMethods()</td><td>获得类的所有公共方法</td></tr><tr><td>Method getDeclaredMethod(String name, Class[] params)</td><td>使用特写的参数类型，获得类声明的命 名的方法</td></tr><tr><td>Method[] getDeclaredMethods()</td><td>获得类声明的所有方法</td></tr></table><h2 id="6-2-4-反射实战的基本步骤"><a href="#6-2-4-反射实战的基本步骤" class="headerlink" title="6.2.4 反射实战的基本步骤"></a>6.2.4 反射实战的基本步骤</h2><p>Class actionClass&#x3D;Class.forName(“MyClass”);</p><p>Object action&#x3D;actionClass.newInstance();</p><p>Method method ( &#x3D; ) actionClass.getMethod(“myMethod”, null);</p><p>method.invoke(action, null);</p><p>上面就是最常见的反射使用的例子，前两行实现了类的装载、链接和初始化（newInstance方法实际上也是使用反射调用了<init>方法），后两行实现了从class对象中获取到method对象然后执行反射调用。下面简单分析一下该代码的具体原理。</p><h2 id="6-2-4-1-获得类的Class对象"><a href="#6-2-4-1-获得类的Class对象" class="headerlink" title="6.2.4.1 获得类的Class对象"></a>6.2.4.1 获得类的Class对象</h2><p>通常有三种不同的方法:</p><ol><li><p>Class ( \mathrm{c} &#x3D; ) Class.forName(“java.lang.String”)</p></li><li><p>Class ( \mathrm{c} &#x3D; ) MyClass.class</p></li><li><p>对于基本数据类型可以用Class ( \mathrm{c} &#x3D; ) int.class 或 Class ( \mathrm{c} &#x3D; ) Integer.TYPE这样的语句.</p></li></ol><p>举个小栗子：先通过反射机制得到某个类的构造器，然后调用该构造器创建该类的一个实例</p><p>PS：反射的原理之一其实就是动态的生成类似于上述的字节码，加载到jvm中运行。</p><p>设想一下，上面的代码中，如果想要实现 method. invoke (action, null) 调用action对象的 myMethod 方法,只需要实现这样一个Method类即可:</p><p>class Method{</p><p>public Object invoke(Object obj, Object[] param){</p><p>MyClass myClass&#x3D;(MyClass)obj;</p><p>return myClass.myMethod();</p><p>}</p><p>}</p><h2 id="6-2-4-2-获取-Method-对象"><a href="#6-2-4-2-获取-Method-对象" class="headerlink" title="6.2.4.2 获取 Method 对象"></a>6.2.4.2 获取 Method 对象</h2><p>首先来看一下Method对象是如何生成的:</p><ul><li><p>使用Method m &#x3D;myclass.getMethod(“myMethod”)获得了一个Class对象</p></li><li><p>接着对其进行判断,如果没有对应的cache,那么JVM就会为其创建一个并放入缓冲空间</p></li><li><p>处理器再判断Cache中是否存在”myMethod”</p></li><li><p>如果没有则返回NoSuchMethodException</p></li><li><p>如果存在那么就Copy一份”myMethod”对象并返回</p></li></ul><p>上面的Class对象是在加载类时由JVM构造的，JVM为每个类管理一个独一无二的Class对象，这份Class对象里维护着该类的所有Method，Field，Constructor的cache，这份cache也可以被称作根对象。每次 getMethod获取到的Method对象都持有对根对象的引用，因为一些重量级的Method的成员变量（主要是MethodAccessor），我们不希望每次创建Method对象都要重新初始化，于是所有代表同一个方法的 Method对象都共享着根对象的MethodAccessor，每一次创建都会调用根对象的copy方法复制一份：</p><p>Method copy() {</p><p>Method res &#x3D; new Method(clazz, name, parameterTypes, returnType,</p><p>exceptionTypes, modifiers, slot, signature,</p><p>annotations, parameterAnnotations,</p><p>annotationDefault);</p><p>res.root ( &#x3D; ) this;</p><p>res.methodAccessor ( &#x3D; ) methodAccessor;</p><p>return res;</p><h2 id="6-2-4-3-调用invoke-方法"><a href="#6-2-4-3-调用invoke-方法" class="headerlink" title="6.2.4.3 调用invoke()方法"></a>6.2.4.3 调用invoke()方法</h2><p>获取到Method对象之后，调用invoke方法的流程如下:</p><p>m.invoke(obj, param);</p><ul><li><p>首先调用MethodAccess.invoke</p></li><li><p>如果该方法的累计调用次数&lt;&#x3D;15，会创建出NativeMethodAccessorImp</p></li><li><p>如果该方法的累计调用次数 ( &gt; {15} ) ，会由java代码创建出字节码组装而成的</p></li></ul><p>MethodAccessorImpl</p><p>我们可以看到，调用Method.invoke之后，会直接去调 MethodAccessor.invoke 。MethodAccessor就是上面提到的所有同名method共享的一个实例，由ReflectionFactory创建。创建机制采用了一种名为 inflation的方式 (JDK1.4之后) : 如果该方法的累计调用次数&lt;&#x3D;15, 会创建出</p><p>NativeMethodAccessorImpl，它的实现就是直接调用native方法实现反射；如果该方法的累计调用次数 &gt;15，会由java代码创建出字节码组装而成的MethodAccessorImpl。（是否采用inflation和15这个数字都可以在jvm参数中调整)</p><p>以调用 MyClass.myMethod(String s) 为例，生成出的MethodAccessorImpl字节码翻译成Java代码大致如下:</p><p>public class GeneratedMethodAccessor1 extends MethodAccessorImpl {</p><p>public Object invoke(Object obj, Object[] args) throws Exception {</p><p>try ( { )</p><p>MyClass target ( &#x3D; ) (MyClass) obj;</p><p>String arg0 &#x3D; (String) args[0];</p><p>target.myMethod(arg0);</p><p>} catch (Throwable t) {</p><p>throw new InvocationTargetException(t);</p><p>}</p><p>}</p><p>}</p><p>通过对java运行过程的详细分析，我们可以发现其中第1次和第16次调用是最耗时的(初始化 NativeMethodAccessorImpl和字节码拼装MethodAccessorImpl)。初始化不可避免，因而native方式的初始化会更快，所以前几次的调用会采用native方法。</p><p>随着调用次数的增加，每次反射都使用JNI跨越native边界会对优化有阻碍作用，相对来说使用拼装出的字节码可以直接以Java调用的形式实现反射，发挥了JIT优化的作用，避免了JNI为了维护OopMap （HotSpot用来实现准确式GC的数据结构）进行封装&#x2F;解封装的性能损耗。</p><p>在已经创建了MethodAccessor的情况下，使用Java版本的实现会比native版本更快。所以当调用次数到达一定次数（15次）后，会切换成Java实现的版本，来优化未来可能的更频繁的反射调用。</p><h2 id="6-3-Java反射的应用-Hibernate框架"><a href="#6-3-Java反射的应用-Hibernate框架" class="headerlink" title="6.3 Java反射的应用(Hibernate框架)"></a>6.3 Java反射的应用(Hibernate框架)</h2><p>前面我们已经知道，Java 反射机制提供了一种动态链接程序组件的多功能方法，它允许程序创建和控制任何类的对象(根据安全性限制)之前，无需提前硬编码目标类。这些特性使得反射特别适用于创建以非常普通的方式与对象协作的库。例如，反射经常在持续存储对象为数据库、XML或其它外部格式的框架中使用。下面就已Hibernate框架为例像大家阐述一下反射的重要意义。</p><p>Hibernate是一个屏蔽了JDBC，实现了ORM的java框架，利用该框架我们可以抛弃掉繁琐的sql语句而是利用Hibernate中Session类的save()方法直接将某个类的对象存到数据库当中,也就是所涉及到sql语句的那些代码Hibernate帮我们做了。这时候就出现了一个问题, Hibernate怎样知道他要存的某个对象都有什么属性呢？这些属性都是什么类型呢？想一想,它在向数据库中存储该对象属性时的sql语句该怎么构造</p><p>呢? OK,反射的作用此刻就体现出来了!</p><p>下面我们以一个例子来进行阐述，比如我们定义了一个User类，这个User类中有20个属性和这些属性的 get和set方法，相应的在数据库中有一个User表，这个User表中对应着20个字段。假设我们从User表中提取了一条记录，现在需要将这条记录的20个字段的内容分别赋给一个User对象myUser的20个属性， 而Hibernate框架在编译的时候并不知道这个User类，他无法直接调用myUser.getXXX或者 myUser.setXXX方法，此时就用到了反射，具体处理过程如下:</p><ol><li><p>根据查询条件构造PreparedStament语句，该语句返回20个字段的值;</p></li><li><p>Hibernate通过读取配置文件得到User类的属性列表list(是一个String数组)以及这些属性的类型；</p></li><li><p>创建myUser所属类的Class对象c; ( \mathrm{c} &#x3D; ) myUser.getClass();</p></li><li><p>构造一个for循环，循环的次数为list列表的长度;</p></li></ol><p>。 读取list[i]的值，然后构造对应该属性的set方法；</p><p>。判断list[i]的类型XXX，调用PreparedStament语句中的getXXX(i)，进而得到i出字段的值；</p><p>。 将4.2中得到的值作为4.1中得到的set方法的参数，这样就完成了一个字段像一个属性的赋值， 如此循环直至程序运行结束;</p><p>如果没有反射难以想象实现这么复杂的功能将会有多么难！</p><p>话说回来,反射给我们带来便利的同时也有它自身的缺点，比如性能较低、安全性较低、过程比较复杂等等，感兴趣的读者也可以在实际工作中再深入研究哦！</p><h1 id="7-Java-异常详解"><a href="#7-Java-异常详解" class="headerlink" title="7. Java 异常详解"></a>7. Java 异常详解</h1><h2 id="7-1-异常的概念"><a href="#7-1-异常的概念" class="headerlink" title="7.1 异常的概念"></a>7.1 异常的概念</h2><p>如果某个方法不能按照正常的途径完成任务，就可以通过另一种路径退出方法。在这种情况下会抛出一个封装了错误信息的对象。此时，这个方法会立刻退出同时不返回任何值。另外，调用这个方法的其他代码也无法继续执行，异常处理机制会将代码执行交给异常处理器。</p><p><img src="/../img/java/6.jpg" alt="6"></p><h2 id="7-2-Java-中异常分为哪些种类"><a href="#7-2-Java-中异常分为哪些种类" class="headerlink" title="7.2 Java 中异常分为哪些种类"></a>7.2 Java 中异常分为哪些种类</h2><p>按照异常需要处理的时机分为编译时异常（也叫强制性异常）也叫CheckedException 和运行时异常（也叫非强制性异常）也叫RuntimeException。</p><p>只有java 语言提供了Checked 异常，Java 认为 Checked 异常都是可以被处理的异常，所以java 程序必须显式处理Checked 异常。如果程序没有处理Checked 异常，该程序在编译时就会发生错误无法编译。 这体现了Java 的设计哲学：没有完善错误处理的代码根本没有机会被执行。对Checked 异常处理方法有两种:</p><ol><li><p>当前方法知道如何处理该异常，则用try…catch 块来处理该异常。</p></li><li><p>当前方法不知道如何处理，则在定义该方法是声明抛出该异常。</p></li></ol><p>运行时异常只有当代码在运行时才发行的异常，编译时不需要try catch。Runtime 如除数是0 和数组下标越界等，其产生频繁，处理麻烦，若显示申明或者捕获将会对程序的可读性和运行效率影响很大。所以由系统自动检测并将它们交给缺省的异常处理程序。当然如果你有处理要求也可以显示捕获它们。</p><p>那么，调用下面的方法，会得到什么结果呢?</p><p>public int getNum(){</p><p>try {</p><p>int ( a &#x3D; 1&#x2F;0 ) ;</p><p>return 1 ;</p><p>} catch (Exception e) {</p><p>return 2;</p><p>}finally{</p><p>return 3;</p><p>}</p><p>}</p><p>代码在走到第3 行的时候遇到了一个MathException，这时第四行的代码就不会执行了，代码直接跳转到 catch语句中，走到第6 行的时候，异常机制有这么一个原则如果在catch 中遇到了return 或者异常等能使该函数终止的话那么有finally 就必须先执行完finally 代码块里面的代码然后再返回值。因此代码又跳到第 8 行，可惜第 8 行是一个return 语句，那么这个时候方法就结束了，因此第 6 行的返回结果就无法被真正返回。如果finally 仅仅是处理了一个释放资源的操作，那么该道题最终返回的结果就是2。因此上面返回值是3。</p><h2 id="7-3-error-和exception-有什么区别"><a href="#7-3-error-和exception-有什么区别" class="headerlink" title="7.3 error 和exception 有什么区别?"></a>7.3 error 和exception 有什么区别?</h2><p>Error 类和Exception 类的父类都是Throwable 类，他们的区别如下。</p><p>Error 类一般是指与虚拟机相关的问题，如系统崩溃，虚拟机错误，内存空间不足，方法调用栈溢出等。 对于这类错误的导致的应用程序中断，仅靠程序本身无法恢复和和预防，遇到这样的错误，建议让程序终止。</p><p>Exception 类表示程序可以处理的异常，可以捕获且可能恢复。遇到这类异常，应该尽可能处理异常，使程序恢复运行，而不应该随意终止异常。</p><p>Exception 类又分为运行时异常 (Runtime Exception) 和受检查的异常(Checked Exception )，运行时异常；ArithmaticException, IllegalArgumentException，编译能通过，但是一运行就终止了，程序不会处理运行时异常，出现这类异常，程序会终止。而受检查的异常，要么用try。。。catch 捕获，要么用 throws 字句声明抛出，交给它的父类处理，否则编译不会通过。</p><h2 id="7-4-throw-和-throws-的区别是什么"><a href="#7-4-throw-和-throws-的区别是什么" class="headerlink" title="7.4 throw 和 throws 的区别是什么?"></a>7.4 throw 和 throws 的区别是什么?</h2><p>Java 中的异常处理除了包括捕获异常和处理异常之外，还包括声明异常和抛出异常，可以通过 throws 关键字在方法上声明该方法要抛出的异常，或者在方法内部通过 throw 抛出异常对象。</p><p>throws 关键字和 throw 关键字在使用上的几点区别如下:</p><ol><li><p>throw 关键字用在方法内部，只能用于抛出一种异常，用来抛出方法或代码块中的异常，受查异常和非受查异常都可以被抛出。</p></li><li><p>throws 关键字用在方法声明上，可以抛出多个异常，用来标识该方法可能抛出的异常列表。一个方法用 throws 标识了可能抛出的异常列表，调用该方法的方法中必须包含可处理异常的代码，否则也要在方法签名中用 throws 关键字声明相应的异常。</p></li></ol><h2 id="7-5-Java-的异常处理机制"><a href="#7-5-Java-的异常处理机制" class="headerlink" title="7.5 Java 的异常处理机制"></a>7.5 Java 的异常处理机制</h2><p>Java 对异常进行了分类，不同类型的异常分别用不同的Java 类表示，所有异常的根类为</p><p>java.lang.Throwable，Throwable 下面又派生了两个子类：Error 和Exception，Error 表示应用程序本身无法克服和恢复的一种严重问题。</p><p>Exception 表示程序还能够克服和恢复的问题，其中又分为系统异常和普通异常，系统异常是软件本身缺陷所导致的问题，也就是软件开发人员考虑不周所导致的问题，软件使用者无法克服和恢复这种问题， 但在这种问题下还可以让软件系统继续运行或者让软件死掉，例如，数组脚本越界</p><p>（ArrayIndexOutOfBoundsException），空指针异常（NullPointerException）、类转换异常</p><p>（ClassCastException）；普通异常是运行环境的变化或异常所导致的问题，是用户能够克服的问题，</p><p>例如，网络断线，硬盘空间不够，发生这样的异常后，程序不应该死掉。java 为系统异常和普通异常提供了不同的解决方案，编译器强制普通异常必须try..catch 处理或用throws 声明继续抛给上层调用方法处理，所以普通异常也称为checked 异常，而系统异常可以处理也可以不处理，所以，编译器不强制用 try..catch 处理或用throws 声明，所以系统异常也称为unchecked 异常。</p><h2 id="7-6-请写出你最常见的5-个RuntimeException"><a href="#7-6-请写出你最常见的5-个RuntimeException" class="headerlink" title="7.6 请写出你最常见的5 个RuntimeException"></a>7.6 请写出你最常见的5 个RuntimeException</h2><p>这是面试过程中，很喜欢问的问题，下面列举几个常见的RuntimeException。</p><p>1）java.lang.NullPointerException 空指针异常；出现原因：调用了未经初始化的对象或者是不存在的对象。</p><p>2）java.lang.ClassNotFoundException 指定的类找不到；出现原因：类的名称和路径加载错误；通常都是程序试图通过字符串来加载某个类时可能引发异常。</p><p>3）java.lang.NumberFormatException 字符串转换为数字异常；出现原因：字符型数据中包含非数字型字符。</p><p>4）java.lang.IndexOutOfBoundsException 数组角标越界异常，常见于操作数组对象时发生。</p><p>5）java.lang.IllegalArgumentException 方法传递参数错误。</p><ol start="6"><li>java.lang.ClassCastException 数据类型转换异常。</li></ol><p>7）java.lang.NoClassDefFoundException 未找到类定义错误。</p><p>8）SQLException SQL 异常，常见于操作数据库时的SQL 语句错误。</p><ol start="9"><li><p>java.lang.InstantiationException 实例化异常。</p></li><li><p>java.lang.NoSuchMethodException 方法不存在异常。</p></li></ol><h2 id="7-7-final、finally、finalize-的区别"><a href="#7-7-final、finally、finalize-的区别" class="headerlink" title="7.7 final、finally、finalize 的区别"></a>7.7 final、finally、finalize 的区别</h2><ol><li><p>final：用于声明属性，方法和类，分别表示属性不可变，方法不可覆盖，被其修饰的类不可继承。</p></li><li><p>finally: 异常处理语句结构的一部分，表示总是执行。</p></li><li><p>finalize：Object 类的一个方法，在垃圾回收器执行的时候会调用被回收对象的此方法，可以覆盖此方法提供垃圾收集时的其他资源回收，例如关闭文件等。该方法更像是一个对象生命周期的临终方法，</p></li></ol><p>当该方法被系统调用则代表该对象即将“死亡”，但是需要注意的是，我们主动行为上去调用该方法并不会导致该对象“死亡”，这是一个被动的方法（其实就是回调方法），不需要我们调用。</p><h2 id="7-8-NoClassDefFoundError-和-ClassNotFoundException-区别"><a href="#7-8-NoClassDefFoundError-和-ClassNotFoundException-区别" class="headerlink" title="7.8 NoClassDefFoundError 和 ClassNotFoundException 区别"></a>7.8 NoClassDefFoundError 和 ClassNotFoundException 区别</h2><p>NoClassDefFoundError 是一个 Error 类型的异常，是由 JVM 引起的，不应该尝试捕获这个异常。</p><p>引起该异常的原因是 JVM 或 ClassLoader 尝试加载某类时在内存中找不到该类的定义，该动作发生在运行期间，即编译时该类存在，但是在运行时却找不到了，可能是变异后被删除了等原因导致；</p><p>ClassNotFoundException 是一个受查异常，需要显式地使用 try-catch 对其进行捕获和处理，或在方法签名中用 throws 关键字进行声明。当使用 Class.forName, ClassLoader.loadClass 或</p><p>ClassLoader.findSystemClass 动态加载类到内存的时候，通过传入的类路径参数没有找到该类，就会抛出该异常；另一种抛出该异常的可能原因是某个类已经由一个类加载器加载至内存中，另一个加载器又尝试去加载它。</p><p>Java 异常 就总结这么多，如果有问题，欢迎讨论。</p><h1 id="8-Java-IO-流详解"><a href="#8-Java-IO-流详解" class="headerlink" title="8. Java IO 流详解"></a>8. Java IO 流详解</h1><h2 id="8-1-Java-IO概念"><a href="#8-1-Java-IO概念" class="headerlink" title="8.1 Java IO概念"></a>8.1 Java IO概念</h2><p>Java IO：即 Java 输入 &#x2F; 输出系统。</p><p>Java 的 IO 模型设计非常优秀，它使用 Decorator (装饰者)模式，按功能划分 stream，您可以动态装配这些 stream，以便获得您需要的功能。</p><p>Stream：JAVA 中将数据的输入输出抽象为流，流是一组有顺序的、单向的，有起点和终点的数据集合。按照流中的最小数据单元又分为字节流和字符流。</p><p>IO 流用来处理设备之间的数据传输，Java 程序中，对于数据的输入&#x2F;输出操作 都是以“流”的方式进行的。 java.io 包下提供了各种“流”类的接口，用以获取不同种类的数据，并通过标准的方法输入或输出数据。</p><p>对于计算机来说，数据是以二进制形式读出或写入。我们可以把文件想象为一个桶，我们通过管道将桶里的水抽出来。这里的管道也就相当于Java中的流。流的本质是一种有序的数据集合，有数据源和目的地。</p><h2 id="8-2-Java-IO流分类"><a href="#8-2-Java-IO流分类" class="headerlink" title="8.2 Java IO流分类"></a>8.2 Java IO流分类</h2><ol><li>按照流的方向 (输出输入都是站在程序所在内存的角度为依据划分的)</li></ol><p>。 输入流：只能从内存中读数据</p><p>。 输出流：只能向文件中写数据</p><p>○ 输入：读取外部数据（磁盘、光盘等存储设备的数据）到程序（内存）中。</p><p>。 输出：将程序（内存）数据输出到磁盘、光盘等存储设备中</p><table><thead><tr><th>.</th><th>字节流</th><th>字符流</th></tr></thead><tr><td>输入流</td><td>InputStream</td><td>Reader</td></tr><tr><td>输出流</td><td>OutputStream</td><td>Writer</td></tr></table><ul><li><p>Inputstream: 字节输入流</p></li><li><p>OutputStream: 字节输出流</p></li><li><p>Reader: 字符输入流</p></li><li><p>Writer: 字符输出流</p></li></ul><p>在日常工作中，字节流一般用来处理图像，视频，以及PPT，Word类型的文件。字符流一般用于处理纯文本类型的文件，如TXT文件等，字节流可以用来处理纯文本文件，但是字符流不能用于处理图像视频等非文本类型的文件。</p><ol start="2"><li>按处理数据单位(字节流与字符流)</li></ol><p>1字符 &#x3D; 2字节 、 1字节(byte) &#x3D; 8位(bit) 、 一个汉字占两个字节长度</p><p>。 字节流：每次读取(写出)一个字节，当传输的资源文件有中文时，就会出现乱码。</p><p>。 字符流：每次读取(写出)两个字节，有中文时，使用该流就可以正确传输显示中文。</p><ol start="3"><li>按功能不同分为(节点流与处理流)</li></ol><p>○ 节点流：以从或向一个特定的地方 (节点) 读写数据。</p><ul><li><p>文件流: FileInputStream, FileOutputStrean, FileReader, FileWriter, 它们都会直接操作文件，直接与 OS 底层交互。因此他们被称为节点流，注意：使用这几个流的对象之后，需要关闭流对象，因为 java 垃圾回收器不会主动回收。不过在 Java7 之后，可以在 try() 括号中打开流，最后程序会自动关闭流对象，不再需要显示地 close。</p></li><li><p>数组流: ByteArrayInputStream, ByteArrayOutputStream, CharArrayReader,</p></li></ul><p>CharArrayWriter，对数组进行处理的节点流。</p><ul><li><p>字符串流: StringReader, StringWriter, 其中 StringReader 能从 String 中读取数据并保存到 char 数组。</p></li><li><p>管道流: PipedInputStream, PipedOutputStream, PipedReader, PipedWrite, 对管道进行处理的节点流。</p></li></ul><p>。 处理流：是对一个已存在的流的连接和封装，通过所封装的流的功能调用实现数据读写。</p><ul><li><p>缓冲流 : BufferedImputStrean, BufferedOutputStream, BufferedReader , BufferedWriter，需要父类作为参数构造，增加缓冲功能，避免频繁读写硬盘，可以初始化缓冲数据的大小，由于带了缓冲功能，所以就写数据的时候需要使用 flush 方法，另外，BufferedReader 提供一个 readLine( ) 方法可以读取一行，而 FileInputStream 和 FileReader 只能读取一个字节或者一个字符，因此 BufferedReader 也被称为行读取器。</p></li><li><p>转换流: InputStreamReader, OutputStreamWriter, 要 inputStream 或 OutputStream 作为参数，实现从字节流到字符流的转换，我们经常在读取键盘输入 (System.in) 或网络通信的时候，需要使用这两个类。</p></li><li><p>数据流：DataInputStream，DataOutputStream，提供将基础数据类型写入到文件中， 或者读取出来。</p></li></ul><p>以BufferedReader为例。处理流的构造方法总要带上一个其他的流对象做参数。一个流对象会经过其他流的多次包装。</p><h2 id="8-3-Java-IO流特性"><a href="#8-3-Java-IO流特性" class="headerlink" title="8.3 Java IO流特性"></a>8.3 Java IO流特性</h2><ol><li><p>顺序存取:可以一个接一个地往流中写入一串字节，读出时也将按写入顺序读取一串字节，不能随机访问中间的数据。（RandomAccessFile可以从文件的任意位置进行存取（输入输出）操作）</p></li><li><p>先进先出:最先写入输出流的数据最先被输入流读取到。</p></li><li><p>只读或只写：每个流只能是输入流或输出流的一种，不能同时具备两个功能，输入流只能进行读操作，对输出流只能进行写操作。在一个数据传输通道中，如果既要写入数据，又要读取数据，则要分别提供两个流。</p></li></ol><h2 id="8-4-Java-IO流接口"><a href="#8-4-Java-IO流接口" class="headerlink" title="8.4 Java IO流接口"></a>8.4 Java IO流接口</h2><ol><li><p>File（文件特征与管理）：File类是对文件系统中文件以及文件夹进行封装的对象，可以通过对象的思想来操作文件和文件夹。 File类保存文件或目录的各种元数据信息，包括文件名、文件长度、最后修改时间、是否可读、获取当前文件的路径名，判断指定文件是否存在、获得当前目录中的文件列表，创建、删除文件和目录等方法。</p></li><li><p>InputStream（二进制）：抽象类，基于字节的输入操作，是所有输入流的父类。定义了所有输入流都具有的共同特征。</p></li><li><p>OutputStream（二进制）：抽象类。基于字节的输出操作。是所有输出流的父类。定义了所有输出流都具有的共同特征。</p></li><li><p>Reader (文件格式) : 抽象类，基于字符的输入操作。</p></li><li><p>Writer (文件格式) : 抽象类，基于字符的输出操作。</p></li><li><p>RandomAccessFile（随机文件）：一个独立的类，直接继承至Object.它的功能丰富，可以从文件的任意位置进行存取（输入输出）操作。</p></li></ol><p>一个接口指的是Serializable.掌握了这些IO的核心操作那么对于Java中的IO体系也就有了一个初步的认识了。</p><h2 id="8-5-Java-IO流对象"><a href="#8-5-Java-IO流对象" class="headerlink" title="8.5 Java IO流对象"></a>8.5 Java IO流对象</h2><h2 id="8-5-1-输入字节流InputStream"><a href="#8-5-1-输入字节流InputStream" class="headerlink" title="8.5.1 输入字节流InputStream"></a>8.5.1 输入字节流InputStream</h2><ol><li><p>ByteArrayInputStream：字节数组输入流，该类的功能就是从字节数组(byte[])中进行以字节为单位的读取，也就是将资源文件都以字节的形式存入到该类中的字节数组中。</p></li><li><p>PipedInputStream：管道字节输入流，它和PipedOutputStream一起使用，能实现多线程间的管道通信。</p></li><li><p>FilterInputStream : 装饰者模式中处于装饰者，具体的装饰者都要继承它，所以在该类的子类下都是用来装饰别的流的，也就是处理类。具体装饰者模式在下面会讲解到，到时就明白了。</p></li><li><p>BufferedInputStream: 缓冲流，对处理流进行装饰，增强，内部会有一个缓存区，用来存放字节，每次都是将缓存区存满然后发送，而不是一个字节或两个字节这样发送。效率更高。</p></li><li><p>DataInputStream：数据输入流，它是用来装饰其它输入流，它“允许应用程序以与机器无关方式从底层输入流中读取基本 Java 数据类型”。</p></li><li><p>FileInputSream: 文件输入流。它通常用于对文件进行读取操作。</p></li><li><p>File：对指定目录的文件进行操作，具体可以查看讲解File的博文。注意，该类虽然是在IO包下，但是并不继承自四大基础类。</p></li><li><p>ObjectInputStream：对象输入流，用来提供对“基本数据或对象”的持久存储。在反序列化中使用。</p></li></ol><h2 id="8-5-2-输出字节流OutputStream"><a href="#8-5-2-输出字节流OutputStream" class="headerlink" title="8.5.2 输出字节流OutputStream"></a>8.5.2 输出字节流OutputStream</h2><ol><li><p>OutputStream 是所有的输出字节流的父类，它是一个抽象类。</p></li><li><p>ByteArrayOutputStream、FileOutputStream 是两种基本的介质流，它们分别向Byte 数组、和本地文件中写入数据。PipedOutputStream 是向与其它线程共用的管道中写入数据。</p></li><li><p>ObjectOutputStream 和所有FilterOutputStream 的子类都是装饰流，同样在序列化中使用。</p></li></ol><h2 id="8-5-3-字符输入流-Reader"><a href="#8-5-3-字符输入流-Reader" class="headerlink" title="8.5.3 字符输入流 Reader"></a>8.5.3 字符输入流 Reader</h2><ol><li><p>Reader : 所有的输入字符流的父类，它是一个抽象类。</p></li><li><p>CharReader 、StringReader：两种基本的介质流，它们分别将Char 数组、String中读取数据。 PipedReader 是从与其它线程共用的管道中读取数据。</p></li><li><p>BufferedReader : 一个装饰器，它和其子类负责装饰其它Reader 对象。</p></li><li><p>FilterReader: 所有自定义具体装饰流的父类，其子类PushbackReader 对Reader 对象进行装饰，会增加一个行号。</p></li><li><p>InputstreamReader : 一个连接字节流和字符流的桥梁，它将字节流转变为字符流。 FileReader 可以说是一个达到此功能、常用的工具类，在其源代码中明显使用了将FileInputStream 转变为 Reader 的方法。我们可以从这个类中得到一定的技巧。Reader 中各个类的用途和使用方法基本和 InputStream 中的类使用一致。后面会有Reader 与InputStream 的对应关系。</p></li></ol><h2 id="8-5-4-字符输出流Writer"><a href="#8-5-4-字符输出流Writer" class="headerlink" title="8.5.4 字符输出流Writer"></a>8.5.4 字符输出流Writer</h2><ol><li><p>Writer：所有的输出字符流的父类，它是一个抽象类。</p></li><li><p>CharArrayWriter、StringWriter：两种基本的介质流，它们分别向Char 数组、String 中写入数据。PipedWriter 是向与其它线程共用的管道中写入数据，</p></li><li><p>BufferedWriter: 一个装饰器为Writer 提供缓冲功能。</p></li><li><p>PrintWriter 和PrintStream 极其类似，功能和使用也非常相似。</p></li><li><p>OutputStreamWriter 是OutputStream 到Writer 转换的桥梁，它的子类FileWriter 其实就是这么一个实现此功能的类。功能和使用和OutputStream类似。</p></li></ol><h2 id="8-6-Java-IO流方法"><a href="#8-6-Java-IO流方法" class="headerlink" title="8.6 Java IO流方法"></a>8.6 Java IO流方法</h2><h2 id="8-6-1-字节流方法"><a href="#8-6-1-字节流方法" class="headerlink" title="8.6.1 字节流方法"></a>8.6.1 字节流方法</h2><p>字节输入流InputStream主要方法:</p><p>read() : 从此输入流中读取一个数据字节。</p><p>read(byte[] b) : 从此输入流中将最多 b.length 个字节的数据读入一个 byte 数组中。</p><p>read(byte[] b, int off, int len) : 从此输入流中将最多 len 个字节的数据读入一个 byte 数组中。</p><p>close(): 关闭此输入流并释放与该流关联的所有系统资源。</p><p>字节输出流OutputStream主要方法:</p><p>write(byte[] b) : 将 b.length 个字节从指定 byte 数组写入此文件输出流中。</p><p>write(byte[] b, int off, int len) : 将指定 byte 数组中从偏移量 off 开始的 len 个字节写入此文件输出流。</p><p>write(int b) : 将指定字节写入此文件输出流。</p><p>close() : 关闭此输入流并释放与该流关联的所有系统资源。</p><h2 id="8-6-2-字符流方法"><a href="#8-6-2-字符流方法" class="headerlink" title="8.6.2 字符流方法"></a>8.6.2 字符流方法</h2><p>字符输入流Reader主要方法:</p><p>read(): 读取单个字符。</p><p>read(char[] cbuf) : 将字符读入数组。</p><p>read(char[] cbuf, int off, int len) : 将字符读入数组的某一部分。</p><p>read(CharBuffer target) : 试图将字符读入指定的字符缓冲区。</p><p>flush() : 刷新该流的缓冲。</p><p>close() : 关闭此流，但要先刷新它。</p><p>字符输出流Writer主要方法:</p><p>write(char[] cbuf) ：写入字符数组。</p><p>write(char[] cbuf, int off, int len) : 写入字符数组的某一部分。</p><p>write(int c) : 写入单个字符。</p><p>write(String str) : 写入字符串。</p><p>write(String str, int off, int len) : 写入字符串的某一部分。</p><p>flush() : 刷新该流的缓冲。</p><p>close() ：关闭此流，但要先刷新它。</p><p>BufferedWriter类newLine() : 写入一个行分隔符。这个方法会自动适配所在系统的行分隔符。</p><p>BufferedReader类readLine() : 读取一个文本行。</p><h2 id="8-7-字节流与字符流的转换"><a href="#8-7-字节流与字符流的转换" class="headerlink" title="8.7 字节流与字符流的转换"></a>8.7 字节流与字符流的转换</h2><p>字节流与字符流的转换主要用于文本文件在硬盘中以字节流的形式存储时，通过InputStreamReader读取后转化为字符流给程序处理，程序处理的字符流通过OutputStreamWriter转换为字节流保存。</p><p>转换流有哪些基本特点呢?</p><ol><li><p>是字符流和字节流之间的桥梁</p></li><li><p>可对读取到的字节数据经过指定编码转换成字符</p></li><li><p>可对读取到的字符数据经过指定编码转换成字节</p></li></ol><p>那么什么时候使用转换流呢?</p><ol><li><p>当字节和字符之间有转换动作</p></li><li><p>流操作的数据需要编码或解码</p></li></ol><p>具体的对象体现在哪些方面?</p><ol><li><p>InputStreamReader:字节到字符的桥梁</p></li><li><p>OutputStreamwriter:字符到字节的桥梁</p></li></ol><p>这两个流对象是字符体系中的成员，它们有转换作用，本身又是字符流，所以在构造的时候需要传入字节流对象进来。</p><ol><li><p>Outputstreamwriter(Outstreamout) :将字节流以字符流输出。</p></li><li><p>InputstreamReader(Inputstream in): 将字节流以字符流输入。</p></li></ol><p>public class IOTest {</p><p>public static void write(File file) throws IOException {</p><p>&#x2F;&#x2F; OutputStreamwriter可以显示指定字符集, 否则使用默认字符集</p><p>OutputStreamwriter osw &#x3D; new OutputStreamWriter(new</p><p>FileOutputStream(file, true), “UTF-8”);</p><p>&#x2F;&#x2F; 要写入的字符串</p><p>string string ( &#x3D; ) “松下问童子,言师采药去。只在此山中,云深不知处。”;</p><p>osw.write(string);</p><p>osw.close();</p><p>}</p><p>public static String read(File file) throws IOException {</p><p>InputStreamReader isr &#x3D; new InputStreamReader(new FileInputStream(file),</p><p>“UTF-8”);</p><p>&#x2F;&#x2F; 字符数组: 一次读取多少个字符</p><p>char[] chars ( &#x3D; ) new char[1024];</p><p>&#x2F;&#x2F; 每次读取的字符数组先append到StringBuilder中</p><p>StringBuilder ( \mathrm &#x3D; ) new StringBuilder();</p><p>&#x2F;&#x2F; 读取到的字符数组长度, 为-1时表示没有数据</p><p>int length;</p><p>&#x2F;&#x2F; 循环取数据</p><p>while ((length &#x3D; isr.read(chars)) !&#x3D; -1) {</p><p>&#x2F;&#x2F; 将读取的内容转换成字符串</p><p>sb.append(chars, 0, length);</p><p>}</p><p>&#x2F;&#x2F; 关闭流</p><p>isr.close();</p><p>return sb.toString()</p><p>}</p><h2 id="8-8-字节流与字符流的区别"><a href="#8-8-字节流与字符流的区别" class="headerlink" title="8.8 字节流与字符流的区别"></a>8.8 字节流与字符流的区别</h2><ol><li><p>读写的单位有所不同：字节流以字节 (8bit) 为单位，字符流以字符为单位，根据码表映射字符， 一次可能读多个字节。</p></li><li><p>处理的对象有所不同：字节流能处理所有类型的数据（如图片、avi等），而字符流只能处理字符类型的数据。</p></li><li><p>字节流没有缓冲区，是直接输出的，而字符流是输出到缓冲区的。因此在输出时，字节流不调用 colse()方法时，信息已经输出了，而字符流只有在调用close()方法关闭缓冲区时，信息才输出。要想字符流在未关闭时输出信息，则需要手动调用flush()方法。</p></li></ol><h2 id="8-9-小结"><a href="#8-9-小结" class="headerlink" title="8.9 小结"></a>8.9 小结</h2><p>想要更系统的学习java IO系统，除了掌握这些基础的IO知识以外，重点是要学会IO模型，了解了各种IO 模型之后才可以更好的理解java IO，所以大家在看了这篇文章之后还需要再去深入学习一些关于IO模型的知识与运用哦~</p><h1 id="9-Java-注解详解"><a href="#9-Java-注解详解" class="headerlink" title="9. Java 注解详解"></a>9. Java 注解详解</h1><p>注解，英文名Annotation。官方文档中对注解的定义是这样的：Java注解用于为Java代码提供元数据。 作为元数据，注解不直接影响你的代码运行，但是也有一些类型的注解实际上可以用于这些目的。</p><p>Java注解是从 Java5 开始添加到 Java 里面的。看完这句话你可能对注解的定义还是一头雾水，接下来就和我一起结合案例来深入学习Java注解相关的知识吧。</p><h2 id="9-1-什么是注解"><a href="#9-1-什么是注解" class="headerlink" title="9.1 什么是注解?"></a>9.1 什么是注解?</h2><p>日常开发中新建 Java 类，比较常见的有 class、interface 等，而注解同样也属于一种类，只不过它的修饰符是 ‘@interface’。</p><p>public interface override extends Annotation {</p><p>一个注解准确意义上来说，只不过是一种特殊的注释而已，如果没有解析它的代码，它可能连注释都不是。</p><h2 id="9-2-元注解探秘"><a href="#9-2-元注解探秘" class="headerlink" title="9.2 元注解探秘"></a>9.2 元注解探秘</h2><p>元注解是用于修饰注解的注解，通常用在注解的定义上。</p><p>Java 中元注解有以下几种形式:</p><ul><li><p>@Target: 注解的作用目标</p></li><li><p>@Inherited: 是否允许子类继承该注解</p></li><li><p>@Retention: 注解的生命周期</p></li><li><p>@Documented: 注解是否应当被包含在 JavaDoc 文档中</p></li><li><p>@Repeatable：说明被这个元注解修饰的注解可以同时作用一个对象多次，每次作用注解代表不同的含义</p></li></ul><h2 id="9-2-1-Target"><a href="#9-2-1-Target" class="headerlink" title="9.2.1 Target"></a>9.2.1 Target</h2><ul><li><p>@Target元注解表示我们的注解作用的范围就很大，有类，方法，方法参数变量等，还可通过枚举类ElementType来表示作用类型。</p></li><li><p>@Target(ElementType.TYPE) 作用接口、类、枚举、注解。</p></li><li><p>@Target(ElementType.FIELD) 作用属性字段、枚举的常量。</p></li><li><p>@Target(ElementType.METHOD) 作用方法。</p></li><li><p>@Target(ElementType.PARAMETER) 作用方法参数。</p></li><li><p>@Target(ElementType.CONSTRUCTOR) 作用构造函数。</p></li><li><p>@Target(ElementType.LOCAL_VARIABLE) 作用局部变量。</p></li><li><p>@Target(ElementType.ANNOTATION_TYPE) 作用于注解 (@Retention注解中就使用该属性）。</p></li><li><p>@Target(ElementType.PACKAGE) 作用于包。</p></li><li><p>@Target(ElementType.TYPE_PARAMETER) 作用于类型泛型，即泛型方法、泛型类、泛型接口 （jdk1.8加入）。</p></li><li><p>( @ ) Target(ElementType.TYPE_USE) 类型使用.可以用于标注任意类型除了 class (jdk1.8加入) - 般比较常用的是ElementType.TYPE类型。</p></li></ul><p>PS：@Target 用于指明被修饰的注解最终可以作用的目标是谁，也就是指明，你的注解到底是用来修饰方法、修饰类亦或者是用来修饰字段属性的。</p><h2 id="9-2-2-Inherited"><a href="#9-2-2-Inherited" class="headerlink" title="9.2.2 @Inherited"></a>9.2.2 @Inherited</h2><ul><li>Inherited 的意思是继承，但是这个继承和我们平时理解的继承大同小异，一个被 @Inherited 注解了的注解修饰了一个父类，如果他的子类没有被其他注解修饰，则它的子类也继承了父类的注解。</li></ul><h2 id="自定义注解"><a href="#自定义注解" class="headerlink" title="&#x2F;*自定义注解&#x2F;"></a>&#x2F;*<em>自定义注解</em>&#x2F;</h2><p>@Documented</p><p>@Inherited</p><p>@Retention(RetentionPolicy.RUNTIME)</p><p>@Target(ElementType.TYPE)</p><p>public @interface MyTestAnnotation {</p><p>}</p><p>&#x2F;*<em>父类标注自定义注解</em>&#x2F;</p><p>@MyTestAnnotation</p><p>public class Father {</p><p>}</p><p>&#x2F;*<em>子类</em>&#x2F;</p><p>public class Son extends Father {</p><p>}</p><p>&#x2F;*<em>测试子类获取父类自定义注解</em>&#x2F;</p><p>public class test {</p><p>public static void main(String[] args){</p><p>&#x2F;&#x2F;获取Son的class对象</p><p>Class<Son> sonClass &#x3D; Son.class;</p><p>&#x2F;&#x2F; 获取Son类上的注解MyTestAnnotation可以执行成功</p><p>MyTestAnnotation annotation ( &#x3D; )</p><p>sonClass.getAnnotation(MyTestAnnotation.class);</p><p>}</p><p>}</p><h2 id="9-2-3-Retention"><a href="#9-2-3-Retention" class="headerlink" title="9.2.3 @Retention"></a>9.2.3 @Retention</h2><ul><li><p>Retention有保留、保持的意思，它表示注解存在阶段是保留在源码（编译期），字节码（类加载） 或者运行期（JVM中运行）。在@Retention注解中使用枚举RetentionPolicy来表示注解保留时期。</p></li><li><p>@Retention(RetentionPolicy.CLASS)，默认的保留策略，注解会在class字节码文件中存在，但运行时无法获得。</p></li><li><p>@Retention(RetentionPolicy.SOURCE)，注解仅存在于源码中，在class字节码文件中并不包含。</p></li><li><p>@Retention(RetentionPolicy.RUNTIME)，注解会在class字节码文件中存在，在运行时可以通过反射获取到。</p></li><li><p>如果我们是自定义注解，则通过前面分析，我们自定义注解如果只存着源码中或者字节码文件中就无法发挥作用，而在运行期间能获取到注解才能实现我们目的，所以自定义注解中肯定是使用 @Retention(RetentionPolicy.RUNTIME)。</p></li></ul><h2 id="9-2-4-Documented"><a href="#9-2-4-Documented" class="headerlink" title="9.2.4 @Documented"></a>9.2.4 @Documented</h2><ul><li>Document的英文意思是文档。它的作用是能够将注解中的元素包含到 Javadoc 中去。</li></ul><h2 id="9-2-5-Repeatable"><a href="#9-2-5-Repeatable" class="headerlink" title="9.2.5 @Repeatable"></a>9.2.5 @Repeatable</h2><ul><li>Repeatable表示可重复的。从字面意思来理解就是说明被这个元注解修饰的注解可以同时作用一个对象多次，但是每次作用注解又可以代表不同的含义。</li></ul><hr><p>&#x2F;*<em>小Y喜欢玩游戏, 他喜欢玩英雄联盟, 绝地求生, 极品飞车, 尘埃4等, 则我们需要定义一个人的注解, 他属性代表喜欢玩游戏集合, 一个游戏注解, 游戏属性代表游戏名称</em>&#x2F;</p><p>&#x2F;*<em>玩家注解</em>&#x2F;</p><p>@Documented</p><p>@Retention(RetentionPolicy.RUNTIME)</p><p>@Target(ElementType.TYPE)</p><p>public @interface People {</p><p>Game[] value() ;</p><p>}</p><p>&#x2F;*<em>游戏注解</em>&#x2F;</p><hr><p>@Repeatable(People.class)</p><p>@Retention(RetentionPolicy.RUNTIME)</p><p>@Target(ElementType.TYPE)</p><p>public @interface Game {</p><p>String value() default “”;</p><p>}</p><p>&#x2F;*<em>玩游戏类</em>&#x2F;</p><p>@Game(value &#x3D; “LOL”)</p><p>@Game(value &#x3D; “PUBG”)</p><p>@Game(value &#x3D; “NFS”)</p><p>@Game(value &#x3D; “Dirt4”)</p><p>public class PlayGame {</p><p>}</p><h2 id="9-3-注解属性知多少"><a href="#9-3-注解属性知多少" class="headerlink" title="9.3 注解属性知多少"></a>9.3 注解属性知多少</h2><p>注解的属性其实和类中定义的变量有异曲同工之处，只是注解中的变量都是成员变量（属性），并且注解中是没有方法的，只有成员变量，变量名就是使用注解括号中对应的参数名，变量返回值注解括号中对应参数类型。相信这会你应该会对上面的例子有一个更深的认识。而 ( @ ) Repeatable 注解中的变量则类型则是对应 Annotation (接口) 的泛型 Class。</p><p>&#x2F;*<em>注解Repeatable源码</em>&#x2F;</p><p>@Documented</p><p>@Retention(RetentionPolicy.RUNTIME)</p><p>@Target(ElementType.ANNOTATION_TYPE)</p><p>public @interface Repeatable {</p><p>&#x2F;**</p><ul><li><p>Indicates the <em>containing annotation type</em> for the</p></li><li><p>repeatable annotation type.</p></li><li><p>@return the containing annotation type</p></li></ul><p>*&#x2F;</p><p>Class&lt;? extends Annotation&gt; value();</p><p>}</p><h1 id="9-自定义注解"><a href="#9-自定义注解" class="headerlink" title="9. 自定义注解"></a>9. 自定义注解</h1><h2 id="9-4-1-注解的本质"><a href="#9-4-1-注解的本质" class="headerlink" title="9.4.1 注解的本质"></a>9.4.1 注解的本质</h2><p>注解的本质就是一个Annotation接口。</p><p>&#x2F;*<em>Annotation接口源码</em>&#x2F;</p><p>public interface Annotation {</p><p>boolean equals(Object obj);</p><p>int hashCode();</p><p>Class&lt;? extends Annotation&gt; annotationType();</p><p>}</p><p>从上述代码中我们可以看出，注解本身就是Annotation接口的子接口，也就是说注解中其实是可以有属性和方法，但是接口中的属性都是static final的，对于注解来说没什么意义，而我们定义接口的方法就相当于注解的属性，也就对应了前面说的为什么注解只有属性成员变量，其实他就是接口的方法，这就是为什么成员变量会有括号，不同于接口我们可以在注解的括号中给成员变量赋值。</p><h2 id="9-4-2-注解属性类型"><a href="#9-4-2-注解属性类型" class="headerlink" title="9.4.2 注解属性类型"></a>9.4.2 注解属性类型</h2><ul><li><p>基本数据类型</p></li><li><p>String</p></li><li><p>枚举类型</p></li><li><p>注解类型</p></li><li><p>Class类型</p></li><li><p>以上类型的一维数组类型</p></li></ul><h2 id="9-4-3-为注解成员变量赋值"><a href="#9-4-3-为注解成员变量赋值" class="headerlink" title="9.4.3 为注解成员变量赋值"></a>9.4.3 为注解成员变量赋值</h2><p>如果注解又多个属性，则可以在注解括号中用“，”号隔开分别给对应的属性赋值，如下例子，注解在父类中赋值属性。</p><p>@Documented</p><p>@Inherited</p><p>@Retention(RetentionPolicy.RUNTIME)</p><p>@Target(ElementType.TYPE)</p><p>public @interface MyTestAnnotation {</p><p>String name() default “mao”;</p><p>int age() default 18;</p><p>}</p><p>@MyTestAnnotation(name &#x3D; “father”, age &#x3D; 50)</p><p>public class Father {</p><p>}</p><h2 id="9-4-4-获取注解的属性"><a href="#9-4-4-获取注解的属性" class="headerlink" title="9.4.4 获取注解的属性"></a>9.4.4 获取注解的属性</h2><p>前面我们说了很多注解如何定义，放在哪，现在我们可以开始学习注解属性的提取了，这才是使用注解的关键，获取属性的值才是使用注解的目的。如果获取注解属性，当然是反射啦，主要有三个基本的方法:</p><p>&#x2F;*<em>是否存在对应 Annotation 对象</em>&#x2F;</p><p>public boolean isAnnotationPresent(Class&lt;? extends Annotation&gt; annotationClass)</p><p>{</p><p>return GenericDeclaration.super.isAnnotationPresent(annotationClass);</p><p>}</p><p>&#x2F;*<em>获取 Annotation 对象</em>&#x2F;</p><p>public <A extends Annotation> A getAnnotation(Class<A> annotationClass) {</p><p>Objects.requireNonNull(annotationClass);</p><p>return (A) annotationData().annotations.get(annotationClass);</p><p>}</p><p>&#x2F;*<em>获取所有 Annotation 对象数组</em>&#x2F;</p><p>public Annotation[] getAnnotations() { return AnnotationParser.toArray(annotationData().annotations);</p><p>下面结合前面的例子，我们来获取一下注解属性，在获取之前我们自定义的注解必须使用元注解 @Retention(RetentionPolicy.RUNTIME)。</p><p>public class test {</p><p>public static void main(String[] args) throws NoSuchMethodException {</p><p>&#x2F;**</p><ul><li>获取类注解属性</li></ul><p>*&#x2F;</p><p>Class<Father> fatherClass &#x3D; Father.class;</p><p>boolean annotationPresent ( &#x3D; )</p><p>fatherClass. isAnnotationPresent(MyTestAnnotation.class);</p><p>if(annotationPresent){</p><p>MyTestAnnotation annotation ( &#x3D; )</p><p>fatherClass.getAnnotation(MyTestAnnotation.class);</p><p>System.out.println(annotation.name());</p><p>System.out.println(annotation.age());</p><p>}</p><p>&#x2F;**</p><ul><li>获取方法注解属性</li></ul><p>*&#x2F;</p><p>try ( { )</p><p>Field age &#x3D; fatherClass.getDeclaredField(“age”);</p><p>boolean annotationPresent1 &#x3D; age.isAnnotationPresent(Age.class);</p><p>if(annotationPresent1){</p><p>Age annotation ( &#x3D; ) age.getAnnotation(Age.class);</p><p>System.out.println(annotation.value());</p><p>}</p><p>Method play ( &#x3D; ) PlayGame.class.getDeclaredMethod(“play”);</p><p>if (play!&#x3D;null){</p><p>People annotation2 &#x3D; play.getAnnotation(People.class);</p><p>Game[] value ( &#x3D; ) annotation2.value();</p><p>for (Game game : value) {</p><p>System.out.println(game.value());</p><p>}</p><p>}</p><p>} catch (NoSuchFieldException e) {</p><p>e.printstackTrace();</p><p>}</p><p>}</p><p>}</p><h2 id="9-5-JDK提供的注解"><a href="#9-5-JDK提供的注解" class="headerlink" title="9.5 JDK提供的注解"></a>9.5 JDK提供的注解</h2><table><thead><tr><th>注解</th><th>作用</th></tr></thead><tr><td>@SuppressWarnings</td><td>对程序中的警告去除。</td></tr><tr><td>@Deprecated</td><td>它是用于描述当前方法是一个过时的方法。</td></tr></table><table><thead><tr><th>注解</th><th>作用</th></tr></thead><tr><td>@Override</td><td>主要是用来描述当前方法是一个重写的方法，在编译阶段对方法进行检 查。jdk1.5中它只能描述继承中的重写，jdk1.6中它可以描述接口实现的 重写,也能描述类的继承的重写。</td></tr></table><h2 id="9-6-注解的运用"><a href="#9-6-注解的运用" class="headerlink" title="9.6 注解的运用"></a>9.6 注解的运用</h2><p>如果你是一名Android 开发者，平常所使用的第三方框架ButterKnife，Retrofit2，Dagger2等都有注解的应用，如果想要了解这些框架的原理，则注解的基础知识则是必不可少的。</p><h2 id="9-7-注解的意义"><a href="#9-7-注解的意义" class="headerlink" title="9.7 注解的意义"></a>9.7 注解的意义</h2><ul><li><p>提供信息给编译器： 编译器可以利用注解来检测出错误或者警告信息，打印出日志。</p></li><li><p>编译阶段时的处理： 软件工具可以用来利用注解信息来自动生成代码、文档或者做其它相应的自动处理。</p></li><li><p>运行时处理：某些注解可以在程序运行的时候接受代码的提取，自动做相应的操作。</p></li></ul><ul><li>正如官方文档的那句话所说，注解能够提供元数据，转账例子中处理获取注解值的过程是我们开发者直接写的注解提取逻辑，处理提取和处理 Annotation 的代码统称为 APT (Annotation</li></ul><p>Processing Tool)。上面转账例子中的processAnnotationMoney方法就可以理解为APT工具类。</p><p>更多关于注解的有意思的学习经历也需要靠大家在日常工作中认真去体会啦！</p><h1 id="10-Java-泛型"><a href="#10-Java-泛型" class="headerlink" title="10. Java 泛型"></a>10. Java 泛型</h1><h2 id="10-1-泛型的提出？"><a href="#10-1-泛型的提出？" class="headerlink" title="10.1 泛型的提出？"></a>10.1 泛型的提出？</h2><ul><li>泛型实质上就是是程序员定义安全的类型。在没有出现泛型之前，Java提供了对Object的引用“任意化“操作，这种“任意化”操作就是对Object引用进行向下转型及向上转型操作，但某些强制类型转换的错误也许不会被编译器捕捉，而在运行后出现异常，可吉安强制类型转换存在安全隐患，所以在此提供了泛型机制。</li></ul><ul><li>泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。</li></ul><p>说再多不如举了例子来帮助大家理解:</p><p>List arrayList ( &#x3D; ) new ArrayList();</p><p>arrayList.add(“aaaa”);</p><p>arrayList.add(100);</p><p>for(int ( i &#x3D; 0 ) ; ( i &lt; \operatorname{arrayList.size();}i + + ){ )</p><p>String item ( &#x3D; ) (String)arrayList.get(i);</p><p>Log. ( d ) (“泛型测试”,”item ( &#x3D; ) “ + item);</p><p>}</p><p>这样的代码运行的最终结果必然是会崩溃的:</p><p>java.lang.classCastException: java.lang.Integer cannot be cast to</p><p>java.lang.string</p><p>ArrayList可以存放任意类型，例子中添加了一个String类型，添加了一个Integer类型，再使用时都以 String的方式使用，因此程序崩溃了。为了解决类似这样的问题（在编译阶段就可以解决），泛型应运而生。</p><p>我们将第一行声明初始化list的代码更改一下，编译器会在编译阶段就能够帮我们发现类似这样的问题。</p><p>List<String> arrayList &#x3D; new ArrayList<String>();</p><p>( \cdots )</p><p>&#x2F;&#x2F;arrayList.add(100); 在编译阶段, 编译器就会报错</p><p>那么有没有什么办法可以使集合能够记住集合内元素各类型，且能够达到只要编译时不出现问题，运行时就不会出现“java.lang.ClassCastException”异常呢？答案就是使用泛型。</p><h2 id="10-2-常用的泛型类型变量"><a href="#10-2-常用的泛型类型变量" class="headerlink" title="10.2 常用的泛型类型变量"></a>10.2 常用的泛型类型变量</h2><p>E: 元素 (Element) ，多用于java集合框架。</p><p>K：关键字（Key）。</p><p>N: 数字 (Number) 。</p><p>T：类型（Type）。</p><p>V：值（Value）。</p><h2 id="10-3-泛型的使用"><a href="#10-3-泛型的使用" class="headerlink" title="10.3 泛型的使用"></a>10.3 泛型的使用</h2><p>泛型有三种使用方式，分别为:</p><ul><li><p>泛型类</p></li><li><p>泛型接口</p></li><li><p>泛型方法</p></li></ul><h2 id="1-0-3-1-泛型类"><a href="#1-0-3-1-泛型类" class="headerlink" title="1.0.3.1 泛型类"></a>1.0.3.1 泛型类</h2><p>泛型类型用于类的定义中，被称为泛型类。通过泛型可以完成对一组类的操作对外开放相同的接口。最典型的就是各种容器类，如：List、Set、Map。</p><p>定义一个泛型类:</p><p>class 类名称 ( &lt; ) 泛型标识: 可以随便写任意标识号,标识指定的泛型的类型 ( &gt; { )</p><p>private 泛型标识 &#x2F;* (成员变量类型) *&#x2F; var;</p><p>( \cdots )</p><p>}</p><p>}</p><h2 id="将案例具体化"><a href="#将案例具体化" class="headerlink" title="将案例具体化:"></a>将案例具体化:</h2><p>public class Generic<T>{</p><p>&#x2F;&#x2F;key这个成员变量的类型为 ( T, T ) 的类型由外部指定</p><p>private ( T ) key;</p><p>public Generic(T key) { &#x2F;&#x2F;泛型构造方法形参key的类型也为T, T的类型由外部指定 this.key ( &#x3D; ) key; }</p><p>public T getKey() { &#x2F;&#x2F;泛型方法getKey的返回值类型为T, T的类型由外部指定</p><p>return key;</p><p>}</p><p>}</p><p>&#x2F;&#x2F;泛型的类型参数只能是类类型 (包括自定义类), 不能是简单类型</p><p>&#x2F;&#x2F;传入的实参类型需与泛型的类型参数类型相同, 即为Integer.</p><p>Generic<Integer> genericInteger &#x3D; new Generic<Integer>(123456);</p><p>&#x2F;&#x2F;传入的实参类型需与泛型的类型参数类型相同, 即为String.</p><p>Generic<String> genericString &#x3D; new Generic<String>(“key_vlaue”);</p><p>Log.d(“泛型测试”,”key is “ + genericInteger.getKey());</p><p>Log.d(“泛型测试”,”key is “ + genericString.getKey());</p><p>测试结果:</p><p>12-27 09:20:04.432 13063-13063&#x2F;? D&#x2F;泛型测试: key is 123456</p><p>12-27 09:20:04.432 13063-13063&#x2F;? D&#x2F;泛型测试: key is key_vlaue</p><p>定义的泛型类并不是一定要传入泛型类型实参。在使用泛型的时候如果传入泛型实参，则会根据传入的泛型实参做相应的限制，此时泛型才会起到本应起到的限制作用。如果不传入泛型类型实参的话，在泛型类中使用泛型的方法或成员变量定义的类型可以为任何的类型。</p><p>再举一个例子:</p><p>Generic generic &#x3D; new Generic(“111111”);</p><p>Generic generic1 &#x3D; new Generic(4444);</p><p>Generic generic2 &#x3D; new Generic(55.55);</p><p>Generic generic3 &#x3D; new Generic(false);</p><p>Log.d(“泛型测试”,”key is “ + generic.getKey());</p><p>Log.d(“泛型测试”,”key is “ + generic1.getKey());</p><p>Log.d(“泛型测试”,”key is “ + generic2.getKey());</p><p>Log.d(“泛型测试”,”key is “ + generic3.getKey());</p><p>运行结果:</p><p>D&#x2F;泛型测试: key is 111111</p><p>D&#x2F;泛型测试：key is 4444</p><p>D&#x2F;泛型测试: key is ( {55.55} )</p><p>D&#x2F;泛型测试: key is false</p><h2 id="值得注意的是"><a href="#值得注意的是" class="headerlink" title="值得注意的是:"></a>值得注意的是:</h2><ol><li><p>泛型的类型参数只能是类类型，不能是简单类型。</p></li><li><p>不能对确切的泛型类型使用instanceof操作。如下面的操作是非法的，编译时会出错。</p></li></ol><p>if(ex_num instanceof Generic<Number>){ }</p><h2 id="10-3-2-泛型接口"><a href="#10-3-2-泛型接口" class="headerlink" title="10.3.2 泛型接口"></a>10.3.2 泛型接口</h2><p>定义一个泛型接口: public interface GenericIntercace{}</p><p>public interface GenericIntercace<T> {</p><p>T getData();</p><p>}</p><p>实现泛型接口方式一：public class ImplGenericInterface1 implements GenericIntercace</p><hr><p>public class ImplGenericInterface1<T> implements GenericIntercace<T> {</p><p>private ( T ) data;</p><p>private void setData(T data) {</p><p>this.data ( &#x3D; ) data;</p><p>}</p><p>@override</p><p>public T getData() {</p><p>return data;</p><p>}</p><p>public static void main(String[] args) {</p><p>ImplGenericInterface1<String> implGenericInterface1 &#x3D; new</p><p>ImplGenericInterface1&lt;&gt;();</p><p>implGenericInterface1.setData(“Generic Interface1”);</p><p>System.out.println(implGenericInterface1.getData());</p><p>}</p><p>}</p><hr><p>实现泛型接口方式二：public class ImplGenericInterface2 implements GenericIntercace {}</p><p>public class ImplGenericInterface2 implements GenericIntercace<String> {</p><p>@override</p><p>public String getData() {</p><p>return “Generic Interface2”;</p><p>}</p><p>public static void main(String[] args) {</p><p>ImplGenericInterface2 implGenericInterface2 &#x3D; new</p><p>ImplGenericInterface2();</p><p>System.out.println(implGenericInterface2.getData());</p><p>}</p><p>}</p><h2 id="10-3-3-泛型方法"><a href="#10-3-3-泛型方法" class="headerlink" title="10.3.3 泛型方法"></a>10.3.3 泛型方法</h2><p>泛型方法是在调用方法的时候指明泛型的具体类型。</p><p>&#x2F;**</p><ul><li><p>泛型方法的基本介绍</p></li><li><p>@param tclass 传入的泛型实参</p></li><li><p>@return T 返回值为T类型</p></li><li><p>说明:</p></li></ul><ol><li>public 与 返回值中间<T>非常重要, 可以理解为声明此方法为泛型方法。</li></ol><p>2）只有声明了<T>的方法才是泛型方法, 泛型类中的使用了泛型的成员方法并不是泛型方法。</p><p>3） ( &lt; \mathrm{T} &gt; ) 表明该方法将使用泛型类型T，此时才可以在方法中使用泛型类型T。</p><ol start="4"><li>与泛型类的定义一样,此处T可以随便写为任意标识,常见的如T、E、K、V等形式的参数常用于表</li></ol><p>示泛型。</p><p>*&#x2F;</p><p>public ( &lt; T &gt; T ) genericMethod(Class ( &lt; T &gt; ) tclass)throws InstantiationException,</p><p>IllegalAccessException{</p><p>T instance ( &#x3D; ) tclass.newInstance();</p><p>return instance;</p><p>}</p><p>object obj &#x3D; genericMethod(Class.forName(“com.test.test”));</p><h2 id="10-3-3-1-泛型方法的基本用法"><a href="#10-3-3-1-泛型方法的基本用法" class="headerlink" title="10.3.3.1 泛型方法的基本用法"></a>10.3.3.1 泛型方法的基本用法</h2><p>public class GenericTest {</p><p>&#x2F;&#x2F;这个类是个泛型类, 在上面已经介绍过</p><p>public class Generic<T>{</p><p>private ( T ) key;</p><p>public Generic(T key) {</p><p>this.key ( &#x3D; ) key;</p><p>}</p><p>&#x2F;&#x2F;我想说的其实是这个, 虽然在方法中使用了泛型, 但是这并不是一个泛型方法。</p><p>&#x2F;&#x2F;这只是类中一个普通的成员方法, 只不过他的返回值是在声明泛型类已经声明过的泛型。</p><p>&#x2F;&#x2F;所以在这个方法中才可以继续使用 ( \mathrm{T} ) 这个泛型。</p><p>public T getKey(){</p><p>return key;</p><p>}</p><p>&#x2F;**</p><ul><li><p>这个方法显然是有问题的, 在编译器会给我们提示这样的错误信息”cannot reslove symbol</p></li><li><p>因为在类的声明中并未声明泛型E,所以在使用E做形参和返回值类型时,编译器会无法识别。</p></li></ul><p>public ( E ) setKey(E ( {key}){ )</p><p>this.key ( &#x3D; ) keu</p><p>}</p><p>*&#x2F;</p><p>&#x2F;**</p><ul><li>这才是一个真正的泛型方法。</li></ul><p>首先在public与返回值之间的<T>必不可少, 这表明这是一个泛型方法, 并且声明了一个泛型T</p><ul><li>这个T可以出现在这个泛型方法的任意位置.</li></ul><p>’泛型的数量也可以为任意多个</p><p>如: public &lt;T, K&gt; K showKeyName(Generic<T> container){</p><ul><li>. .</li></ul><p>}</p><p>*&#x2F;</p><p>public <T> T showKeyName(Generic<T> container){</p><p>System.out.println(“container key :” + container.getKey());</p><p>&#x2F;&#x2F;当然这个例子举的不太合适, 只是为了说明泛型方法的特性。</p><p>( T ) test ( &#x3D; ) container.getKey();</p><p>return test;</p><p>}</p><p>&#x2F;&#x2F;这也不是一个泛型方法, 这就是一个普通的方法, 只是使用了Generic<Number>这个泛型类做形参而已。</p><p>public void showKeyValue1(Generic<Number> obj){</p><p>Log.d(“泛型测试”,”key value is “ + obj.getKey());</p><p>}</p><p>&#x2F;&#x2F;这也不是一个泛型方法, 这也是一个普通的方法, 只不过使用了泛型通配符?</p><p>&#x2F;&#x2F;同时这也印证了泛型通配符章节所描述的, ?是一种类型实参, 可以看做为Number等所有类的父类</p><p>public void showKeyValue2(Generic&lt;?&gt; obj){</p><p>Log.d(“泛型测试”,”key value is “ + obj.getKey());</p><p>}</p><p>&#x2F;**</p><ul><li><p>这个方法是有问题的,编译器会为我们提示错误信息: “UnKnown class ‘E’ “</p></li><li><p>虽然我们声明了 ( &lt; \mathrm{T} &gt; ) ,也表明了这是一个可以处理泛型的类型的泛型方法。</p></li><li><p>但是只声明了泛型类型T,并未声明泛型类型E,因此编译器并不知道该如何处理E这个类型。</p></li></ul><p>public <T> T showKeyName(Generic<E> container){</p><p>( \cdots )</p><p>}</p><p>*&#x2F;</p><p>&#x2F;**</p><ul><li><p>这个方法也是有问题的,编译器会为我们提示错误信息: “Unknown class ‘T’ “</p></li><li><p>对于编译器来说T这个类型并未项目中声明过, 因此编译也不知道该如何编译这个类。</p></li><li><p>所以这也不是一个正确的泛型方法声明。</p></li></ul><p>public void showkey(T genericobj){</p><p>}</p><p>*&#x2F;</p><p>public static void main(String[] args) {</p><p>} }</p><h2 id="10-3-3-2-类中的泛型方法"><a href="#10-3-3-2-类中的泛型方法" class="headerlink" title="10.3.3.2 类中的泛型方法"></a>10.3.3.2 类中的泛型方法</h2><p>当然这并不是泛型方法的全部，泛型方法可以出现杂任何地方和任何场景中使用。但是有一种情况是非常特殊的，当泛型方法出现在泛型类中时，我们再通过一个例子看一下</p><hr><p>public class GenericFruit {</p><p>class Fruit{</p><p>@override</p><p>public string toString() {</p><p>return “fruit”;</p><p>}</p><p>}</p><p>class Apple extends Fruit{</p><p>@override</p><p>public string toString() {</p><p>return “apple”;</p><p>} }</p><hr><h2 id="10-3-3-3-静态方法与泛型"><a href="#10-3-3-3-静态方法与泛型" class="headerlink" title="10.3.3.3 静态方法与泛型"></a>10.3.3.3 静态方法与泛型</h2><hr><p>class Person{</p><p>@override</p><p>public string toString() {</p><p>return “Person”;</p><p>}</p><p>}</p><p>class GenerateTest<T>{</p><p>public void show_1(T t){</p><p>System.out.println(t.toString());</p><p>}</p><p>&#x2F;&#x2F;在泛型类中声明了一个泛型方法,使用泛型 ( \mathrm{E} ) ,这种泛型 ( \mathrm{E} ) 可以为任意类型。可以类型与 ( \mathrm{T} ) 相同,也可以不同。</p><p>&#x2F;&#x2F;由于泛型方法在声明的时候会声明泛型 ( &lt; \mathrm{E} &gt; ) ,因此即使在泛型类中并未声明泛型,编译器也能够正确识别泛型方法中识别的泛型。</p><p>public <E> void show_3(E t){</p><p>System.out.println(t.toString());</p><p>}</p><p>&#x2F;&#x2F;在泛型类中声明了一个泛型方法, 使用泛型T, 注意这个T是一种全新的类型, 可以与泛型类中声明的T不是同一种类型。</p><p>public <T> void show_2(T t){</p><p>System.out.println(t.toString());</p><p>}</p><p>}</p><p>public static void main(String[] args) {</p><p>Apple apple ( &#x3D; ) new Apple();</p><p>Person person ( &#x3D; ) new Person();</p><p>GenerateTest<Fruit> generateTest &#x3D; new GenerateTest<Fruit>();</p><p>&#x2F;&#x2F;apple是Fruit的子类, 所以这里可以</p><p>generateTest.show_1(apple);</p><p>&#x2F;&#x2F;编译器会报错, 因为泛型类型实参指定的是 Fruit, 而传入的实参类是 Person</p><p>&#x2F;&#x2F;generateTest.show_1(person);</p><p>&#x2F;&#x2F;使用这两个方法都可以成功</p><p>generateTest.show_2(apple);</p><p>generateTest.show_2(person);</p><p>&#x2F;&#x2F;使用这两个方法也都可以成功</p><p>generateTest.show_3(apple);</p><p>generateTest.show_3(person);</p><p>} }</p><p>静态方法有一种情况需要注意一下，那就是在类中的静态方法使用泛型：静态方法无法访问类上定义的泛型；如果静态方法操作的引用数据类型不确定的时候，必须要将泛型定义在方法上。</p><hr><p>即：如果静态方法要使用泛型的话，必须将静态方法也定义成泛型方法。</p><p>public class StaticGenerator<T> {</p><p>( \cdots )</p><p>… …</p><p>&#x2F;**</p><ul><li><p>如果在类中定义使用泛型的静态方法, 需要添加额外的泛型声明 (将这个方法定义成泛型方法)</p></li><li><p>即使静态方法要使用泛型类中已经声明过的泛型也不可以。</p></li><li><p>如: public static void show(T t){..},此时编译器会提示错误信息:</p></li></ul><p>“StaticGenerator cannot be refrenced from static context”</p><p>*&#x2F;</p><p>public static ( &lt; T &gt; ) void show(T t){</p><p>}</p><p>}</p><p>至此，我们可以发现，在使用泛型类时，虽然有不同的泛型实参传入，但并没有真正意义上生成不同的类型，不同泛型实参的泛型类传入内存并只有一个，即还是原来的最基本的类型，当然，在逻辑上我们可以理解成多个不同的泛型类型。</p><p>细想原因，在于Java中的泛型这一概念提出的目的，导致其只是作用于代码编译阶段，在编译过程中， 对于正确检验泛型结果后，会将泛型的相关信息擦出，也就是说，成功编译过后的class文件中是不包含任何泛型信息的。泛型信息不会进入到运行时阶段。</p><p>总结一下：泛型类型在逻辑上看以看成是多个不同的类型，实际上都是相同的基本类型。</p><h2 id="10-4-泛型通配符"><a href="#10-4-泛型通配符" class="headerlink" title="10.4 泛型通配符"></a>10.4 泛型通配符</h2><p>我们知道Ingeter是Number的一个子类，同时在特性章节中我们也验证过Generic与Generic实际上是相同的一种基本类型。那么问题来了，在使用Generic作为形参的方法中，能否使用Generic的实例传入呢？在逻辑上类似于Generic和Generic是否可以看成具有父子关系的泛型类型呢？</p><p>弄清楚这个问题，使用Generic这个泛型类继续看下面的例子：</p><p>public void showKeyValue1(Generic<Number> obj){</p><p>Log.d(“泛型测试”,”key value is “ + obj.getKey());</p><p>}</p><p>Generic<Integer> gInteger &#x3D; new Generic<Integer>(123);</p><p>Generic<Number> gNumber &#x3D; new Generic<Number>(456);</p><p>showKeyValue(gNumber);</p><p>&#x2F;&#x2F; showKeyValue这个方法编译器会为我们报错：Generic&lt;java.lang.Integer&gt;</p><p>&#x2F;&#x2F; cannot be applied to Generic&lt;java.lang.Number&gt;</p><p>&#x2F;&#x2F; showKeyValue(gInteger);</p><p>在提示信息中，我们可以看到Generic不能被看作为 Generic的子类。</p><p>由此可以看出:同一种泛型可以对应多个版本（因为参数类型是不确定的），不同版本的泛型类实例是不兼容的。</p><p>再回到上面的例子，那么究竟如何解决上面的问题呢?</p><p>或许我们需要一个在逻辑上可以表示同时是Generic和Generic父类的引用类型。至此类型通配符应运而生。</p><p>我们可以将上面的方法改一下:</p><p>public void showKeyValue1(Generic&lt;?&gt; obj){</p><p>Log.d(“泛型测试”,”key value is “ + obj.getKey());</p><p>}</p><p>类型通配符一般是使用？ 代替具体的类型实参，注意了，此处？ 是类型实参，而不是类型形参。</p><h2 id="要说三遍"><a href="#要说三遍" class="headerlink" title="要说三遍!"></a>要说三遍!</h2><p>此处? 是类型实参，而不是类型形参!</p><p>此处? 是类型实参，而不是类型形参!</p><p>再直白点的意思就是，此处的? 和Number、String、Integer一样都是一种实际的类型，可以把? 看成所有类型的父类。是一种真实的类型。</p><p>可以解决当具体类型不确定的时候，这个通配符就是？。</p><p>当操作类型时，不需要使用类型的具体功能时，只使用Object类中的功能。那么可以用？通配符来表未知类型。</p><h2 id="10-5-泛型上下边界"><a href="#10-5-泛型上下边界" class="headerlink" title="10.5 泛型上下边界"></a>10.5 泛型上下边界</h2><p>在使用泛型的时候，我们还可以为传入的泛型类型实参进行上下边界的限制，如：类型实参只准传入某种类型的父类或某种类型的子类。</p><p>添加上边界，就是指传入的类型实参必须是指定类型的子类型。</p><p>public void showKeyValue1(Generic&lt;? extends Number&gt; obj){</p><p>Log.d(“泛型测试”,”key value is “ + obj.getKey());</p><p>}</p><p>Generic<String> generic1 &#x3D; new Generic<String>(“s”);</p><p>Generic<Integer> generic2 &#x3D; new Generic<Integer>(1314520);</p><p>Generic<Float> generic3 &#x3D; new Generic<Float>(11.11f);</p><p>Generic<Double> generic4 &#x3D; new Generic<Double>(3.14);</p><p>&#x2F;&#x2F;这一行代码编译器会提示错误, 因为string类型并不是Number类型的子类</p><p>&#x2F;&#x2F;showKeyValue1(generic1);</p><p>showKeyValue1(generic2);</p><p>showKeyValue1(generic3);</p><p>showKeyValue1(generic4);</p><p>如果再把把泛型类的定义也改一下:</p><p>public class Generic<T extends Number>{</p><p>private ( T ) key;</p><p>public Generic(T key) {</p><p>this.key ( &#x3D; ) key;</p><p>}</p><p>public T getKey(){</p><p>return key;</p><p>}</p><p>}</p><p>&#x2F;&#x2F;这一行代码也会报错, 因为String不是Number的子类</p><p>Generic<String> generic1 &#x3D; new Generic<String>(“11111”);</p><p>我们发现：泛型的上下边界添加，必须与泛型的声明在一起。</p><h2 id="10-6-泛型存在的约束"><a href="#10-6-泛型存在的约束" class="headerlink" title="10.6 泛型存在的约束"></a>10.6 泛型存在的约束</h2><ul><li><p>无法实例化泛型类</p></li><li><p>无法使用instanceof关键字或&#x3D;&#x3D;判断泛型类的类型</p></li><li><p>泛型类不能继承Exception或者Throwable</p></li><li><p>不能捕获泛型类型限定的异常但可以将泛型限定的异常抛出</p></li><li><p>泛型类的原生类型与所传递的泛型无关，无论传递什么类型，原生类是一样的</p></li><li><p>静态变量或方法不能引用泛型类型变量，但是静态泛型方法是可以的</p></li><li><p>基本类型无法作为泛型类型</p></li><li><p>泛型数组可以声明但无法实例化</p></li></ul><p>更多关于Java泛型的有意思的学习经历也需要靠大家在日常工作中认真去体会啦~</p><h1 id="11-Java-枚举"><a href="#11-Java-枚举" class="headerlink" title="11. Java 枚举"></a>11. Java 枚举</h1><h2 id="11-1-什么是枚举"><a href="#11-1-什么是枚举" class="headerlink" title="11.1 什么是枚举?"></a>11.1 什么是枚举?</h2><p>枚举是Java1.5引入的新特性，通过关键字enum来定义枚举类。枚举类是一种特殊类，它和普通类一样可以使用构造器、定义成员变量和方法，也能实现一个或多个接口,但枚举类不能继承其他类。</p><p>例如，你要指定一整个星期的天的枚举类型是:</p><p>public enum Day {</p><p>SUNDAY, MONDAY, TUESDAY, WEDNESDAY,</p><p>THURSDAY, FRIDAY, SATURDAY</p><p>}</p><p>我们应该在需要使用固定组常量的任何时候使用枚举类型。这包括自然枚举类型，例如银河系的行星，</p><p>这些你可以在编译时知道任何可能值。还有菜单选择，命令行标志等。</p><h2 id="11-2-如何声明枚举类型？"><a href="#11-2-如何声明枚举类型？" class="headerlink" title="11.2 如何声明枚举类型？"></a>11.2 如何声明枚举类型？</h2><p>这里有一些介绍如何使用Day枚举类型声明的代码，如下:</p><p>public class EnumTest {</p><p>Day day;</p><p>public EnumTest(Day day) {</p><p>this.day ( &#x3D; ) day;</p><p>}</p><p>public void tellItLikeItIs() {</p><p>switch (day) {</p><p>case MONDAY:</p><p>System.out.println(“Mondays are bad.”);</p><p>break;</p><p>case FRIDAY:</p><p>System.out.println(“Fridays are better.”);</p><p>break;</p><p>case SATURDAY: case SUNDAY:</p><p>System.out.println(“Weekends are best.”);</p><p>break;</p><p>default:</p><p>System.out.println(“Midweek days are so-so.”);</p><p>break;</p><p>}</p><p>}</p><p>public static void main(String[] args) {</p><p>EnumTest firstDay ( &#x3D; ) new EnumTest(Day.MONDAY);</p><p>firstDay.tellItLikeItIs();</p><p>EnumTest thirdDay &#x3D; new EnumTest(Day.WEDNESDAY);</p><p>thirdDay.tellItLikeItIs();</p><p>EnumTest fifthDay &#x3D; new EnumTest(Day.FRIDAY);</p><p>fifthDay.tellItLikeItIs();</p><p>EnumTest sixthDay &#x3D; new EnumTest(Day.SATURDAY);</p><p>sixthDay.tellItLikeItIs();</p><p>EnumTest seventhDay &#x3D; new EnumTest(Day.SUNDAY);</p><p>seventhDay.tellItLikeItIs();</p><p>}</p><p>}</p><h2 id="上述代码输出为"><a href="#上述代码输出为" class="headerlink" title="上述代码输出为:"></a>上述代码输出为:</h2><p>Mondays are bad.</p><p>Midweek days are so-so.</p><p>Fridays are better.</p><p>weekends are best.</p><p>weekends are best.</p><p>注意：任意两个枚举成员不能具有相同的名称，且它的常数值必须在该枚举的基础类型的范围之内，多个枚举成员之间使用逗号分隔。</p><p>如果没有显式地声明基础类型的枚举，那么意味着它所对应的基础类型是 int。</p><h2 id="11-2-1-枚举类"><a href="#11-2-1-枚举类" class="headerlink" title="11.2.1 枚举类"></a>11.2.1 枚举类</h2><p>Java 中的每一个枚举都继承自 java.lang.Enum 类。当定义一个枚举类型时，每一个枚举类型成员都可以看作是 Enum 类的实例，这些枚举成员默认都被 final、public, static 修饰，当使用枚举类型成员时，直接使用枚举名称调用成员即可。</p><table><thead><tr><th>方法名称</th><th>描述</th></tr></thead><tr><td>values()</td><td>以数组形式返回枚举类型的所有成员</td></tr><tr><td>valueOf()</td><td>将普通字符串转换为枚举实例</td></tr><tr><td>compareTo()</td><td>比较两个枚举成员在定义时的顺序</td></tr><tr><td>ordinal()</td><td>获取枚举成员的索引位置</td></tr></table><h2 id="11-3-从宇宙入手深入了解枚举类型"><a href="#11-3-从宇宙入手深入了解枚举类型" class="headerlink" title="11.3 从宇宙入手深入了解枚举类型"></a>11.3 从宇宙入手深入了解枚举类型</h2><p>Java编程语言枚举类型比其他编程语言更加强大。enum声明，定义了类(称为enum类型)。枚举类体， 可以包含方法和其他字段。编译器为enum自动添加特殊的方法。例如，有一个静态的values方法，返回一个按照声明顺序排列的enum值数组。这个方法通常结合for-each结构，遍历enum类型的所有值。例如，下面Planet类里的代码，演示了遍历银河系的所有行星。</p><p>for (Planet ( p ) : Planet.values()) {</p><p>System.out.printf(“Your weight on %s is %f%n”,</p><p>p, p.surfaceweight(mass));</p><p>}</p><p>所有enum类隐式继承java.lang.Enum。由于java不支持多继承，所有enum也不能继承其他类。</p><p>Planet是一个枚举类型，代表银河系里的所有行星。他们是恒定的质量和半径属性定义。</p><p>每个枚举常量都有质量和半径参数的声明。这些值，通过构造方法，在常量初始化时传递进来。java要求常量首先定义，其次才是字段和方法。所以，在字段和方法之前，enum常量列表必须以分号(;)结束。</p><p>注意：enum类型的构造方法必须是包内私有或者是private访问。它自动创建在enum体内的开始创建声明的常量，不允许直接调用enum的构造方法。</p><p>对于它的属性和构造方法，行星上有自己的方法，您可以检索每个行星的表面引力和重量。下面是一个示例程序，根据你在地球的体重(任何单位),计算并打印你在所有的行星的体重（相同单位）：</p><p>public enum Planet {</p><p>MERCURY (3.303e+23, 2.4397e6),</p><p>VENUS (4.869e+24, 6.0518e6),</p><p>EARTH (5.976e+24, 6.37814e6),</p><p>MARS (6.421e+23, 3.3972e6),</p><p>JUPITER (1.9e+27, 7.1492e7),</p><p>SATURN (5.688e+26, 6.0268e7),</p><p>URANUS (8.686e+25, 2.5559e7),</p><p>NEPTUNE (1.024e+26, 2.4746e7);</p><p>private final double mass; &#x2F;&#x2F; in kilograms</p><p>private final double radius; &#x2F;&#x2F; in meters</p><p>Planet(double mass, double radius) {</p><p>this.mass ( &#x3D; ) mass;</p><p>this.radius ( &#x3D; ) radius;</p><p>}</p><p>private double mass() { return mass; }</p><p>private double radius() { return radius; }</p><p>&#x2F;&#x2F; universal gravitational constant (m3 kg-1 s-2)</p><p>public static final double ( G &#x3D; {6.67300E} - {11} ) ;</p><p>double surfaceGravity() {</p><p>return G * mass &#x2F; (radius * radius);</p><p>}</p><p>double surfaceweight(double otherMass) {</p><p>return otherMass * surfaceGravity();</p><p>}</p><p>public static void main(String[] args) {</p><p>if (args.length ( ! &#x3D; 1 ) ) {</p><p>System.err.println(“Usage: java Planet <earth_weight>“);</p><p>System.exit(-1);</p><p>}</p><p>double earthweight ( &#x3D; ) Double.parseDouble(args[0]);</p><p>double mass ( &#x3D; ) earthweight&#x2F;EARTH.surfaceGravity();</p><p>for (Planet ( p ) : Planet.values ())</p><p>System.out.printf(“Your weight on %s is %f%n”,</p><p>p, p.surfaceweight(mass));</p><p>} }</p><p>如果在命令行运行Planet.class，参数是175，输出是:</p><p>$ java Planet 175</p><p>Your weight on MERCURY is 66.107583</p><p>Your weight on VENUS is 158.374842</p><p>Your weight on EARTH is 175.000000</p><p>Your weight on MARS is 66.279007</p><p>YOUR WEIGHTER IS 442.847567</p><p>Your weight on SATURN is 186.552719</p><p>Your weight on URANUS is 158.397260</p><p>Your weight on NEPTUNE is 199.207413</p><h2 id="11-4-EnumMap-与-EnumSet"><a href="#11-4-EnumMap-与-EnumSet" class="headerlink" title="11.4 EnumMap 与 EnumSet"></a>11.4 EnumMap 与 EnumSet</h2><p>为了更好地支持枚举类型，java.util 中添加了两个新类：EnumMap 和 EnumSet。使用它们可以更高效地操作枚举类型。</p><ul><li>EnumMap 类</li></ul><p>EnumMap 是专门为枚举类型量身定做的 Map 实现。虽然使用其他的 Map（如 HashMap）实现也能完成枚举类型实例到值的映射，但是使用 EnumMap 会更加高效。</p><ul><li>HashMap 只能接收同一枚举类型的实例作为键值，并且由于枚举类型实例的数量相对固定并且有限，所以 EnumMap 使用数组来存放与枚举类型对应的值，使得 EnumMap 的效率非常高。</li></ul><p>下面是使用 EnumMap 的一个代码示例。枚举类型 DataBaseType 里存放了现在支持的所有数据库类型。针对不同的数据库，一些数据库相关的方法需要返回不一样的值，例如示例中 getURL() 方法。</p><p>&#x2F;&#x2F;定义数据库类型枚举</p><p>public enum DataBaseType</p><p>{</p><p>MYSQUORACLE , DB2 , SQLSERVER</p><p>}</p><p>&#x2F;&#x2F;某类中定义的获取数据库URL的方法以及EnumMap的声明</p><p>private EnumMap&lt;DataBaseType, String&gt;urls&#x3D;new EnumMap&lt;DataBaseType, String&gt;</p><p>(DataBaseType.class);</p><p>public DataBaseInfo()</p><p>{</p><p>urls.put(DataBaseType.DB2,”jdbc:db2:&#x2F;&#x2F;localhost:5000&#x2F;sample”);</p><p>urls.put(DataBaseType.MYSQL,”jdbc:mysql:&#x2F;&#x2F;localhost&#x2F;mydb”);</p><p>urls.put(DataBaseType.ORACLE, “jdbc:oracle:thin:@localhost:1521:sample”);</p><p>urls . put (DataBaseType . SQLSERVER, “jdbc : microsoft : sq1server : &#x2F;&#x2F;sq1 : 1433 ; Database&#x3D;myd</p><p>b”);</p><p>}</p><p>&#x2F;&#x2F;根据不同的数据库类型, 返回对应的URL</p><p>&#x2F;&#x2F;@param type DataBaseType 枚举类新实例</p><p>&#x2F;&#x2F;@return</p><p>public String getURL(DataBaseType type)</p><p>{</p><p>return this.urls.get(type);</p><p>}</p><p>在实际使用中，EnumMap对象urls往往是由外部负责整个应用初始化的代码来填充的。</p><p>从本例中可以看出，使用EnumMap可以很方便地为枚举类型在不同的环境中绑定到不同的值上。本例子中getURL绑定到URL上，在其他的地方可能又被绑定到数据库驱动上去。</p><h2 id="EnumSet-类"><a href="#EnumSet-类" class="headerlink" title="EnumSet 类"></a>EnumSet 类</h2><p>EnumSet 是枚举类型的高性能 Set 实现，它要求放入它的枚举常量必须属于同一枚举类型。EnumSet 提供了许多工厂方法以便于初始化，如表 2 所示</p><table><thead><tr><th>方法名称</th><th>描述</th></tr></thead><tr><td>of(E first, e...rest)</td><td>创建包含指定枚举成员的 EnumSet 对象</td></tr><tr><td>allOf(Class element type)</td><td>创建一个包含指定枚举类型中所有枚举成员的 EnumSet 对象</td></tr><tr><td>range(E from, E to)</td><td>创建一个 EnumSet 对象，该对象包含了 from 到 to 之间的所有 枚举成员</td></tr><tr><td>complementOf(EnumSet s)</td><td>创建一个与指定 EnumSet 对象 s 相同的枚举类型 EnumSet 对 象，并包含所有 s 中未包含的枚举成员</td></tr><tr><td>copyOf(EnumSet s)</td><td>创建一个与指定 EnumSet 对象 s 相同的枚举类型 EnumSet 对 象，并与 s 包含相同的枚举成员</td></tr></table><table><thead><tr><th>方法名称</th><th>描述</th></tr></thead><tr><td>noneOf(<Class elementType)</td><td>创建指定枚举类型的空 EnumSet 对象</td></tr></table><h2 id="11-5-使用枚举类型的优势"><a href="#11-5-使用枚举类型的优势" class="headerlink" title="11.5 使用枚举类型的优势"></a>11.5 使用枚举类型的优势</h2><p>枚举类型声明提供了一种用户友好的变量定义方法，枚举了某种数据类型所有可能出现的值。总结枚举类型，有以下特点:</p><ul><li><p>类型安全</p></li><li><p>紧凑有效的数据定义</p></li><li><p>可以和程序其他部分完美交互</p></li><li><p>运行效率高</p></li></ul><p>更多关于Java泛型的有意思的学习经历也需要靠大家在日常工作中认真去体会啦~</p><h1 id="12-Java-8-新特性"><a href="#12-Java-8-新特性" class="headerlink" title="12. Java 8 新特性"></a>12. Java 8 新特性</h1><h2 id="12-1-Java-8-简介"><a href="#12-1-Java-8-简介" class="headerlink" title="12.1 Java 8 简介"></a>12.1 Java 8 简介</h2><p>Java 8是Java自 Java 5 (发布于2004年) 之后的最重要的版本。这个版本包含语言、编译器、库、工具和JVM等方面的十多个新特性。在本文中我们将学习这些新特性，并用实际的例子说明在什么场景下适合使用。</p><p>本文中我们假设Java开发者经常面对的几类问题:</p><ul><li><p>语言</p></li><li><p>编译器</p></li><li><p>库</p></li></ul><p>。 工具</p><ul><li>运行时 (JVM)</li></ul><h2 id="12-2-Java-8-特性详解"><a href="#12-2-Java-8-特性详解" class="headerlink" title="12.2 Java 8 特性详解"></a>12.2 Java 8 特性详解</h2><h2 id="12-2-1-Lambda表达式和函数式接口"><a href="#12-2-1-Lambda表达式和函数式接口" class="headerlink" title="12.2.1 Lambda表达式和函数式接口"></a>12.2.1 Lambda表达式和函数式接口</h2><p>Lambda表达式（也称为闭包）是Java 8中最大和最令人期待的语言改变。它允许我们将函数当成参数传递给某个方法，或者把代码本身当作数据处理：函数式开发者非常熟悉这些概念。如果没有lambda， Stream用起来相当别扭，他会产生大量的匿名内部类，所以lambda+default method使得jdk库更加强大，以及灵活，Stream以及集合框架的改进便是最好的证明。</p><p>(1). Lambda的设计耗费了很多时间和很大的社区力量，最终找到一种折中的实现方案，可以实现简洁而紧凑的语言结构。</p><p>Arrays.asList(“a”, “b”, “d”).forEach( e -&gt; System.out.println( e ));</p><p>上面这个代码中的参数e的类型是由编译器推理得出的，你也可以显式指定该参数的类型，例如：</p><p>Arrays.asList(“a”, “b”, “d”).forEach( (String e ) -&gt; System.out.println( e ) );</p><p>(2). 当Lambda表达式需要更复杂的语句块时，可以使用花括号将该语句块括起来，类似于Java中的函数体，例如:</p><p>Arrays.asList(“a”, “b”, “d”).forEach( e -&gt; {</p><p>System.out.print( e );</p><p>System.out.print( e );</p><p>});</p><p>(3). Lambda表达式可以引用类成员和局部变量（会将这些变量隐式得转换成final的），下列两个代码块的效果一致:</p><p>String separator ( &#x3D; ) “,”;</p><p>Arrays.asList(“a”, “b”, “d”).forEach(</p><p>( String e ) -&gt; System.out.print( e + separator ) );</p><p>final String separator ( &#x3D; ) “,”;</p><p>Arrays.asList(“a”, “b”, “d”).forEach(</p><p>( String e ) -&gt; System.out.print( e + separator ) );</p><p>(4). Lambda表达式是可以有返回值的，返回值的类型也由编译器推理得出。如果Lambda表达式中的语句块只有一行，则可以不用使用return语句，具体如下：</p><p>Arrays.asList(“a”, “b”, “d”).sort(( e1, e2)) -&gt; e1.compareTo( e2 ));</p><p>Arrays.asList(“a”, “b”, “d” ).sort( ( e1, e2 ) -&gt; {</p><p>int result ( &#x3D; ) e1.compareTo(e2);</p><p>return result;</p><p>});</p><p>为了让现有的功能与Lambda表达式良好兼容，函数接口应运而生。函数接口指的是只有一个函数的接 ( ▱ ) ，这样的接口可以隐式转换为Lambda表达式。java.lang.Runnable和java.util.concurrent.Callable是函数式接口的最佳例子。在实践中，函数式接口非常脆弱：只要某个开发者在该接口中添加一个函数， 则该接口就不再是函数式接口进而导致编译失败。为了克服这种代码层面的脆弱性，并显式说明某个接口是函数式接口，Java 8 提供了一个特殊的注解@FunctionalInterface，举个简单的函数式接口的定义:</p><p>@FunctionalInterface</p><p>public interface Functional {</p><p>void method();</p><p>}</p><p>如果你需要了解更多Lambda表达式的细节，一定要去看看官方文档哦。</p><h2 id="12-2-2-方法引用"><a href="#12-2-2-方法引用" class="headerlink" title="12.2.2 方法引用"></a>12.2.2 方法引用</h2><p>方法引用使得开发者可以直接引用现存的方法、Java类的构造方法或者实例对象。方法引用和Lambda表达式配合使用，使得java类的构造方法看起来紧凑而简洁，没有很多复杂的模板代码。</p><p>举个例子:</p><hr><p>public static class Car {</p><p>public static Car create( final Supplier&lt; Car &gt; supplier ) {</p><p>return supplier.get();</p><p>}</p><p>public static void collide( final Car car ) {</p><p>System.out.println( “Collided” + car.toString() );</p><p>}</p><p>public void follow( final Car another ) {</p><p>System.out.println( “Following the “ + another.toString() );</p><p>}</p><p>public void repair() {</p><p>System.out.println( “Repaired “ + this.toString() );</p><p>}</p><p>}</p><hr><p>方法一引用的类型是构造器引用，语法是Class::new，或者更一般的形式：Class::new。注意：这个构造器没有参数。</p><p>final car car &#x3D; Car.create( Car::new );</p><p>final List&lt; Car &gt; cars &#x3D; Arrays.asList( car );</p><p>方法二引用的类型是静态方法引用，语法是Class::static_method。注意：这个方法接受一个Car类型的参数。</p><p>cars.forEach( Car::collide );</p><p>方法三引用的类型是某个实例对象的成员方法的引用，语法是instance::method。注意：这个方法接受一个Car类型的参数:</p><p>final Car police ( &#x3D; ) Car.create(Car::new);</p><p>cars.forEach( police::follow );</p><p>方法四引用的类型是某个类的成员方法的引用，语法是Class::method，注意，这个方法没有定义入参：</p><p>cars.forEach( Car::repair );</p><p>运行上述例子，可以在控制台看到如下输出（Car实例可能不同）：</p><p>collided com.javacodegeeks.java8.method.references.MethodReferences$Car@7a81197d Repaired com.javacodegeeks.java8.method.references.MethodReferences$Car@7a81197d Following the</p><p>com. javacodegeeks . java8 . method . references . MethodReferences $Car@7a81197d</p><h2 id="12-2-3-接口的默认方法和静态方法"><a href="#12-2-3-接口的默认方法和静态方法" class="headerlink" title="12.2.3 接口的默认方法和静态方法"></a>12.2.3 接口的默认方法和静态方法</h2><p>Java 8使用两个新概念扩展了接口的含义：默认方法和静态方法。默认方法使得接口有点类似traits，不过要实现的目标不一样。默认方法使得开发者可以在 不破坏二进制兼容性的前提下，往现存接口中添加新的方法，即不强制那些实现了该接口的类也同时实现这个新加的方法。</p><p>默认方法和抽象方法之间的区别在于抽象方法需要实现，而默认方法不需要。接口提供的默认方法会被接口的实现类继承或者覆写，例子代码如下:</p><hr><p>private interface Defaulable {</p><p>&#x2F;&#x2F; Interfaces now allow default methods, the implementer may or</p><p>&#x2F;&#x2F; may not implement (override) them.</p><p>default String notRequired() {</p><p>return “Default implementation”;</p><p>}</p><p>}</p><p>private static class DefaultableImpl implements Defaulable {</p><p>}</p><p>private static class OverridableImpl implements Defaulable {</p><p>@override</p><p>public string notRequired() {</p><p>return “Overridden implementation”;</p><p>}</p><p>}</p><hr><p>Defaulable接口使用关键字default定义了一个默认方法notRequired()。DefaultableImpl类实现了这个接口，同时默认继承了这个接口中的默认方法；OverridableImpl类也实现了这个接口，但覆写了该接口的默认方法，并提供了一个不同的实现。</p><p>Java 8的另一个有趣的特性是在接口中定义静态方法，例子代码如下：</p><p>private interface DefaulableFactory {</p><p>&#x2F;&#x2F; Interfaces now allow static methods</p><p>static Defaulable create( Supplier&lt; Defaulable &gt; supplier ) {</p><p>return supplier.get();</p><p>}</p><p>}</p><p>下面的代码片段整合了默认方法和静态方法的使用场景：</p><p>public static void main( String[] args ) {</p><p>Defaulable defaulable ( &#x3D; ) DefaulableFactory.create(DefaultableImpl::new);</p><p>System.out.println( defaulable.notRequired());</p><p>defaulable ( &#x3D; ) DefaulableFactory.create(OverridableImpl::new);</p><p>System.out.println( defaulable.notRequired()); }</p><p>这段代码的输出结果如下:</p><p>Default implementation</p><p>Overridden implementation</p><p>由于JVM上的默认方法的实现在字节码层面提供了支持，因此效率非常高。默认方法允许在不打破现有继</p><p>承体系的基础上改进接口。该特性在官方库中的应用是：给java.util.Collection接口添加新方法，如</p><p>stream()、parallelStream()、forEach()和removeIf()等等。</p><h2 id="12-2-4-更好的类型推断"><a href="#12-2-4-更好的类型推断" class="headerlink" title="12.2.4 更好的类型推断"></a>12.2.4 更好的类型推断</h2><p>Java 8编译器在类型推断方面有很大的提升，在很多场景下编译器可以推导出某个参数的数据类型，从而使得代码更为简洁。例子代码如下:</p><hr><p>package com.javacodegeeks.java8.type.inference;</p><p>public class value&lt; ( T &gt; { )</p><p>public static&lt; ( T &gt; T ) defaultvalue() {</p><p>return null;</p><p>}</p><p>public ( T ) getOrDefault( ( T ) value, ( T ) defaultvalue ( ){ )</p><p>return ( value !&#x3D; null ) ? value : defaultvalue;</p><p>}</p><p>}</p><hr><h2 id="下列代码是Value类型的应用"><a href="#下列代码是Value类型的应用" class="headerlink" title="下列代码是Value类型的应用:"></a>下列代码是Value类型的应用:</h2><p>package com.javacodegeeks.java8.type.inference;</p><p>public class TypeInference {</p><p>public static void main(String[] args) {</p><p>final value&lt; String ( &gt; ) value ( &#x3D; ) new value ( &lt; &gt; \left( \right) ) ;</p><p>value.getOrDefault(“22”, value.defaultvalue());</p><p>}</p><p>}</p><p>参数Value.defaultValue()的类型由编译器推导得出，不需要显式指明。在Java 7中这段代码会有编译错误，除非使用Value.defaultValue()。</p><h2 id="12-2-5-重复注解"><a href="#12-2-5-重复注解" class="headerlink" title="12.2.5 重复注解"></a>12.2.5 重复注解</h2><p>自从Java 5中引入注解以来，这个特性开始变得非常流行，并在各个框架和项目中被广泛使用。不过，注解有一个很大的限制是：在同一个地方不能多次使用同一个注解。Java 8打破了这个限制，引入了重复注解的概念，允许在同一个地方多次使用同一个注解。</p><p>在Java 8中使用@Repeatable注解定义重复注解，实际上，这并不是语言层面的改进，而是编译器做的一个trick，底层的技术仍然相同。可以利用下面的代码说明：</p><hr><p>package com.javacodegeeks.java8.repeatable.annotations;</p><p>import java.lang.annotation.ElementType;</p><p>import java.lang.annotation.Repeatable;</p><p>import java.lang.annotation.Retention;</p><hr><hr><p>import java.lang.annotation.RetentionPolicy;</p><p>import java.lang.annotation.Target;</p><p>public class RepeatingAnnotations {</p><p>@Target( ElementType.TYPE )</p><p>@Retention( RetentionPolicy.RUNTIME )</p><p>public @interface Filters {</p><p>Filter[] value();</p><p>}</p><p>@Target( ElementType.TYPE )</p><p>@Retention( RetentionPolicy.RUNTIME )</p><p>@Repeatable( Filters.class )</p><p>public @interface Filter {</p><p>String value();</p><p>};</p><p>@Filter(“filter1”)</p><p>@Filter(“filter2”)</p><p>public interface Filterable {</p><p>}</p><p>public static void main(String[] args) {</p><p>for( Filter filter: Filterable.class.getAnnotationsByType( Filter.class )</p><p>) {</p><p>System.out.println( filter.value() );</p><p>}</p><p>}</p><p>}</p><hr><p>如上所见，这的Filter类使用@Repeatable(Filters.class)注解修饰，而Filters是存放Filter注解的容器，编译器尽量对开发者屏蔽这些细节。这样就会导致，Filterable接口可以用两个Filter注解注释（这里并没有提到任何关于Filters的信息）。</p><p>另外，反射API提供了一个新的方法：getAnnotationsByType()，可以返回某个类型的重复注解，例如 Filterable.class.getAnnoation(Filters.class)将返回两个Filter实例，输出到控制台的内容如下所示：</p><p>filter1</p><p>filter2</p><h2 id="12-2-6-拓展注解"><a href="#12-2-6-拓展注解" class="headerlink" title="12.2.6 拓展注解"></a>12.2.6 拓展注解</h2><p>Java 8拓宽了注解的应用场景。现在，注解几乎可以使用在任何元素上：局部变量、接口类型、超类和接口实现类，甚至可以用在函数的异常定义上。下面是一些例子：</p><p>package com.javacodegeeks.java8.annotations;</p><p>import java.lang.annotation.ElementType;</p><p>import java.lang.annotation.Retention;</p><p>import java.lang.annotation.RetentionPolicy;</p><p>import java.lang.annotation.Target;</p><p>import java.util.ArrayList;</p><p>import java.util.Collection;</p><p>public class Annotations {</p><p>@Retention( RetentionPolicy.RUNTIME )</p><p>@Target( { ElementType.TYPE_USE, ElementType.TYPE_PARAMETER })</p><p>public @interface NonEmpty {</p><p>}</p><p>public static class Holder&lt; @NonEmpty T &gt; extends @NonEmpty object {</p><p>public void method() throws @NonEmpty Exception {</p><p>}</p><p>}</p><p>@Suppresswarnings(“unused”)</p><p>public static void main(String[] args) {</p><p>final Holder&lt; String &gt; holder &#x3D; new @NonEmpty Holder&lt; String &gt;();</p><p>@NonEmpty Collection&lt; @NonEmpty String &gt; strings &#x3D; new ArrayList&lt;&gt;(); } }</p><p>ElementType.TYPE_USER和ElementType.TYPE_PARAMETER是Java 8新增的两个注解，用于描述注解的使用场景。Java 语言也做了对应的改变，以识别这些新增的注解。</p><h2 id="12-2-7-Java编译器的新特性"><a href="#12-2-7-Java编译器的新特性" class="headerlink" title="12.2.7 Java编译器的新特性"></a>12.2.7 Java编译器的新特性</h2><p>为了在运行时获得Java程序中方法的参数名称，老一辈的Java程序员必须使用不同方法，例如</p><p>Paranamer liberary。Java 8终于将这个特性规范化，在语言层面（使用反射API和</p><p>Parameter.getName()方法）和字节码层面（使用新的javac编译器以及-parameters参数）提供支持。</p><p>package com.javacodegeeks.java8.parameter.names;</p><p>import java.lang.reflect.Method;</p><p>import java.lang.reflect.Parameter;</p><p>public class ParameterNames {</p><p>public static void main(String[] args) throws Exception {</p><p>Method method &#x3D; ParameterNames.class.getMethod(“main”, String[].class );</p><p>for( final Parameter parameter: method.getParameters() ) {</p><p>System.out.println(“Parameter: “ + parameter.getName() );</p><p>}</p><p>}</p><p>}</p><p>在Java 8中这个特性是默认关闭的，因此如果不带-parameters参数编译上述代码并运行，则会输出如下结果:</p><p>Parameter: arg0</p><p>如果带-parameters参数，则会输出如下结果（正确的结果）：</p><p>Parameter: args</p><p>如果你使用Maven进行项目管理，则可以在maven-compiler-plugin编译器的配置项中配置-parameters 参数:</p><plugin><p><groupId>org.apache.maven.plugins</groupId></p><p><artifactId>maven-compiler-plugin</artifactId></p><p><version>3.1</version></p><configuration><p><compilerArgument>-parameters</compilerArgument></p><source>1.8</source><p><target>1.8</target></p></configuration></plugin><h4 id="12-2-8-Optional"><a href="#12-2-8-Optional" class="headerlink" title="12.2.8 Optional"></a>12.2.8 Optional</h4><p>Java应用中最常见的bug就是空值异常。在Java 8之前，Google Guava引入了Optionals类来解决</p><p>NullPointerException，从而避免源码被各种null检查污染，以便开发者写出更加整洁的代码。Java 8也将Optional加入了官方库。</p><p>Optional仅仅是一个容易：存放T类型的值或者null。它提供了一些有用的接口来避免显式的null检查， 可以参考Java 8官方文档了解更多细节。</p><p>接下来看一点使用Optional的例子：可能为空的值或者某个类型的值：</p><p>Optional&lt; String &gt; fullName &#x3D; Optional.ofNullable( null );</p><p>System.out.println(“Full Name is set?” + fullName.isPresent() );</p><p>System.out.println(“Full Name: “ + fullName.orElseGet( () -&gt; “[none]” ) );</p><p>System.out.println( fullName.map( s -&gt; “Hey” + s + “!” ).orElse( “Hey Stranger!” ））；</p><p>如果Optional实例持有一个非空值，则isPresent()方法返回true，否则返回false；orElseGet()方法， Optional实例持有null，则可以接受一个lambda表达式生成的默认值；map()方法可以将现有的 Opetional实例的值转换成新的值；orElse()方法与orElseGet()方法类似，但是在持有null的时候返回传入的默认值。</p><p>输出结果如下:</p><p>Full Name is set? false</p><p>Full Name: [none]</p><p>Hey Stranger!</p><h2 id="12-2-9-Streams"><a href="#12-2-9-Streams" class="headerlink" title="12.2.9 Streams"></a>12.2.9 Streams</h2><p>新增的Stream API（java.util.stream）将生成环境的函数式编程引入了Java库中。这是目前为止最大的一次对Java库的完善，以便开发者能够写出更加有效、更加简洁和紧凑的代码。</p><p>Steam API极大得简化了集合操作（后面我们会看到不止是集合），首先看下这个叫Task的类：</p><p>public class Streams {</p><p>private enum Status {</p><p>OPEN, CLOSED</p><p>};</p><p>private static final class Task {</p><p>private final Status status;</p><p>private final Integer points;</p><hr><p>Task( final Status status, final Integer points ) {</p><p>this.status ( &#x3D; ) status;</p><p>this.points ( &#x3D; ) points;</p><p>}</p><p>public Integer getPoints() {</p><p>return points;</p><p>}</p><p>public Status getStatus() {</p><p>return status;</p><p>}</p><p>@override</p><p>public string tostring() {</p><p>return String.format(“[%s, %d]”, status, points );</p><p>}</p><p>} }</p><hr><p>Task类有一个分数 (或伪复杂度) 的概念，另外还有两种状态：OPEN或者CLOSED。现在假设有一个 task集合:</p><p>final Collection&lt; Task &gt; tasks &#x3D; Arrays.asList(</p><p>new Task( Status.OPEN, 5 ),</p><p>new Task( Status.OPEN, 13 ),</p><p>new Task( Status.CLOSED, 8 )</p><p>);</p><p>试想一下：在这个task集合中一共有多少个处于OPEN状态的点？在Java 8之前，要解决这个问题，则需要使用foreach循环遍历task集合；但是在Java 8中可以利用steams解决：包括一系列元素的列表，并且支持顺序和并行处理。</p><p>&#x2F;&#x2F; Calculate total points of all active tasks using sum()</p><p>final long totalPointsOfOpenTasks &#x3D; tasks</p><p>.stream()</p><p>.filter( task -&gt; task.getStatus() &#x3D;&#x3D; Status.OPEN )</p><p>.mapToInt( Task::getPoints )</p><p>.sum();</p><p>System.out.println( “Total points: “ + totalPointsOfOpenTasks );</p><p>运行这个方法的控制台输出是:</p><p>Total points: 18</p><ul><li><p>tasks集合被转换成steam表示;</p></li><li><p>在steam上的filter操作会过滤掉所有CLOSED的task;</p></li><li><p>mapToInt操作基于每个task实例的Task::getPoints方法将task流转换成Integer集合;</p></li><li><p>通过sum方法计算总和，得出最后的结果。</p></li></ul><h2 id="12-2-10-Date-Time-API-JSR-310"><a href="#12-2-10-Date-Time-API-JSR-310" class="headerlink" title="12.2.10 Date&#x2F;Time API(JSR 310)"></a>12.2.10 Date&#x2F;Time API(JSR 310)</h2><p>Java 8引入了新的Date-Time API(JSR 310)来改进时间、日期的处理。时间和日期的管理一直是最令Java 开发者痛苦的问题。java.util.Date和后来的java.util.Calendar一直没有解决这个问题（甚至令开发者更加迷茫）。</p><p>由上述原因，诞生了第三方库Joda-Time，可以替代Java的时间管理API。Java 8中新的时间和日期管理 API深受Joda-Time影响，并吸收了很多Joda-Time的精华。新的java.time包包含了所有关于日期、时间、时区、Instant（跟日期类似但是精确到纳秒）、duration（持续时间）和时钟操作的类。新设计的 API认真考虑了这些类的不变性（从java.util.Calendar吸取的教训），如果某个实例需要修改，则返回一个新的对象。</p><table><thead><tr><th>方法</th><th>描述</th></tr></thead><tr><td>now()</td><td>静态方法，根据当前时间创建对象</td></tr><tr><td>of()</td><td>静态方法，根据指定日期/时间创建 对象</td></tr><tr><td>plusDays, plusWeeks, plusMonths, plusYears</td><td>向当前 LocalDate 对象添加几天、 几周、几个月、 几年</td></tr><tr><td>minusDays, minusWeeks, minusMonths, minusYears</td><td>从当前 LocalDate 对象减去几天、 几周、几个月 几年</td></tr><tr><td>plus, minus</td><td>添加或减少一个 Duration或 Period</td></tr><tr><td>withDayOfMonth, withDayOfYear, withMonth, withYear</td><td>将月份天数、年份天数、月份、年 份修改为指定的 值并返回新的 LocalDate对象</td></tr><tr><td>getDayOfMonth</td><td>获得月份天数(1-31)</td></tr><tr><td>getDayOfYear</td><td>获得年份天数(1-366)</td></tr><tr><td>getDayOfWeek</td><td>获得星期几(返回一个 DayOfWeek 枚举值</td></tr><tr><td>getMonth</td><td>获得月份, 返回一个 Month枚举值</td></tr><tr><td>getMonthValue</td><td>获得月份(1-12)</td></tr><tr><td>getYear</td><td>获得年份</td></tr><tr><td>until</td><td>获得两个日期之间的 Period 对象，或者指定 ChronoUnits的数字</td></tr><tr><td>isBefore, isAfter</td><td>比较两个 LocalDate</td></tr><tr><td>isLeapYear</td><td>判断是否是闰年</td></tr></table><p>我们接下来看看java.time包中的关键类和各自的使用例子。</p><p>首先，Clock类使用时区来返回当前的纳秒时间和日期。Clock可以替代System.currentTimeMillis()和 TimeZone.getDefault()。</p><p>&#x2F;&#x2F; Get the system clock as UTC offset</p><p>final clock clock ( &#x3D; ) clock.systemUTC();</p><p>System.out.println( clock.instant());</p><p>System.out.println( clock.millis() );</p><p>输出的结果是:</p><p>2014-04-12T15:19:29.282Z</p><p>1397315969360</p><p>LocalDateTime类包含了LocalDate和LocalTime的信息，但是不包含ISO-8601日历系统中的时区信息。 这里有一些关于LocalDate和LocalTime的例子:</p><p>&#x2F;&#x2F; Get the local date&#x2F;time</p><p>final LocalDateTime datetime ( &#x3D; ) LocalDateTime.now();</p><p>final LocalDateTime datetimeFromClock &#x3D; LocalDateTime.now( clock );</p><p>System.out.println( datetime );</p><p>System.out.println( datetimeFromClock );</p><p>输出的结果是:</p><p>2014-04-12T11:37:52.309</p><p>2014-04-12T15:37:52.309</p><p>最后看下Duration类，它持有的时间精确到秒和纳秒。这使得我们可以很容易得计算两个日期之间的不同，例子代码如下:</p><p>&#x2F;&#x2F; Get duration between two dates</p><p>final LocalDateTime from &#x3D; LocalDateTime.of( 2014, Month.APRIL, 16, 0, 0, 0 );</p><p>final LocalDateTime to ( &#x3D; ) LocalDateTime.of( 2015, Month.APRIL, 16, 23, 59, 59);</p><p>final Duration duration ( &#x3D; ) Duration.between( from, to );</p><p>System.out.println( “Duration in days: “ + duration.toDays() );</p><p>System.out.println( “Duration in hours: “ + duration.toHours() );</p><p>这个例子用于计算2014年4月16日和2015年4月16日之间的天数和小时数，输出结果如下：</p><p>Duration in days: 365</p><p>Duration in hours: 8783</p><p>对于Java 8的新日期时间的总体印象还是比较积极的，一部分是因为Joda-Time的积极影响，另一部分是因为官方终于听取了开发人员的需求。</p><h2 id="12-2-11-Base64"><a href="#12-2-11-Base64" class="headerlink" title="12.2.11 Base64"></a>12.2.11 Base64</h2><p>对Base64编码的支持已经被加入到Java 8官方库中，这样不需要使用第三方库就可以进行Base64编码， 例子代码如下:</p><p>package com.javacodegeeks.java8.base64;</p><p>import java.nio.charset.StandardCharsets;</p><p>import java.util.Base64;</p><p>public class Base64s {</p><p>public static void main(String[] args) {</p><p>final String text &#x3D; “Base64 finally in Java 8!”;</p><p>final String encoded ( &#x3D; ) Base64</p><p>.getEncoder()</p><p>.encodeToString( text.getBytes( StandardCharsets.UTF_8 ) );</p><p>System.out.println( encoded );</p><p>final string decoded ( &#x3D; ) new String(</p><p>Base64.getDecoder().decode( encoded ),</p><p>StandardCharsets.UTF_8 );</p><p>System.out.println( decoded ); } }</p><p>这个例子的输出结果如下:</p><p>QmFzZTY0IGZpbmFsbHkgaw4gSmF2YSA4IQ&#x3D;&#x3D;</p><p>Base64 finally in Java 8!</p><p>新的Base64API也支持URL和MINE的编码解码。</p><p>(Base64.getUrlEncoder() &#x2F; Base64.getUrlDecoder(), Base64.getMimeEncoder() &#x2F;</p><p>Base64.getMimeDecoder())。</p><h2 id="12-2-12-Nashorn-JavaScript引擎"><a href="#12-2-12-Nashorn-JavaScript引擎" class="headerlink" title="12.2.12 Nashorn JavaScript引擎"></a>12.2.12 Nashorn JavaScript引擎</h2><p>Java 8提供了新的Nashorn JavaScript引擎，使得我们可以在JVM上开发和运行JS应用。Nashorn</p><p>JavaScript引擎是javax.script.ScriptEngine的另一个实现版本，这类Script引擎遵循相同的规则，允许 Java和JavaScript交互使用，例子代码如下:</p><p>ScriptEngineManager manager &#x3D; new ScriptEngineManager();</p><p>ScriptEngine engine &#x3D; manager.getEngineByName(“JavaScript”);</p><p>System.out.println( engine.getClass().getName());</p><p>System.out.println(“Result:” + engine.eval(“function ( f\left( \right) { ) return ( 1;} ;f\left( \right) + )</p><p>1;” ) );</p><p>这个代码的输出结果如下:</p><p>jdk.nashorn.api.scripting.NashornScriptEngine</p><p>Result: 2</p><h2 id="12-2-13-并行数组"><a href="#12-2-13-并行数组" class="headerlink" title="12.2.13 并行数组"></a>12.2.13 并行数组</h2><p>Java8版本新增了很多新的方法，用于支持并行数组处理。最重要的方法是parallelSort()，可以显著加快多核机器上的数组排序。下面的例子论证了parallexXxx系列的方法：</p><p>package com.javacodegeeks.java8.parallel.arrays;</p><p>import java.util.Arrays;</p><p>import java.util.concurrent.ThreadLocalRandom;</p><p>public class ParallelArrays {</p><p>public static void main( String[] args ) {</p><p>long[] arrayOfLong &#x3D; new long [ 20000 ];</p><p>Arrays.parallelSetAll(arrayOfLong,</p><p>index -&gt; ThreadLocalRandom.current().nextInt( 1000000 );</p><p>Arrays.stream( arrayOfLong ).limit( 10 ).forEach(</p><p>i -&gt; System.out.print( i + “ “ ) );</p><p>System.out.println();</p><p>Arrays.parallelSort( arrayOfLong );</p><p>Arrays.stream( arrayOfLong ).limit( 10 ).forEach(</p><p>i -&gt; System.out.print( i + “ “ ) );</p><p>System.out.println(); } }</p><p>上述这些代码使用parallelSetAll()方法生成20000个随机数，然后使用parallelSort()方法进行排序。这个程序会输出乱序数组和排序数组的前10个元素。上述例子的代码输出的结果是:</p><p>Unsorted: 591217 891976 443951 424479 766825 351964 242997 642839 119108 552378</p><p>Sorted: 39 220 263 268 325 607 655 678 723 793</p><h2 id="12-2-14-并发性"><a href="#12-2-14-并发性" class="headerlink" title="12.2.14 并发性"></a>12.2.14 并发性</h2><p>基于新增的lambda表达式和steam特性，为Java 8中为java.util.concurrent.Concurrent.HashMap类添加了新的方法来支持聚焦操作；另外，也为java.util.concurrentForkjoinPool类添加了新的方法来支持通用线程池操作（更多内容可以参考我们的并发编程课程）。</p><p>Java 8还添加了新的java.util.concurrent.locks.StampedLock类，用于支持基于容量的锁——该锁有三个模型用于支持读写操作（可以把这个锁当做是java.util.concurrent.locks.ReadWriteLock的替代者）。</p><p>在java.util.concurrent.atomic包中也新增了不少工具类，列举如下:</p><p>DoubleAccumulator</p><p>DoubleAdder</p><p>LongAccumulator</p><p>LongAdder</p><h2 id="12-2-15-JVM的新特性"><a href="#12-2-15-JVM的新特性" class="headerlink" title="12.2.15 JVM的新特性"></a>12.2.15 JVM的新特性</h2><p>使用Metaspace (JEP 122) 代替持久代 (PermGen space) 。在JVM参数方面，使用-</p><p>XX:MetaSpaceSize和-XX:MaxMetaspaceSize代替原来的-XX:PermSize和-XX:MaxPermSize。</p><p>距JAVA 8更行已有数年之久，现在的学习者大多在一开始就已经适应了JAVA 8 的新特性，如果想要了解更多关于JAVA 8新特性的细节一定要浏览官网文档哦~！！！</p>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++图学习整理</title>
      <link href="/2024/06/23/C-%E5%9B%BE%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86/"/>
      <url>/2024/06/23/C-%E5%9B%BE%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="C-图学习整理"><a href="#C-图学习整理" class="headerlink" title="C++图学习整理"></a>C++图学习整理</h1><h2 id="最小生成树"><a href="#最小生成树" class="headerlink" title="最小生成树"></a>最小生成树</h2><p>在无向图中生成一棵树（n-1条边，无环，连通所有点），且这棵树的劝和最小</p><h3 id="普利姆算法（Prim）——加点法"><a href="#普利姆算法（Prim）——加点法" class="headerlink" title="普利姆算法（Prim）——加点法"></a>普利姆算法（Prim）——加点法</h3><ol><li><p>任选一点开始，找到离这个点最近的点，加入最小生成树</p></li><li><p>再继续去找离这个最小生成树最近的点，加入最小生成树中，重复步骤2</p></li></ol><h3 id="克鲁斯卡尔算法（Kruskal）-——加边法"><a href="#克鲁斯卡尔算法（Kruskal）-——加边法" class="headerlink" title="克鲁斯卡尔算法（Kruskal） ——加边法"></a>克鲁斯卡尔算法（Kruskal） ——加边法</h3><ol><li>找到最短边，判断其两个端点在不在一个连通分量里</li><li>若在，则跳过；若不在，加入最小生成树</li></ol><h3 id="洛谷例题"><a href="#洛谷例题" class="headerlink" title="洛谷例题"></a>洛谷例题</h3><h4 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h4><p>如题，给出一个无向图，求出最小生成树，如果该图不连通，则输出 <code>orz</code>。</p><h4 id="输入格式"><a href="#输入格式" class="headerlink" title="输入格式"></a>输入格式</h4><p>第一行包含两个整数 $N,M$，表示该图共有 $N$ 个结点和 $M$ 条无向边。</p><p>接下来 $M$ 行每行包含三个整数 $X_i,Y_i,Z_i$，表示有一条长度为 $Z_i$ 的无向边连接结点 $X_i,Y_i$。</p><h4 id="输出格式"><a href="#输出格式" class="headerlink" title="输出格式"></a>输出格式</h4><p>如果该图连通，则输出一个整数表示最小生成树的各边的长度之和。如果该图不连通则输出 <code>orz</code>。</p><h4 id="样例-1"><a href="#样例-1" class="headerlink" title="样例 #1"></a>样例 #1</h4><h5 id="样例输入-1"><a href="#样例输入-1" class="headerlink" title="样例输入 #1"></a>样例输入 #1</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">4 5</span><br><span class="line">1 2 2</span><br><span class="line">1 3 2</span><br><span class="line">1 4 3</span><br><span class="line">2 3 4</span><br><span class="line">3 4 3</span><br></pre></td></tr></table></figure><h5 id="样例输出-1"><a href="#样例输出-1" class="headerlink" title="样例输出 #1"></a>样例输出 #1</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">7</span><br></pre></td></tr></table></figure><h4 id="提示"><a href="#提示" class="headerlink" title="提示"></a>提示</h4><p>数据规模：</p><p>对于 $20%$ 的数据，$N\le 5$，$M\le 20$。</p><p>对于 $40%$ 的数据，$N\le 50$，$M\le 2500$。</p><p>对于 $70%$ 的数据，$N\le 500$，$M\le 10^4$。</p><p>对于 $100%$ 的数据：$1\le N\le 5000$，$1\le M\le 2\times 10^5$，$1\le Z_i \le 10^4$。</p><p>样例解释：</p><p> <img src="https://cdn.luogu.com.cn/upload/pic/2259.png"> </p><p>所以最小生成树的总边权为 $2+2+3&#x3D;7$。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstdio&gt;</span>   <span class="comment">// 包含标准输入输出库</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;queue&gt;</span>    <span class="comment">// 包含优先队列库</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> INF 2147483647    <span class="comment">// 定义无穷大（表示不可达距离）</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAXN 5001         <span class="comment">// 定义最大节点数</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAXM 200001       <span class="comment">// 定义最大边数</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 全局变量</span></span><br><span class="line"><span class="type">int</span> head[MAXN], dis[MAXN];   <span class="comment">// head：每个节点的邻接表的头指针，dis：节点到MST的最小距离</span></span><br><span class="line"><span class="type">bool</span> vis[MAXN];              <span class="comment">// vis：标记节点是否已加入MST</span></span><br><span class="line"><span class="type">int</span> edge_sum = <span class="number">0</span>;            <span class="comment">// 边计数</span></span><br><span class="line"><span class="type">int</span> n, m, MST;               <span class="comment">// n：节点数，m：边数，MST：最小生成树的权重和</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 边结构体定义，存储边的目标节点及权重</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Edge</span> &#123;</span><br><span class="line">    <span class="type">int</span> next, to, dis;</span><br><span class="line">&#125; edge[MAXM &lt;&lt; <span class="number">1</span>];   <span class="comment">// 使用两倍最大边数的数组，考虑无向图每条边存两次</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 添加边到邻接表</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">addedge</span><span class="params">(<span class="type">int</span> from, <span class="type">int</span> to, <span class="type">int</span> dis)</span> </span>&#123;</span><br><span class="line">    edge[++edge_sum].next = head[from]; <span class="comment">// 设置新边的下一个指针为当前头指针</span></span><br><span class="line">    edge[edge_sum].to = to;             <span class="comment">// 设置目标节点</span></span><br><span class="line">    edge[edge_sum].dis = dis;           <span class="comment">// 设置边的权重</span></span><br><span class="line">    head[from] = edge_sum;              <span class="comment">// 更新头指针为新边的索引</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 优先队列中的节点结构体</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">node</span> &#123;</span><br><span class="line">    <span class="type">int</span> u, dis;  <span class="comment">// u：节点编号，dis：距离</span></span><br><span class="line">    <span class="comment">// 重载运算符 &lt;，使得优先队列按距离从小到大排序</span></span><br><span class="line">    <span class="type">bool</span> <span class="keyword">operator</span> &lt;(<span class="type">const</span> node&amp; rhs) <span class="type">const</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> dis &gt; rhs.dis;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Prim算法实现</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">prim</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    priority_queue&lt;node&gt; q;  <span class="comment">// 优先队列，用于选择最小权重的边</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">register</span> <span class="type">int</span> i = <span class="number">0</span>; i &lt;= n; i++)  <span class="comment">// 初始化所有节点的距离为无穷大</span></span><br><span class="line">        dis[i] = INF;</span><br><span class="line">    dis[<span class="number">1</span>] = <span class="number">0</span>;              <span class="comment">// 设置起始节点1的距离为0</span></span><br><span class="line">    q.<span class="built_in">push</span>((node&#123;<span class="number">1</span>, <span class="number">0</span>&#125;));    <span class="comment">// 将起始节点1加入优先队列</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (!q.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        node tmp = q.<span class="built_in">top</span>();  <span class="comment">// 取出距离最小的节点</span></span><br><span class="line">        q.<span class="built_in">pop</span>();</span><br><span class="line">        <span class="type">int</span> u = tmp.u, d = tmp.dis;</span><br><span class="line">        <span class="keyword">if</span> (vis[u]) <span class="keyword">continue</span>;  <span class="comment">// 如果节点已访问过，跳过</span></span><br><span class="line">        vis[u] = <span class="number">1</span>;            <span class="comment">// 标记节点u为已访问</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">register</span> <span class="type">int</span> j = head[u]; j; j = edge[j].next) &#123;  <span class="comment">// 遍历邻接节点</span></span><br><span class="line">            <span class="keyword">if</span> (!vis[edge[j].to] &amp;&amp; edge[j].dis &lt; dis[edge[j].to]) &#123;  <span class="comment">// 如果邻接节点未访问且距离更短</span></span><br><span class="line">                dis[edge[j].to] = edge[j].dis;  <span class="comment">// 更新距离</span></span><br><span class="line">                <span class="keyword">if</span> (!vis[edge[j].to]) q.<span class="built_in">push</span>((node)&#123;edge[j].to, dis[edge[j].to]&#125;);  <span class="comment">// 将节点加入优先队列</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 主函数</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d%d&quot;</span>, &amp;n, &amp;m);  <span class="comment">// 输入节点数和边数</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">register</span> <span class="type">int</span> i = <span class="number">1</span>; i &lt;= m; i++) &#123;</span><br><span class="line">        <span class="type">int</span> x, y, z;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d%d%d&quot;</span>, &amp;x, &amp;y, &amp;z);  <span class="comment">// 输入边的起点、终点和权重</span></span><br><span class="line">        <span class="built_in">addedge</span>(x, y, z);   <span class="comment">// 添加边</span></span><br><span class="line">        <span class="built_in">addedge</span>(y, x, z);   <span class="comment">// 无向图需要添加两次（反向边）</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">prim</span>();  <span class="comment">// 执行Prim算法</span></span><br><span class="line"></span><br><span class="line">    <span class="type">bool</span> flag = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">register</span> <span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i++) &#123;  <span class="comment">// 检查所有节点是否都被访问过</span></span><br><span class="line">        <span class="keyword">if</span> (dis[i] == INF)</span><br><span class="line">            flag = <span class="number">1</span>;   <span class="comment">// 如果有节点未访问到，说明图不连通</span></span><br><span class="line">        MST += dis[i];  <span class="comment">// 累加MST的总权重</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!flag) <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, MST);  <span class="comment">// 如果所有节点都访问到，输出MST的总权重</span></span><br><span class="line">    <span class="keyword">else</span> <span class="built_in">printf</span>(<span class="string">&quot;orz\n&quot;</span>);  <span class="comment">// 否则输出&quot;orz&quot;，表示图不连通</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="最短路径"><a href="#最短路径" class="headerlink" title="最短路径"></a>最短路径</h2><h3 id="迪杰斯特拉（Dijkstra）算法——找到a到其他点的最短路径"><a href="#迪杰斯特拉（Dijkstra）算法——找到a到其他点的最短路径" class="headerlink" title="迪杰斯特拉（Dijkstra）算法——找到a到其他点的最短路径"></a>迪杰斯特拉（Dijkstra）算法——找到a到其他点的最短路径</h3><p>每次都选距离a最近的点，然后更新</p><p><img src="/../img/cpp/2.png" alt="2"></p><h3 id="弗洛伊德（Floyd）算法"><a href="#弗洛伊德（Floyd）算法" class="headerlink" title="弗洛伊德（Floyd）算法"></a>弗洛伊德（Floyd）算法</h3><p>求任意两个点的最短路径，使用邻接矩阵来存储</p><ul><li>数组D保存任意两个点的最短路径</li><li>数组Path保存任意两个点之间的最短路径本身</li></ul><p><img src="/../img/cpp/3.png" alt="3"></p><p><img src="/../img/cpp/4.png" alt="4"></p><h2 id="关键路径——AOE网中最长的路"><a href="#关键路径——AOE网中最长的路" class="headerlink" title="关键路径——AOE网中最长的路"></a>关键路径——AOE网中最长的路</h2><h3 id="AOE"><a href="#AOE" class="headerlink" title="AOE"></a>AOE</h3><p>—边上有权值的图</p><h3 id="拓扑排序"><a href="#拓扑排序" class="headerlink" title="拓扑排序"></a>拓扑排序</h3><p>—每次选入度为0的点，然后删除这个点和它的出边</p><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>AOE网中的节点为事件，边为路径</p><p>v—vertex(事件)；e—early；l—late</p><p>先设变量ve,vl,e,l</p><p>通过一次拓扑排序，求出每个节点的ve；</p><p>再通过一次逆拓扑排序，求出每个节点的vl；</p>]]></content>
      
      
      
        <tags>
            
            <tag> c++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch6多层感知机</title>
      <link href="/2024/06/21/Pytorch6-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"/>
      <url>/2024/06/21/Pytorch6-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="多层感知机"><a href="#多层感知机" class="headerlink" title="多层感知机"></a>多层感知机</h1><h2 id="隐藏层"><a href="#隐藏层" class="headerlink" title="隐藏层"></a>隐藏层</h2><p>在多层感知机（Multilayer Perceptron, MLP）中，隐藏层（Hidden Layer）是指位于输入层和输出层之间的神经元层。多层感知机是一种前馈神经网络，通常由多个隐藏层组成，每个隐藏层由多个神经元组成。</p><p>隐藏层的作用是对输入数据进行非线性映射和特征提取，使得神经网络能够学习到复杂的模式和关系。每个隐藏层中的每个神经元接收来自上一层（或者输入层）的输入，通过加权和和激活函数处理后输出给下一层（或者输出层）。</p><p>具体来说，多层感知机的运作过程如下：</p><ol><li><strong>输入层</strong>接收原始数据或特征向量作为输入。</li><li><strong>隐藏层</strong>接收来自输入层的输入，对其进行线性加权和，并通过一个非线性的激活函数（如ReLU、sigmoid等）进行转换，输出给下一层或输出层。</li><li><strong>输出层</strong>接收最后一个隐藏层的输出，进行最终的处理和分类，输出预测结果。</li></ol><p>隐藏层的引入使得多层感知机能够处理复杂的非线性问题，并且通过调整隐藏层的神经元数量和结构，可以增加神经网络的表达能力，提高其对数据的建模能力和预测精度。</p><h3 id="线性模型可能会出错"><a href="#线性模型可能会出错" class="headerlink" title="线性模型可能会出错"></a>线性模型可能会出错</h3><p>例如，线性意味着<em>单调</em>假设： 任何特征的增大都会导致模型输出的增大（如果对应的权重为正）， 或者导致模型输出的减小（如果对应的权重为负）。 有时这是有道理的。 例如，如果我们试图预测一个人是否会偿还贷款。 我们可以认为，在其他条件不变的情况下， 收入较高的申请人比收入较低的申请人更有可能偿还贷款。 但是，虽然收入与还款概率存在单调性，但它们不是线性相关的。 收入从0增加到5万，可能比从100万增加到105万带来更大的还款可能性。 处理这一问题的一种方法是对我们的数据进行预处理， 使线性变得更合理，如使用收入的对数作为我们的特征。</p><p>然而我们可以很容易找出违反单调性的例子。 例如，我们想要根据体温预测死亡率。 对体温高于37摄氏度的人来说，温度越高风险越大。 然而，对体温低于37摄氏度的人来说，温度越高风险就越低。 在这种情况下，我们也可以通过一些巧妙的预处理来解决问题。 例如，我们可以使用与37摄氏度的距离作为特征。</p><p>但是，如何对猫和狗的图像进行分类呢？ 增加位置(13,17)处像素的强度是否总是增加（或降低）图像描绘狗的似然？ 对线性模型的依赖对应于一个隐含的假设， 即区分猫和狗的唯一要求是评估单个像素的强度。 在一个倒置图像后依然保留类别的世界里，这种方法注定会失败。</p><p>与我们前面的例子相比，这里的线性很荒谬， 而且我们难以通过简单的预处理来解决这个问题。 这是因为任何像素的重要性都以复杂的方式取决于该像素的上下文（周围像素的值）。 我们的数据可能会有一种表示，这种表示会考虑到我们在特征之间的相关交互作用。 在此表示的基础上建立一个线性模型可能会是合适的， 但我们不知道如何手动计算这么一种表示。 对于深度神经网络，我们使用观测数据来联合学习隐藏层表示和应用于该表示的线性预测器。</p><h3 id="在网络中加入隐藏层"><a href="#在网络中加入隐藏层" class="headerlink" title="在网络中加入隐藏层"></a>在网络中加入隐藏层</h3><p>我们可以通过在网络中加入一个或多个隐藏层来克服线性模型的限制， 使其能处理更普遍的函数关系类型。 要做到这一点，最简单的方法是将许多全连接层堆叠在一起。 每一层都输出到上面的层，直到生成最后的输出。 我们可以把前𝐿−1层看作表示，把最后一层看作线性预测器。 这种架构通常称为<em>多层感知机</em>（multilayer perceptron），通常缩写为<em>MLP</em>。 下面，我们以图的方式描述了多层感知机</p><p><img src="/../img/Pytorch1/pytorch6/1.png" alt="1"></p><p>这个多层感知机有4个输入，3个输出，其隐藏层包含5个隐藏单元。 输入层不涉及任何计算，因此使用此网络产生输出只需要实现隐藏层和输出层的计算。 因此，这个多层感知机中的层数为2。 注意，这两个层都是全连接的。 每个输入都会影响隐藏层中的每个神经元， 而隐藏层中的每个神经元又会影响输出层中的每个神经元。</p><p>然而，具有全连接层的多层感知机的参数开销可能会高得令人望而却步。 即使在不改变输入或输出大小的情况下， 可能在参数节约和模型有效性之间进行权衡</p><h3 id="从线性到非线性"><a href="#从线性到非线性" class="headerlink" title="从线性到非线性"></a>从线性到非线性</h3><p>在每一个隐藏层的输出后面使用一个激活函数，来引入非线性特性和增强模型的表达能力</p><p>如果没有激活函数，多层感知机就只是简单的线性变换堆叠，无法学习非线性函数</p><h3 id="常见激活函数"><a href="#常见激活函数" class="headerlink" title="常见激活函数"></a>常见激活函数</h3><p><strong>Sigmoid函数（Logistic函数）：</strong> 将输入映射到(0, 1)区间，主要用于输出层的二分类问题。<br>$$<br>\sigma(x) &#x3D; \frac{1}{1 + e^{-x}}<br>$$<br><strong>ReLU函数（Rectified Linear Unit）：</strong> 对于正数部分输出其本身，负数部分输出0，通常在隐藏层中使用，有助于加速训练。<br>$$<br>\text{ReLU}(x) &#x3D; \max(0, x)<br>$$<br><strong>tanh函数（双曲正切函数）：</strong> 将输入映射到(-1, 1)区间，与sigmoid函数类似，但输出范围更广泛，有时在隐藏层中使用。<br>$$<br>\tanh(x) &#x3D; \frac{e^x - e^{-x}}{e^x + e^{-x}}<br>$$</p><h2 id="多层感知机的pytorch实现"><a href="#多层感知机的pytorch实现" class="headerlink" title="多层感知机的pytorch实现"></a>多层感知机的pytorch实现</h2><p>依旧使用Fashion-MNIST图像分类数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br></pre></td></tr></table></figure><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>与softmax回归的pytorch实现相比， 唯一的区别是我们添加了2个全连接层（之前我们只添加了1个全连接层）。 第一层是隐藏层，它包含256个隐藏单元，并使用了ReLU激活函数。 第二层是输出层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(nn.Flatten(),</span><br><span class="line">                    nn.Linear(<span class="number">784</span>, <span class="number">256</span>),</span><br><span class="line">                    nn.ReLU(),</span><br><span class="line">                    nn.Linear(<span class="number">256</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        nn.init.normal_(m.weight, std=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">net.apply(init_weights);</span><br></pre></td></tr></table></figure><p>训练过程的实现与我们实现softmax回归时完全相同， 这种模块化设计使我们能够将与模型架构有关的内容独立出来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">batch_size, lr, num_epochs = <span class="number">256</span>, <span class="number">0.1</span>, <span class="number">10</span></span><br><span class="line">loss = nn.CrossEntropyLoss(reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">trainer = torch.optim.SGD(net.parameters(), lr=lr)</span><br><span class="line"></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br><span class="line">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</span><br></pre></td></tr></table></figure><p><img src="/../img/Pytorch1/pytorch6/2.png" alt="2"></p><h2 id="模型选择、欠拟合和过拟合"><a href="#模型选择、欠拟合和过拟合" class="headerlink" title="模型选择、欠拟合和过拟合"></a>模型选择、欠拟合和过拟合</h2><p>我们的目标是发现<em>模式</em>（pattern）。且模型应该是真正发现了一种泛化的模式， 而不是简单地记住了数据</p><p>将模型在训练数据上拟合的比在潜在分布中更接近的现象称为<em>过拟合</em>（overfitting）， 用于对抗过拟合的技术称为<em>正则化</em>（regularization）</p><h3 id="训练误差和泛化误差"><a href="#训练误差和泛化误差" class="headerlink" title="训练误差和泛化误差"></a>训练误差和泛化误差</h3><p><em>训练误差</em>（training error）是指， 模型在训练数据集上计算得到的误差。 <em>泛化误差</em>（generalization error）是指， 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。</p><p>在实际中，我们只能通过将模型应用于一个独立的测试集来估计泛化误差， 该测试集由随机选取的、未曾在训练集中出现的数据样本构成。</p><h3 id="过拟合、欠拟合"><a href="#过拟合、欠拟合" class="headerlink" title="过拟合、欠拟合"></a>过拟合、欠拟合</h3><p>当训练误差和验证误差都很严重， 但它们之间仅有一点差距。 如果模型不能降低训练误差，这可能意味着模型过于简单（即表达能力不足）， 无法捕获试图学习的模式。 此外，由于我们的训练和验证误差之间的<em>泛化误差</em>很小， 我们有理由相信可以用一个更复杂的模型降低训练误差。 这种现象被称为<em>欠拟合</em>（underfitting）。即因模型问题导致训练和泛化误差都很大</p><p>当我们的训练误差明显低于验证误差时， 这表明严重的<em>过拟合</em>（overfitting）</p><p>但是，<em>过拟合</em>并不总是一件坏事。 特别是在深度学习领域，众所周知， 最好的预测模型在训练数据上的表现往往比在保留（验证）数据上好得多。 最终，我们通常更关心验证误差，而不是训练误差和验证误差之间的差距。</p><p>是否过拟合或欠拟合可能取决于模型复杂性和可用训练数据集的大小</p><h4 id="模型复杂性"><a href="#模型复杂性" class="headerlink" title="模型复杂性"></a>模型复杂性</h4><p>高阶多项式函数比低阶多项式函数复杂得多。 高阶多项式的参数较多，模型函数的选择范围较广。 因此在固定训练数据集的情况下， 高阶多项式函数相对于低阶多项式的训练误差应该始终更低（最坏也是相等）。 事实上，当数据样本包含了𝑥的不同值时， 函数阶数等于数据样本数量的多项式函数可以完美拟合训练集。 在下图中， 我们直观地描述了多项式的阶数和欠拟合与过拟合之间的关系。</p><p><img src="/../img/Pytorch1/pytorch6/3.png" alt="3"></p><h4 id="数据集大小"><a href="#数据集大小" class="headerlink" title="数据集大小"></a>数据集大小</h4><p>训练数据集中的样本越少，我们就越有可能（且更严重地）过拟合。 随着训练数据量的增加，泛化误差通常会减小。 </p><h2 id="权重衰减"><a href="#权重衰减" class="headerlink" title="权重衰减"></a>权重衰减</h2><p>权重衰减（Weight Decay）是一种在深度学习中广泛使用的正则化技术，旨在减少模型的过拟合现象。以下是关于权重衰减的详细解释：</p><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>权重衰减通过在模型的损失函数中引入一个与权重参数的平方和成正比的惩罚项，来限制模型权重的大小，从而降低模型的复杂度。这种正则化技术能够有效地防止模型在训练数据上过拟合，并提高模型的泛化能力。</p><h3 id="作用原理"><a href="#作用原理" class="headerlink" title="作用原理"></a>作用原理</h3><ol><li><strong>降低模型复杂度</strong>：通过惩罚模型中的权重参数，使其趋向于较小的值，从而降低模型的复杂度。这有助于减少模型对训练数据的过度依赖，避免在测试数据上表现不佳。</li><li><strong>平衡拟合能力与泛化能力</strong>：通过调整权重衰减的系数（正则化参数λ），可以平衡模型的拟合能力和泛化能力。较小的λ值可能导致模型对训练数据的拟合能力过强，而较大的λ值则可能使模型过于简单，无法充分捕捉数据的特征。</li><li><strong>减少特征依赖性</strong>：权重衰减可以减少模型对特定特征的过度依赖，从而降低过拟合的风险。</li></ol><h3 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h3><p>权重衰减的实现通常有两种方式：L1正则化和L2正则化。</p><ul><li><strong>L1正则化</strong>：向损失函数中添加权重参数的绝对值之和作为惩罚项。这种方式会使部分权重收缩为0，从而实现特征选择的效果。</li><li><strong>L2正则化</strong>：向损失函数中添加权重参数的平方和作为惩罚项。这种方式会使所有权重都趋向于较小的值，从而实现权重衰减的效果。L2正则化也称为权重衰减。</li></ul><h3 id="数学表示"><a href="#数学表示" class="headerlink" title="数学表示"></a>数学表示</h3><p>假设模型的权重参数为W，损失函数为L，那么引入权重衰减后的损失函数可以表示为：</p><p>L’ &#x3D; L + λ * ||W||^2</p><p>其中，||W||^2表示W的平方和，λ是正则化参数，用于控制惩罚的大小。λ越大，惩罚的作用越强，权重参数W越趋近于0。</p><h3 id="实现步骤"><a href="#实现步骤" class="headerlink" title="实现步骤"></a>实现步骤</h3><ol><li><strong>定义模型结构和参数</strong>：首先，需要定义深度学习模型的结构和参数。</li><li><strong>定义损失函数</strong>：然后，定义模型在训练数据上的损失函数。</li><li><strong>添加正则化项</strong>：在损失函数中添加与权重参数的平方和成正比的惩罚项，即正则化项。</li><li><strong>构建优化算法</strong>：使用梯度下降法或其变种来优化损失函数，同时更新模型的权重参数。</li><li><strong>迭代训练</strong>：在每次迭代中，计算模型在训练数据上的损失函数、正则化项和总的目标函数，并使用优化算法更新模型的权重参数。</li></ol><p>通过以上步骤，可以有效地实现权重衰减，并降低模型的过拟合风险。</p><h3 id="自我感悟"><a href="#自我感悟" class="headerlink" title="自我感悟"></a>自我感悟</h3><h4 id="正则化定义"><a href="#正则化定义" class="headerlink" title="正则化定义"></a>正则化定义</h4><p>凡是可以减少泛化误差，而不是减少训练误差的方法，即减小过拟合</p><h4 id="利用L1，L2减小过拟合的原因"><a href="#利用L1，L2减小过拟合的原因" class="headerlink" title="利用L1，L2减小过拟合的原因"></a>利用L1，L2减小过拟合的原因</h4><p>因为高维的模型在训练训练集时，很容易出现很大的w值，即使最后的损失函数很小，过大的w值在测试集很容易将误差和噪声增大</p><p>解决：人为地给参数画一个框框，即可行域范围：在求损失函数的时候，规定一个w的可行域，即范数</p><h2 id="暂退法"><a href="#暂退法" class="headerlink" title="暂退法"></a>暂退法</h2><p>—-另一种减少过拟合的方法</p><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>前面提到，出现过拟合的原因是权重w过大，暂退法通过随机丢弃一些神经元来减少神经网络对单一神经元的依赖</p><h3 id="Pytorch实现"><a href="#Pytorch实现" class="headerlink" title="Pytorch实现"></a>Pytorch实现</h3><p>对于深度学习框架的高级API，我们只需在每个全连接层之后添加一个<code>Dropout</code>层， 将暂退概率作为唯一的参数传递给它的构造函数。 在训练时，<code>Dropout</code>层将根据指定的暂退概率随机丢弃上一层的输出（相当于下一层的输入）。 在测试时，<code>Dropout</code>层仅传递数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(nn.Flatten(),</span><br><span class="line">        nn.Linear(<span class="number">784</span>, <span class="number">256</span>),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        <span class="comment"># 在第一个全连接层之后添加一个dropout层</span></span><br><span class="line">        nn.Dropout(dropout1),</span><br><span class="line">        nn.Linear(<span class="number">256</span>, <span class="number">256</span>),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        <span class="comment"># 在第二个全连接层之后添加一个dropout层</span></span><br><span class="line">        nn.Dropout(dropout2),</span><br><span class="line">        nn.Linear(<span class="number">256</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        nn.init.normal_(m.weight, std=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">net.apply(init_weights);</span><br></pre></td></tr></table></figure><p>对模型进行训练和测试</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">trainer = torch.optim.SGD(net.parameters(), lr=lr)</span><br><span class="line">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</span><br></pre></td></tr></table></figure><p><img src="/../img/Pytorch1/pytorch6/4.png" alt="4"></p><h2 id="前向传播，反向传播和计算图"><a href="#前向传播，反向传播和计算图" class="headerlink" title="前向传播，反向传播和计算图"></a>前向传播，反向传播和计算图</h2><p>以带权重衰减（𝐿2正则化）的单隐藏层多层感知机为例。</p><h3 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h3><p>假设输入样本是 𝑥∈𝑅𝑑， 并且我们的隐藏层不包括偏置项。</p><p><img src="/../img/Pytorch1/pytorch6/5.png" alt="5"></p><h3 id="前向传播计算图"><a href="#前向传播计算图" class="headerlink" title="前向传播计算图"></a>前向传播计算图</h3><p>计算图可以可视化计算中操作符和变量的依赖关系</p><p>正方形为变量；圆形为操作符</p><p><img src="/../img/Pytorch1/pytorch6/6.png" alt="6"></p><h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p>——指的是计算神经网络参数的方法，及根据求导的链式法则，按反顺序从输出层到输入层遍历网络</p><p>最终目的是计算：<strong>J对W的偏导</strong></p><p><img src="/../img/Pytorch1/pytorch6/7.png" alt="7"></p><h2 id="梯度消失和梯度爆炸"><a href="#梯度消失和梯度爆炸" class="headerlink" title="梯度消失和梯度爆炸"></a>梯度消失和梯度爆炸</h2><h3 id="梯度消失的原因及影响"><a href="#梯度消失的原因及影响" class="headerlink" title="梯度消失的原因及影响"></a>梯度消失的原因及影响</h3><p><strong>原因：</strong></p><ol><li><strong>网络层数过多</strong>：随着网络层数的增加，梯度在反向传播过程中会逐层乘以前面层的导数，导致梯度值逐渐变小。</li><li><strong>激活函数选择不当</strong>：例如使用sigmoid函数时，其导数在两端非常小（最大为0.25），导致梯度消失现象严重。</li></ol><p><strong>影响：</strong></p><ul><li>梯度消失会导致参数更新几乎不发生变化，使得网络难以收敛，学习效果差。</li><li>这种现象限制了模型的最大深度，使得许多理论上可能有效的深度模型在实际中无法实现。</li></ul><h3 id="梯度爆炸的原因及影响"><a href="#梯度爆炸的原因及影响" class="headerlink" title="梯度爆炸的原因及影响"></a>梯度爆炸的原因及影响</h3><p><strong>原因：</strong></p><ol><li><strong>网络层数过多</strong>：与梯度消失类似，随着网络层数的增加，梯度在反向传播过程中会逐层乘以前面层的导数，导致梯度值逐渐变大。</li><li><strong>学习率设置过高</strong>：如果学习率设置得过高，梯度更新的幅度也会相应增大，容易导致梯度爆炸。</li><li><strong>损失函数设计不合理</strong>：某些损失函数可能导致梯度值在反向传播过程中不断放大。</li></ol><p><strong>影响：</strong></p><ul><li>梯度爆炸会导致模型权重参数变化过大，使整个网络变得不稳定，甚至直接导致权重值溢出（NaN）。</li><li>这种现象会导致模型无法利用训练数据进行有效学习，训练过程中的梯度更新变得非常大，从而使得模型难以训练和收敛。</li></ul><h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>针对梯度消失和梯度爆炸的问题，有多种解决方案：</p><ol><li><strong>更换激活函数</strong>：使用ReLU、LeakyReLU、PReLU等非饱和激活函数，这些激活函数在正区间导数恒等于1，可以有效避免梯度消失问题，但需要注意防止梯度爆炸。</li><li><strong>权重初始化策略</strong>：采用He或Xavier初始化策略，可以更好地控制权重的初始范围，减少梯度爆炸的可能性。</li><li><strong>残差连接</strong>：通过引入残差连接，可以有效地缓解梯度消失和梯度爆炸的问题。</li><li><strong>批量归一化</strong>：在每一层之后添加批量归一化操作，可以稳定网络的训练过程，减少梯度消失和梯度爆炸的影响。</li><li><strong>梯度裁剪</strong>：在反向传播过程中对梯度值进行限制，防止其过大或过小。</li><li><strong>调整学习率</strong>：适当调整学习率，避免过大或过小的学习率导致梯度消失或梯度爆炸。</li></ol><p>通过以上方法，可以有效地缓解深度学习中梯度消失和梯度爆炸的问题，提高模型的训练效率和最终性能。</p><h4 id="如何选择最适合特定深度学习任务的激活函数以避免梯度消失？"><a href="#如何选择最适合特定深度学习任务的激活函数以避免梯度消失？" class="headerlink" title="如何选择最适合特定深度学习任务的激活函数以避免梯度消失？"></a>如何选择最适合特定深度学习任务的激活函数以避免梯度消失？</h4><p>选择最适合特定深度学习任务的激活函数以避免梯度消失问题，需要综合考虑数据特征、任务类型和模型复杂度等因素。以下是一些具体的建议和方法：</p><ol><li><strong>根据数据特征选择激活函数</strong>：<ul><li>对于二元或多元分类问题，可以使用sigmoid函数和tanh函数。</li><li>对于回归问题和一些分类问题，ReLU函数和Leaky ReLU函数更为适用。</li></ul></li><li><strong>尝试多种激活函数</strong>：<ul><li>在实践中，建议尝试不同的激活函数，并通过实验确定最适合特定任务的函数。</li><li>常见的激活函数包括ReLU、Leaky ReLU、ELU、Sigmoid、Tanh和Softmax等。</li></ul></li><li><strong>使用残差网络（ResNet）和LSTM结构</strong>：<ul><li>残差网络（ResNet）可以通过引入残差连接来缓解梯度消失问题。</li><li>LSTM（长短期记忆网络）也是一种有效的方法，特别适用于处理时间序列数据。</li></ul></li><li><strong>权重初始化和正则化技术</strong>：<ul><li>使用合适的权重初始化方法，如Xavier初始化或He初始化，可以减少梯度消失的风险。</li><li>应用梯度剪切和正则化技术也可以帮助控制梯度大小，防止梯度消失。</li></ul></li><li><strong>标准化处理</strong>：<ul><li>使用Batch Normalization（批量归一化）可以有效地减少内部协变量偏移，从而缓解梯度消失问题。</li></ul></li></ol><h3 id="批量归一化操作对深度学习模型训练过程的影响及其效果评估。"><a href="#批量归一化操作对深度学习模型训练过程的影响及其效果评估。" class="headerlink" title="批量归一化操作对深度学习模型训练过程的影响及其效果评估。"></a>批量归一化操作对深度学习模型训练过程的影响及其效果评估。</h3><p>批量归一化（Batch Normalization, BN）是深度学习中一种重要的优化技术，其主要目的是通过在每个批次中对神经网络中每个层次的每个神经元的输入进行归一化处理，使其遵循标准正态分布。这种方法可以有效改善模型的训练过程，提升模型性能和泛化能力。</p><p>批量归一化的核心思想是在训练过程中利用小批量的均值和方差调整神经网络中间输出，从而稳定层输入的分布，使深度神经网络的训练更加快速和稳定。具体来说，批量归一化通过对每一批训练数据进行统计分析，计算出均值和标准差，然后根据这些统计量对输入数据进行归一化处理。这样可以减少内部协方差（internal covariate shift, ICS），即前几层更新时引起的层输入分布的变化，从而简化了训练过程。</p><p>批量归一化还可以加速深层网络的收敛速度，使得模型参数的更新更加平滑，避免了靠近输出层输出的剧烈变化。此外，批量归一化还可以帮助设置更小的学习率和更严格的参数初始化，进一步提高模型的训练效果。</p><p>然而，尽管批量归一化在许多情况下表现出色，但在小批量大小下保证其有效性仍是一个挑战。未来的研究方向包括开发更加适应不同任务和场景的新一代归一化方法，以克服现有技术的局限性。</p><p>批量归一化对深度学习模型训练过程有显著的积极影响，能够提升模型性能和泛化能力，并加速收敛速度。</p><h3 id="梯度裁剪在防止深度学习模型梯度爆炸中的应用及其效果分析。"><a href="#梯度裁剪在防止深度学习模型梯度爆炸中的应用及其效果分析。" class="headerlink" title="梯度裁剪在防止深度学习模型梯度爆炸中的应用及其效果分析。"></a>梯度裁剪在防止深度学习模型梯度爆炸中的应用及其效果分析。</h3><p>梯度裁剪技术在防止深度学习模型梯度爆炸中的应用及其效果分析如下：</p><p>梯度裁剪（Gradient Clipping）是一种常用的优化技术，用于解决深度学习模型训练过程中常见的梯度爆炸问题。梯度爆炸是指在训练过程中，梯度的大小急剧增加，导致权重更新过大，从而阻碍模型训练。为了防止这种情况，梯度裁剪通过限制梯度的范围来控制梯度幅度，使其保持在一个合理的范围内。</p><p>梯度裁剪主要有两种方法：一种是按照梯度的绝对值进行裁剪，即如果梯度的绝对值超过了一个阈值，就将其设置为该阈值的符号乘以该阈值；另一种是按照梯度的范数进行裁剪。这两种方法都可以有效地防止梯度爆炸，但具体选择哪种方法取决于具体任务和模型需求。</p><p>在实际应用中，梯度裁剪可以显著提高模型的训练效果和稳定性。例如，在PyTorch中，可以通过<code>torch.nn.utils.clip _grad_norm_</code>方法来进行梯度裁剪操作，这有助于确保模型训练的稳定性和收敛性。此外，梯度裁剪还可以与其他优化技术结合使用，以进一步提升模型性能。</p>]]></content>
      
      
      
        <tags>
            
            <tag> machine-learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git详解</title>
      <link href="/2024/06/17/git%E8%AF%A6%E8%A7%A3/"/>
      <url>/2024/06/17/git%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="git详解"><a href="#git详解" class="headerlink" title="git详解"></a>git详解</h1><h2 id="基础配置"><a href="#基础配置" class="headerlink" title="基础配置"></a>基础配置</h2><p>a.首次使用添加身份说明，使用以下两个命令：</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name <span class="string">&quot;你的昵称&quot;</span>git config --global user.email 邮箱@example.com</span><br></pre></td></tr></table></figure><p>b.创建仓库</p><p>①在项目文件夹下使用git bash输入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git init</span><br></pre></td></tr></table></figure><p>②使用他人项目创建仓库</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> 项目url</span><br></pre></td></tr></table></figure><h2 id="状态与提交版本"><a href="#状态与提交版本" class="headerlink" title="状态与提交版本"></a><strong>状态与提交版本</strong></h2><p>创建完一个仓库后，会赋予这个仓库每一个文件或目录一个状态</p><p>如果是自己创建的，状态均为：未被跟踪</p><p>当生成一个版本后，未被跟踪的文件就不会在这个版本里</p><p>那么他之前的状态便无法追踪</p><p>现在我们可以单独地跟踪一个文件或目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git add &lt;name&gt;    //去跟踪一个文件或目录</span><br></pre></td></tr></table></figure><p>若一个文件被跟踪，则在这个仓库里会一直被跟踪</p><p>解除跟踪：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">rm</span> &lt;name&gt;    //解除跟踪</span><br></pre></td></tr></table></figure><p>或者：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">rm</span> --cache &lt;name&gt;    //解除跟踪且保留在目录中</span><br></pre></td></tr></table></figure><p>接下来就可以对跟踪的文件就行修改，修改完后，将它的状态设置为缓存状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git add &lt;file-name&gt;    </span><br></pre></td></tr></table></figure><p>取消缓存：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gir reset HEAD &lt;name&gt;</span><br></pre></td></tr></table></figure><p>提交:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit</span><br></pre></td></tr></table></figure><p>git commit 具体操作</p><p>①git commit 进入提交界面, </p><p>​    按” i “键进入输入模式后输入本次提交详情,</p><p>​    然后esc退出编辑模式, 按” : “进入命令栏, 输入”wq”保存并退出.</p><p>②git commit -m ‘ 你对提交内容的描述 ‘</p><p>③git commit -a</p><p>​    连带未暂存文件一起提交</p><p>​    git commit -am ‘提交描述’</p><p>④git reset head~ –soft</p><p>取消本次提交，使用该命令取消本次提交, 但是首次提交不可撤回</p><p>状态总结：</p><p><img src="/../img/git/1.png" alt="1"></p><p>查看文件状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git status</span><br></pre></td></tr></table></figure><ul><li>红色：已修改未暂存</li><li>绿色：暂存</li><li>提交后，则不显示</li></ul><p>查询文件具体修改的位置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git diff</span><br></pre></td></tr></table></figure><p>查看历史提交：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">log</span></span><br></pre></td></tr></table></figure><p>以一个图形化的方式呈现：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">log</span> --graph</span><br></pre></td></tr></table></figure><h2 id="远程仓库"><a href="#远程仓库" class="headerlink" title="远程仓库"></a>远程仓库</h2><p>连接远程仓库：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remove add (名字) 远程仓库url</span><br></pre></td></tr></table></figure><p>查看连接的远程仓库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote</span><br></pre></td></tr></table></figure><p>改名：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote rename 旧名 新名</span><br></pre></td></tr></table></figure><p>推送到远程仓库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git push 远程仓库名 master     //将本地代码中的master分支推送到远程仓库</span><br><span class="line">git push -u 远程仓库名 master      //使用-u命令推送一次，后续的推送即可简写为git push</span><br></pre></td></tr></table></figure><p>通过ssh鉴权：</p><p>进入到.ssh目录下，执行ssh-keygen生成密钥</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -b 4096 -C (邮箱)      //-t选择生成密钥的算法,-b选择生成的大小,-C添加评论(Github推荐评论为邮箱)</span><br></pre></td></tr></table></figure><p>后输入这对密钥的名字(eg.test)，在ssh目录下会自动生成test.pub(公钥)和test(私钥)</p><p>复制公钥，添加到Github</p><h2 id="分支"><a href="#分支" class="headerlink" title="分支"></a>分支</h2><p>每一个提交生成一个新版本的同时，其实会生成一个提交对象，每个提交对象都有一个独一无二的哈希值。</p><p><strong>分支就是一个包含这个哈希值的一个文件</strong>，可简单理解为指向一个提交对象的指针，所以我们可以在一个提交对象上新建多个分支。</p><p>在我们初始化本地仓库时，就已经创建了一个master分支,当每次进行一个提交的时候，分支也跟着提交对象而向前移动</p><h3 id="操作分支："><a href="#操作分支：" class="headerlink" title="操作分支："></a>操作分支：</h3><ol><li><p>查看分支：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">log</span>     //HEAD-&gt;当前所处分支</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git status  </span><br></pre></td></tr></table></figure></li><li><p>创建分支</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch (分支名)</span><br></pre></td></tr></table></figure></li><li><p>切换分支</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout (分支名)</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b (分支名)               //新建并切换到新分支</span><br></pre></td></tr></table></figure></li></ol><h2 id="分支合并"><a href="#分支合并" class="headerlink" title="分支合并"></a>分支合并</h2><h3 id="无冲突合并"><a href="#无冲突合并" class="headerlink" title="无冲突合并"></a>无冲突合并</h3><p>在合并至的分支使用</p><p>(master)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git merge (分支1)                   //当前所处master分支，合并了分支1上的修改</span><br></pre></td></tr></table></figure><h3 id="分支冲突-merge-conflict"><a href="#分支冲突-merge-conflict" class="headerlink" title="分支冲突 merge conflict"></a>分支冲突 merge conflict</h3><p>将 分支2 合并到 master分支 时, 与 分支1 冲突了. 原因是 分支1 和 分支2 修改了同一处内容</p><p>git status 查看哪里有冲突</p><p>vi 到冲突文件中, 选择一个分支的内容保留下来, 保存退出</p><p>git add 文件名</p><p>git commit -m ‘提交描述’</p><p>git log –all –graph 查看合并状态</p><h2 id="推拉与远程跟踪分支"><a href="#推拉与远程跟踪分支" class="headerlink" title="推拉与远程跟踪分支"></a><strong>推拉与远程跟踪分支</strong></h2><h3 id="推送"><a href="#推送" class="headerlink" title="推送"></a>推送</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push 仓库名 分支名</span><br></pre></td></tr></table></figure><p><strong>或者</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push -u 仓库名 分支名</span><br></pre></td></tr></table></figure><p>第一次使用 -u 指定推送目标后, 此后可直接使用git push</p><h3 id="拉取"><a href="#拉取" class="headerlink" title="拉取"></a>拉取</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git fetch           //拉取分支</span><br></pre></td></tr></table></figure><p>远程分支本地化：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout 远程分支</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b 本地分支名 远程分支</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout --track 远程分支</span><br></pre></td></tr></table></figure><h2 id="版本回退"><a href="#版本回退" class="headerlink" title="版本回退"></a>版本回退</h2><h3 id="1-reset"><a href="#1-reset" class="headerlink" title="1. reset"></a>1. reset</h3><p>此种方式不是很推荐，通过<code>reset</code>的方式，把<code>head</code>指针指向之前的某次提交，<code>reset</code>之后，后面的版本就找不到了。例如我们在开发种一共提交了四次分别是A、B、C、D，此时我们发现操作失误需要回退到B，则使用<code>reset</code>之后C、D就不再存在与时间线上了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard commit <span class="built_in">id</span></span><br></pre></td></tr></table></figure><h4 id="reset回退操作步骤："><a href="#reset回退操作步骤：" class="headerlink" title="reset回退操作步骤："></a><code>reset</code>回退操作步骤：</h4><ol><li><p>使用git log查找到所需要回退到的版本号，即提交记录的commit id；例如：576223db1ee100a79b4f82d6713cef700d723018；</p></li><li><p>在客户端执行如下命令（执行前，先将本地代码切换到对应分支）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard 576223db1ee100a79b4f82d6713cef700d723018`</span><br></pre></td></tr></table></figure></li><li><p>强制push到对应的远程分支<code>git push -f -u origin master</code>或者<code>git push -f</code>，此时如果用<code>git push</code>会报错，因为我们本地库HEAD指向的版本比远程库的要旧;</p></li></ol><p>此时，版本回退完成。</p><p>此方法不适用于多人共同创作一个项目的情景</p><h3 id="2-revert"><a href="#2-revert" class="headerlink" title="2. revert"></a>2. revert</h3><p>这种方式不会把版本往前回退，而是生成一个新的版本。所以，你只需要让别人更新一下代码就可以了，你之前操作的提交记录也会被保留下来。例如我们在开发种一共提交了四次分别是A、B、C、D，此时我们发现操作失误需要回退到B，则使用<code>revert</code>之后会生成一个E版本。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git revert -n commit id</span><br></pre></td></tr></table></figure><p>revert回退操作步骤：</p><ol><li><p>使用git log查找到所需要回退到的版本号，即提交记录的commit id；例如：a53a22f1e8b7ed0c7a9355e8563d234b5b99dd53；</p></li><li><p>在客户端执行如下命令git revert -n a53a22f1e8b7ed0c7a9355e8563d234b5b99dd53;</p></li><li><p>使用git commit -m ‘版本回退’进行提交；</p></li><li><p>git push同步推送到远程仓库即可；</p></li></ol><h2 id="恢复回退"><a href="#恢复回退" class="headerlink" title="恢复回退"></a>恢复回退</h2><p>若这个时候突然又发现不需要回退了，刚才那些消失的代码又要重新找回来了，则可以恢复回退</p><ol><li><p>我们可以通过<code>git reflog</code>查看本地的操作历史，找到对应的<code>commit id</code></p></li><li><p>然后再使用<code>git reset --hard commit id</code>就回到之前的操作了</p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> machine-learning </tag>
            
            <tag> Java </tag>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch5线性神经网络</title>
      <link href="/2024/06/13/Pytorch5%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2024/06/13/Pytorch5%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch-learning-notes5-–线性神经网络"><a href="#Pytorch-learning-notes5-–线性神经网络" class="headerlink" title="Pytorch learning notes5 –线性神经网络"></a>Pytorch learning notes5 –线性神经网络</h1><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p><em>回归</em>（regression）是能为一个或多个自变量与因变量之间关系建模的一类方法。 在自然科学和社会科学领域，回归经常用来表示输入和输出之间的关系。</p><p>在机器学习领域中的大多数任务通常都与<em>预测</em>（prediction）有关。</p><h3 id="线性回归的基本元素"><a href="#线性回归的基本元素" class="headerlink" title="线性回归的基本元素"></a>线性回归的基本元素</h3><p> 线性回归基于几个简单的假设： 首先，假设自变量𝑥和因变量𝑦之间的关系是线性的， 即𝑦可以表示为𝑥中元素的加权和，这里通常允许包含观测值的一些噪声； 其次，我们假设任何噪声都比较正常，如噪声遵循正态分布。</p><p>为了解释<em>线性回归</em>，我们举一个实际的例子： 我们希望根据房屋的面积（平方英尺）和房龄（年）来估算房屋价格（美元）。 为了开发一个能预测房价的模型，我们需要收集一个真实的数据集。 这个数据集包括了房屋的销售价格、面积和房龄。 在机器学习的术语中，该数据集称为<em>训练数据集</em>（training data set） 或<em>训练集</em>（training set）。 每行数据（比如一次房屋交易相对应的数据）称为<em>样本</em>（sample）， 也可以称为<em>数据点</em>（data point）或<em>数据样本</em>（data instance）。 我们把试图预测的目标（比如预测房屋价格）称为<em>标签</em>（label）或<em>目标</em>（target）。 预测所依据的自变量（面积和房龄）称为<em>特征</em>（feature）或<em>协变量</em>（covariate）。</p><p>通常，我们使用𝑛来表示数据集中的样本数。 对索引为𝑖的样本，其输入表示为𝑥(𝑖)&#x3D;[𝑥1(𝑖),𝑥2(𝑖)]⊤， 其对应的标签是𝑦(𝑖)。</p><h4 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h4><p>线性假设是指目标（房屋价格）可以表示为特征（面积和房龄）的加权和，如下面的式子：</p><p>(3.1.1)price&#x3D;𝑤area⋅area+𝑤age⋅age+𝑏.</p><p>其中的𝑤area和𝑤age 称为<em>权重</em>（weight），权重决定了每个特征对我们预测值的影响。 𝑏称为<em>偏置</em>（bias）、<em>偏移量</em>（offset）或<em>截距</em>（intercept）。 偏置是指当所有特征都取值为0时，预测值应该为多少。 即使现实中不会有任何房子的面积是0或房龄正好是0年，我们仍然需要偏置项。 如果没有偏置项，我们模型的表达能力将受到限制。 严格来说， <a href="https://zh-v2.d2l.ai/chapter_linear-networks/linear-regression.html#equation-eq-price-area">(3.1.1)</a>是输入特征的一个 <em>仿射变换</em>（affine transformation）。 仿射变换的特点是通过加权和对特征进行<em>线性变换</em>（linear transformation）， 并通过偏置项来进行<em>平移</em>（translation）。</p><p>给定一个数据集，我们的目标是寻找模型的权重𝑤和偏置𝑏， 使得根据模型做出的预测大体符合数据里的真实价格。 输出的预测值由输入特征通过<em>线性模型</em>的仿射变换决定，仿射变换由所选权重和偏置确定。</p><p>而在机器学习领域，我们通常使用的是高维数据集，建模时采用线性代数表示法会比较方便。 当我们的输入包含𝑑个特征时，我们将预测结果𝑦^ （通常使用“尖角”符号表示𝑦的估计值）表示为：</p><p>​                                                           𝑦^&#x3D;𝑤1𝑥1+…+𝑤𝑑𝑥𝑑+𝑏.</p><p>将所有特征放到向量𝑥∈𝑅𝑑中， 并将所有权重放到向量𝑤∈𝑅𝑑中， 我们可以用点积形式来简洁地表达模型：</p><p>​                                                           𝑦^&#x3D;𝑤⊤𝑥+𝑏.</p><p>在 <a href="https://zh-v2.d2l.ai/chapter_linear-networks/linear-regression.html#equation-eq-linreg-y">(3.1.3)</a>中， 向量𝑥对应于单个数据样本的特征。 用符号表示的矩阵𝑋∈𝑅𝑛×𝑑 可以很方便地引用我们整个数据集的𝑛个样本。 其中，𝑋的每一行是一个样本，每一列是一种特征。</p><p>对于特征集合𝑋，预测值𝑦^∈𝑅𝑛 可以通过矩阵-向量乘法表示为：</p><p>(3.1.4)𝑦^&#x3D;𝑋𝑤+𝑏</p><p>这个过程中的求和将使用广播机制。 给定训练数据特征𝑋和对应的已知标签𝑦， 线性回归的目标是找到一组权重向量𝑤和偏置𝑏： 当给定从𝑋的同分布中取样的新样本特征时， 这组权重向量和偏置能够使得新样本预测标签的误差尽可能小。</p><p>虽然我们相信给定𝑥预测𝑦的最佳模型会是线性的， 但我们很难找到一个有𝑛个样本的真实数据集，其中对于所有的1≤𝑖≤𝑛，𝑦(𝑖)完全等于𝑤⊤𝑥(𝑖)+𝑏。 无论我们使用什么手段来观察特征𝑋和标签𝑦， 都可能会出现少量的观测误差。 因此，即使确信特征与标签的潜在关系是线性的， 我们也会加入一个噪声项来考虑观测误差带来的影响。</p><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>在我们开始考虑如何用模型<em>拟合</em>（fit）数据之前，我们需要确定一个拟合程度的度量。 <em>损失函数</em>（loss function）能够量化目标的<em>实际</em>值与<em>预测</em>值之间的差距。 通常我们会选择非负数作为损失，且数值越小表示损失越小，完美预测时的损失为0。 回归问题中最常用的损失函数是平方误差函数。 当样本𝑖的预测值为𝑦^(𝑖)，其相应的真实标签为𝑦(𝑖)时， 平方误差可以定义为以下公式：</p><p>(3.1.5)𝑙(𝑖)(𝑤,𝑏)&#x3D;12(𝑦^(𝑖)−𝑦(𝑖))2.</p><p>常数12不会带来本质的差别，但这样在形式上稍微简单一些 （因为当我们对损失函数求导后常数系数为1）。 由于训练数据集并不受我们控制，所以经验误差只是关于模型参数的函数。 为了进一步说明，来看下面的例子。 我们为一维情况下的回归问题绘制图像，如图所示。</p><p><img src="/../img/Pytorch1/pytorch5/1.png" alt="1"></p><p><em>图3.1.1</em> 用线性模型拟合数据。</p><p>由于平方误差函数中的二次方项， 估计值𝑦^(𝑖)和观测值𝑦(𝑖)之间较大的差异将导致更大的损失。 为了度量模型在整个数据集上的质量，我们需计算在训练集𝑛个样本上的损失均值（也等价于求和）。</p><p>(3.1.6)𝐿(𝑤,𝑏)&#x3D;1𝑛∑𝑖&#x3D;1𝑛𝑙(𝑖)(𝑤,𝑏)&#x3D;1𝑛∑𝑖&#x3D;1𝑛12(𝑤⊤𝑥(𝑖)+𝑏−𝑦(𝑖))2.</p><p>在训练模型时，我们希望寻找一组参数（𝑤∗,𝑏∗）， 这组参数能最小化在所有训练样本上的总损失。如下式：</p><p>​            𝑤∗,𝑏∗&#x3D;argmin𝑤,𝑏 𝐿(𝑤,𝑏).</p><h4 id="解析解"><a href="#解析解" class="headerlink" title="解析解"></a>解析解</h4><p>线性回归刚好是一个很简单的优化问题。 与我们将在本书中所讲到的其他大部分模型不同，线性回归的解可以用一个公式简单地表达出来， 这类解叫作解析解（analytical solution）。 首先，我们将偏置𝑏合并到参数𝑤中，合并方法是在包含所有参数的矩阵中附加一列。 我们的预测问题是最小化‖𝑦−𝑋𝑤‖2。 这在损失平面上只有一个临界点，这个临界点对应于整个区域的损失极小点。 将损失关于𝑤的导数设为0，得到解析解：</p><p>   𝑤∗&#x3D;(𝑋⊤𝑋)−1𝑋⊤𝑦.</p><p>像线性回归这样的简单问题存在解析解，但并不是所有的问题都存在解析解。 解析解可以进行很好的数学分析，但解析解对问题的限制很严格，导致它无法广泛应用在深度学习里。</p><h4 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h4><p>即使在我们无法得到解析解的情况下，我们仍然可以有效地训练模型。 在许多任务上，那些难以优化的模型效果要更好。 因此，弄清楚如何训练这些难以优化的模型是非常重要的。</p><p>本书中我们用到一种名为<em>梯度下降</em>（gradient descent）的方法， 这种方法几乎可以优化所有深度学习模型。 它通过不断地在损失函数递减的方向上更新参数来降低误差。</p><p>梯度下降最简单的用法是计算损失函数（数据集中所有样本的损失均值） 关于模型参数的导数（在这里也可以称为梯度）。 但实际中的执行可能会非常慢：因为在每一次更新参数之前，我们必须遍历整个数据集。 因此，我们通常会在每次需要计算更新的时候随机抽取一小批样本， 这种变体叫做<em>小批量随机梯度下降</em>（minibatch stochastic gradient descent）。</p><p>在每次迭代中，我们首先随机抽样一个小批量𝐵， 它是由固定数量的训练样本组成的。 然后，我们计算小批量的平均损失关于模型参数的导数（也可以称为梯度）。 最后，我们将梯度乘以一个预先确定的正数𝜂，并从当前参数的值中减掉。</p><p>我们用下面的数学公式来表示这一更新过程（𝜕表示偏导数）：</p><p><img src="/../img/Pytorch1/pytorch5/2.png" alt="2"></p><p>公式 <a href="https://zh-v2.d2l.ai/chapter_linear-networks/linear-regression.html#equation-eq-linreg-batch-update">(3.1.10)</a>中的𝑤和𝑥都是向量。 在这里，更优雅的向量表示法比系数表示法（如𝑤1,𝑤2,…,𝑤𝑑）更具可读性。 |𝐵|表示每个小批量中的样本数，这也称为<em>批量大小</em>（batch size）。 𝜂表示<em>学习率</em>（learning rate）。 批量大小和学习率的值通常是手动预先指定，而不是通过模型训练得到的。 这些可以调整但不在训练过程中更新的参数称为<em>超参数</em>（hyperparameter）。 <em>调参</em>（hyperparameter tuning）是选择超参数的过程。 超参数通常是我们根据训练迭代结果来调整的， 而训练迭代结果是在独立的<em>验证数据集</em>（validation dataset）上评估得到的。</p><p>在训练了预先确定的若干迭代次数后（或者直到满足某些其他停止条件后）， 我们记录下模型参数的估计值，表示为𝑤^,𝑏^。 但是，即使我们的函数确实是线性的且无噪声，这些估计值也不会使损失函数真正地达到最小值。 因为算法会使得损失向最小值缓慢收敛，但却不能在有限的步数内非常精确地达到最小值。</p><p>线性回归恰好是一个在整个域中只有一个最小值的学习问题。 但是对像深度神经网络这样复杂的模型来说，损失平面上通常包含多个最小值。 深度学习实践者很少会去花费大力气寻找这样一组参数，使得在<em>训练集</em>上的损失达到最小。 事实上，更难做到的是找到一组参数，这组参数能够在我们从未见过的数据上实现较低的损失， 这一挑战被称为<em>泛化</em>（generalization）。</p><h4 id="用模型进行预测"><a href="#用模型进行预测" class="headerlink" title="用模型进行预测"></a>用模型进行预测</h4><p>给定“已学习”的线性回归模型𝑤^⊤𝑥+𝑏^， 现在我们可以通过房屋面积𝑥1和房龄𝑥2来估计一个（未包含在训练数据中的）新房屋价格。 给定特征估计目标的过程通常称为<em>预测</em>（prediction）或<em>推断</em>（inference）。</p><h3 id="矢量化加速"><a href="#矢量化加速" class="headerlink" title="矢量化加速"></a>矢量化加速</h3><p>在训练我们的模型时，我们经常希望能够同时处理整个小批量的样本。 为了实现这一点，需要我们对计算进行矢量化， 从而利用线性代数库，而不是在Python中编写开销高昂的for循环。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br></pre></td></tr></table></figure><p>为了说明矢量化为什么如此重要，我们考虑对向量相加的两种方法。 我们实例化两个全为1的10000维向量。 在一种方法中，我们将使用Python的for循环遍历向量； 在另一种方法中，我们将依赖对<code>+</code>的调用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">10000</span></span><br><span class="line">a = torch.ones([n])</span><br><span class="line">b = torch.ones([n])</span><br></pre></td></tr></table></figure><p>由于我们将频繁地进行运行时间的基准测试，所以我们定义一个计时器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Timer</span>:  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;记录多次运行时间&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.times = []</span><br><span class="line">        self.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">start</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;启动计时器&quot;&quot;&quot;</span></span><br><span class="line">        self.tik = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">stop</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;停止计时器并将时间记录在列表中&quot;&quot;&quot;</span></span><br><span class="line">        self.times.append(time.time() - self.tik)</span><br><span class="line">        <span class="keyword">return</span> self.times[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">avg</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;返回平均时间&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(self.times) / <span class="built_in">len</span>(self.times)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sum</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;返回时间总和&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(self.times)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cumsum</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;返回累计时间&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> np.array(self.times).cumsum().tolist()</span><br></pre></td></tr></table></figure><p>现在我们可以对工作负载进行基准测试。</p><p>首先，我们使用for循环，每次执行一位的加法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">c = torch.zeros(n)</span><br><span class="line">timer = Timer()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    c[i] = a[i] + b[i]</span><br><span class="line"><span class="string">f&#x27;<span class="subst">&#123;timer.stop():<span class="number">.5</span>f&#125;</span> sec&#x27;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;0.16749 sec&#x27;</span></span><br></pre></td></tr></table></figure><p>或者，我们使用重载的<code>+</code>运算符来计算按元素的和。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">timer.start()</span><br><span class="line">d = a + b</span><br><span class="line"><span class="string">f&#x27;<span class="subst">&#123;timer.stop():<span class="number">.5</span>f&#125;</span> sec&#x27;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;0.00042 sec&#x27;</span></span><br></pre></td></tr></table></figure><p>结果很明显，第二种方法比第一种方法快得多。 矢量化代码通常会带来数量级的加速。 另外，我们将更多的数学运算放到库中，而无须自己编写那么多的计算，从而减少了出错的可能性</p><h3 id="正态分布与平方损失"><a href="#正态分布与平方损失" class="headerlink" title="正态分布与平方损失"></a>正态分布与平方损失</h3><p>定义一个Python函数来计算正态分布</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">normal</span>(<span class="params">x, mu, sigma</span>):</span><br><span class="line">    p = <span class="number">1</span> / math.sqrt(<span class="number">2</span> * math.pi * sigma**<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> p * np.exp(-<span class="number">0.5</span> / sigma**<span class="number">2</span> * (x - mu)**<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>可视化正态分布。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 再次使用numpy进行可视化</span></span><br><span class="line">x = np.arange(-<span class="number">7</span>, <span class="number">7</span>, <span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 均值和标准差对</span></span><br><span class="line">params = [(<span class="number">0</span>, <span class="number">1</span>), (<span class="number">0</span>, <span class="number">2</span>), (<span class="number">3</span>, <span class="number">1</span>)]</span><br><span class="line">d2l.plot(x, [normal(x, mu, sigma) <span class="keyword">for</span> mu, sigma <span class="keyword">in</span> params], xlabel=<span class="string">&#x27;x&#x27;</span>,</span><br><span class="line">         ylabel=<span class="string">&#x27;p(x)&#x27;</span>, figsize=(<span class="number">4.5</span>, <span class="number">2.5</span>),</span><br><span class="line">         legend=[<span class="string">f&#x27;mean <span class="subst">&#123;mu&#125;</span>, std <span class="subst">&#123;sigma&#125;</span>&#x27;</span> <span class="keyword">for</span> mu, sigma <span class="keyword">in</span> params])</span><br></pre></td></tr></table></figure><p><img src="/../img/Pytorch1/pytorch5/3.png" alt="3"></p><h2 id="线性回归的从零开始实现"><a href="#线性回归的从零开始实现" class="headerlink" title="线性回归的从零开始实现"></a>线性回归的从零开始实现</h2><p>从零开始实现整个方法， 包括数据流水线、模型、损失函数和小批量随机梯度下降优化器。 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br></pre></td></tr></table></figure><p>根据带有噪声的线性模型构造一个人造数据集。 我们的任务是使用这个有限样本的数据集来恢复这个模型的参数。 我们将使用低维数据，这样可以很容易地将其可视化。 在下面的代码中，我们生成一个包含1000个样本的数据集， 每个样本包含从标准正态分布中采样的2个特征。 我们的合成数据集是一个矩阵𝑋∈𝑅1000×2。</p><p>我们使用线性模型参数<strong>𝑤&#x3D;[2,−3.4]⊤、𝑏&#x3D;4.2 和噪声项𝜖</strong>生成数据集及其标签：</p><p>(3.2.1)𝑦&#x3D;𝑋𝑤+𝑏+𝜖.</p><p>𝜖可以视为模型预测和标签时的潜在观测误差。 在这里我们认为标准假设成立，即𝜖服从均值为0的正态分布。 为了简化问题，我们将标准差设为0.01。 下面的代码生成合成数据集。</p><h3 id="生成数据集"><a href="#生成数据集" class="headerlink" title="生成数据集"></a>生成数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">synthetic_data</span>(<span class="params">w, b, num_examples</span>):  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;生成y=Xw+b+噪声&quot;&quot;&quot;</span></span><br><span class="line">    X = torch.normal(<span class="number">0</span>, <span class="number">1</span>, (num_examples, <span class="built_in">len</span>(w)))</span><br><span class="line">    y = torch.matmul(X, w) + b</span><br><span class="line">    y += torch.normal(<span class="number">0</span>, <span class="number">0.01</span>, y.shape)</span><br><span class="line">    <span class="keyword">return</span> X, y.reshape((-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">true_w = torch.tensor([<span class="number">2</span>, -<span class="number">3.4</span>])</span><br><span class="line">true_b = <span class="number">4.2</span></span><br><span class="line">features, labels = synthetic_data(true_w, true_b, <span class="number">1000</span>)</span><br></pre></td></tr></table></figure><p>注意，<code>features</code>中的每一行都包含一个二维数据样本， <code>labels</code>中的每一行都包含一维标签值（一个标量）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;features:&#x27;</span>, features[<span class="number">0</span>],<span class="string">&#x27;\nlabel:&#x27;</span>, labels[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">features: tensor([<span class="number">1.4632</span>, <span class="number">0.5511</span>])</span><br><span class="line">label: tensor([<span class="number">5.2498</span>])</span><br></pre></td></tr></table></figure><p>通过生成第二个特征<code>features[:, 1]</code>和<code>labels</code>的散点图， 可以直观观察到两者之间的线性关系。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">d2l.set_figsize()</span><br><span class="line">d2l.plt.scatter(features[:, (<span class="number">1</span>)].detach().numpy(), labels.detach().numpy(), <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p><img src="/../img/Pytorch1/pytorch5/4.png" alt="4"></p><h3 id="读取数据集"><a href="#读取数据集" class="headerlink" title="读取数据集"></a>读取数据集</h3><p>定义一个<code>data_iter</code>函数， 该函数接收批量大小、特征矩阵和标签向量作为输入，生成大小为<code>batch_size</code>的小批量。 每个小批量包含一组特征和标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">data_iter</span>(<span class="params">batch_size, features, labels</span>):</span><br><span class="line">    num_examples = <span class="built_in">len</span>(features)</span><br><span class="line">    indices = <span class="built_in">list</span>(<span class="built_in">range</span>(num_examples))</span><br><span class="line">    <span class="comment"># 这些样本是随机读取的，没有特定的顺序</span></span><br><span class="line">    random.shuffle(indices)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_examples, batch_size):</span><br><span class="line">        batch_indices = torch.tensor(</span><br><span class="line">            indices[i: <span class="built_in">min</span>(i + batch_size, num_examples)])</span><br><span class="line">        <span class="keyword">yield</span> features[batch_indices], labels[batch_indices]</span><br></pre></td></tr></table></figure><p>感受一下小批量运算：读取第一个小批量数据样本并打印。 每个批量的特征维度显示批量大小和输入特征数。 同样的，批量的标签形状与<code>batch_size</code>相等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter(batch_size, features, labels):</span><br><span class="line">    <span class="built_in">print</span>(X, <span class="string">&#x27;\n&#x27;</span>, y)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">0.3934</span>,  <span class="number">2.5705</span>],</span><br><span class="line">        [ <span class="number">0.5849</span>, -<span class="number">0.7124</span>],</span><br><span class="line">        [ <span class="number">0.1008</span>,  <span class="number">0.6947</span>],</span><br><span class="line">        [-<span class="number">0.4493</span>, -<span class="number">0.9037</span>],</span><br><span class="line">        [ <span class="number">2.3104</span>, -<span class="number">0.2798</span>],</span><br><span class="line">        [-<span class="number">0.0173</span>, -<span class="number">0.2552</span>],</span><br><span class="line">        [ <span class="number">0.1963</span>, -<span class="number">0.5445</span>],</span><br><span class="line">        [-<span class="number">1.0580</span>, -<span class="number">0.5180</span>],</span><br><span class="line">        [ <span class="number">0.8417</span>, -<span class="number">1.5547</span>],</span><br><span class="line">        [-<span class="number">0.6316</span>,  <span class="number">0.9732</span>]])</span><br><span class="line"> tensor([[-<span class="number">3.7623</span>],</span><br><span class="line">        [ <span class="number">7.7852</span>],</span><br><span class="line">        [ <span class="number">2.0443</span>],</span><br><span class="line">        [ <span class="number">6.3767</span>],</span><br><span class="line">        [ <span class="number">9.7776</span>],</span><br><span class="line">        [ <span class="number">5.0301</span>],</span><br><span class="line">        [ <span class="number">6.4541</span>],</span><br><span class="line">        [ <span class="number">3.8407</span>],</span><br><span class="line">        [<span class="number">11.1396</span>],</span><br><span class="line">        [-<span class="number">0.3836</span>]])</span><br></pre></td></tr></table></figure><h3 id="初始化模型参数"><a href="#初始化模型参数" class="headerlink" title="初始化模型参数"></a>初始化模型参数</h3><p>我们通过从均值为0、标准差为0.01的正态分布中采样随机数来初始化权重， 并将偏置初始化为0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">w = torch.normal(<span class="number">0</span>, <span class="number">0.01</span>, size=(<span class="number">2</span>,<span class="number">1</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.zeros(<span class="number">1</span>, requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>在初始化参数之后，我们的任务是更新这些参数，直到这些参数足够拟合我们的数据。 每次更新都需要计算损失函数关于模型参数的梯度。 有了这个梯度，我们就可以向减小损失的方向更新每个参数。 因为手动计算梯度很枯燥而且容易出错，所以没有人会手动计算梯度。 我们使用自动微分章节中引入的自动微分来计算梯度。</p><h3 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">linreg</span>(<span class="params">X, w, b</span>):  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;线性回归模型&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> torch.matmul(X, w) + b</span><br></pre></td></tr></table></figure><h3 id="定义损失函数"><a href="#定义损失函数" class="headerlink" title="定义损失函数"></a>定义损失函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">squared_loss</span>(<span class="params">y_hat, y</span>):  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;均方损失&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> (y_hat - y.reshape(y_hat.shape)) ** <span class="number">2</span> / <span class="number">2</span></span><br></pre></td></tr></table></figure><h3 id="定义优化算法"><a href="#定义优化算法" class="headerlink" title="定义优化算法"></a>定义优化算法</h3><p>在每一步中，使用从数据集中随机抽取的一个小批量，然后根据参数计算损失的梯度。 接下来，朝着减少损失的方向更新我们的参数。 下面的函数实现小批量随机梯度下降更新。 该函数接受模型参数集合、学习速率和批量大小作为输入。每 一步更新的大小由学习速率<code>lr</code>决定。 因为我们计算的损失是一个批量样本的总和，所以我们用批量大小（<code>batch_size</code>） 来规范化步长，这样步长大小就不会取决于我们对批量大小的选择。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sgd</span>(<span class="params">params, lr, batch_size</span>):  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;小批量随机梯度下降&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">            param -= lr * param.grad / batch_size</span><br><span class="line">            param.grad.zero_()</span><br></pre></td></tr></table></figure><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>在每次迭代中，我们读取一小批量训练样本，并通过我们的模型来获得一组预测。 计算完损失后，我们开始反向传播，存储每个参数的梯度。 最后，我们调用优化算法<code>sgd</code>来更新模型参数。</p><p>我们将执行以下循环：</p><p><img src="/../img/Pytorch1/pytorch5/5.png" alt="5"></p><p>在每个<em>迭代周期</em>（epoch）中，我们使用<code>data_iter</code>函数遍历整个数据集， 并将训练数据集中所有样本都使用一次（假设样本数能够被批量大小整除）。 这里的迭代周期个数<code>num_epochs</code>和学习率<code>lr</code>都是超参数，分别设为3和0.03。 设置超参数很棘手，需要通过反复试验进行调整。 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">lr = <span class="number">0.03</span></span><br><span class="line">num_epochs = <span class="number">3</span></span><br><span class="line">net = linreg</span><br><span class="line">loss = squared_loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter(batch_size, features, labels):</span><br><span class="line">        l = loss(net(X, w, b), y)  <span class="comment"># X和y的小批量损失</span></span><br><span class="line">        <span class="comment"># 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，</span></span><br><span class="line">        <span class="comment"># 并以此计算关于[w,b]的梯度</span></span><br><span class="line">        l.<span class="built_in">sum</span>().backward()</span><br><span class="line">        sgd([w, b], lr, batch_size)  <span class="comment"># 使用参数的梯度更新参数</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        train_l = loss(net(features, w, b), labels)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>, loss <span class="subst">&#123;<span class="built_in">float</span>(train_l.mean()):f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">epoch <span class="number">1</span>, loss <span class="number">0.042790</span></span><br><span class="line">epoch <span class="number">2</span>, loss <span class="number">0.000162</span></span><br><span class="line">epoch <span class="number">3</span>, loss <span class="number">0.000051</span></span><br></pre></td></tr></table></figure><p>计算误差</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;w的估计误差: <span class="subst">&#123;true_w - w.reshape(true_w.shape)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;b的估计误差: <span class="subst">&#123;true_b - b&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">w的估计误差: tensor([-<span class="number">1.3804e-04</span>,  <span class="number">5.7936e-05</span>], grad_fn=&lt;SubBackward0&gt;)</span><br><span class="line">b的估计误差: tensor([<span class="number">0.0006</span>], grad_fn=&lt;RsubBackward1&gt;)</span><br></pre></td></tr></table></figure><h2 id="线性回归的Pytorch实现"><a href="#线性回归的Pytorch实现" class="headerlink" title="线性回归的Pytorch实现"></a>线性回归的Pytorch实现</h2><h3 id="生成数据集-1"><a href="#生成数据集-1" class="headerlink" title="生成数据集"></a>生成数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">true_w = torch.tensor([<span class="number">2</span>, -<span class="number">3.4</span>])</span><br><span class="line">true_b = <span class="number">4.2</span></span><br><span class="line">features, labels = d2l.synthetic_data(true_w, true_b, <span class="number">1000</span>)</span><br></pre></td></tr></table></figure><h3 id="读取数据集-1"><a href="#读取数据集-1" class="headerlink" title="读取数据集"></a>读取数据集</h3><p>调用框架中现有的API来读取数据。 我们将<code>features</code>和<code>labels</code>作为API的参数传递，并通过数据迭代器指定<code>batch_size</code>。 此外，布尔值<code>is_train</code>表示是否希望数据迭代器对象在每个迭代周期内打乱数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_array</span>(<span class="params">data_arrays, batch_size, is_train=<span class="literal">True</span></span>):  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;构造一个PyTorch数据迭代器&quot;&quot;&quot;</span></span><br><span class="line">    dataset = data.TensorDataset(*data_arrays)</span><br><span class="line">    <span class="keyword">return</span> data.DataLoader(dataset, batch_size, shuffle=is_train)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line">data_iter = load_array((features, labels), batch_size)</span><br></pre></td></tr></table></figure><p>使用<code>data_iter</code>的方式与我们之前使用<code>data_iter</code>函数的方式相同。为了验证是否正常工作，让我们读取并打印第一个小批量样本。 与 之前不同，这里我们使用<code>iter</code>构造Python迭代器，并使用<code>next</code>从迭代器中获取第一项。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">next</span>(<span class="built_in">iter</span>(data_iter))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[tensor([[-<span class="number">1.3116</span>, -<span class="number">0.3062</span>],</span><br><span class="line">         [-<span class="number">1.5653</span>,  <span class="number">0.4830</span>],</span><br><span class="line">         [-<span class="number">0.8893</span>, -<span class="number">0.9466</span>],</span><br><span class="line">         [-<span class="number">1.2417</span>,  <span class="number">1.6891</span>],</span><br><span class="line">         [-<span class="number">0.7148</span>,  <span class="number">0.1376</span>],</span><br><span class="line">         [-<span class="number">0.2162</span>, -<span class="number">0.6122</span>],</span><br><span class="line">         [ <span class="number">2.4048</span>, -<span class="number">0.3211</span>],</span><br><span class="line">         [-<span class="number">0.1516</span>,  <span class="number">0.4997</span>],</span><br><span class="line">         [ <span class="number">1.5298</span>, -<span class="number">0.2291</span>],</span><br><span class="line">         [ <span class="number">1.3895</span>,  <span class="number">1.2602</span>]]),</span><br><span class="line"> tensor([[ <span class="number">2.6073</span>],</span><br><span class="line">         [-<span class="number">0.5787</span>],</span><br><span class="line">         [ <span class="number">5.6339</span>],</span><br><span class="line">         [-<span class="number">4.0211</span>],</span><br><span class="line">         [ <span class="number">2.3117</span>],</span><br><span class="line">         [ <span class="number">5.8492</span>],</span><br><span class="line">         [<span class="number">10.0926</span>],</span><br><span class="line">         [ <span class="number">2.1932</span>],</span><br><span class="line">         [ <span class="number">8.0441</span>],</span><br><span class="line">         [ <span class="number">2.6943</span>]])]</span><br></pre></td></tr></table></figure><h3 id="定义模型-1"><a href="#定义模型-1" class="headerlink" title="定义模型"></a>定义模型</h3><p>当我们在之前中实现线性回归时， 我们明确定义了模型参数变量，并编写了计算的代码，这样通过基本的线性代数运算得到输出。 但是，如果模型变得更加复杂，且当我们几乎每天都需要实现模型时，自然会想简化这个过程。 这种情况类似于为自己的博客从零开始编写网页。 做一两次是有益的，但如果每个新博客就需要工程师花一个月的时间重新开始编写网页，那并不高效。</p><p>对于标准深度学习模型，我们可以使用框架的预定义好的层。这使我们只需关注使用哪些层来构造模型，而不必关注层的实现细节。 我们首先定义一个模型变量<code>net</code>，它是一个<code>Sequential</code>类的实例。 <code>Sequential</code>类将多个层串联在一起。 当给定输入数据时，<code>Sequential</code>实例将数据传入到第一层， 然后将第一层的输出作为第二层的输入，以此类推。 在下面的例子中，我们的模型只包含一个层，因此实际上不需要<code>Sequential</code>。 但是由于以后几乎所有的模型都是多层的，在这里使用<code>Sequential</code>会让你熟悉“标准的流水线”。</p><p>回顾之前中的单层网络架构， 这一单层被称为<em>全连接层</em>（fully-connected layer）， 因为它的每一个输入都通过矩阵-向量乘法得到它的每个输出。</p><p>在PyTorch中，全连接层在<code>Linear</code>类中定义。 值得注意的是，我们将两个参数传递到<code>nn.Linear</code>中。 第一个指定输入特征形状，即2，第二个指定输出特征形状，输出特征形状为单个标量，因此为1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nn是神经网络的缩写</span></span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(nn.Linear(<span class="number">2</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure><h3 id="初始化模型参数-1"><a href="#初始化模型参数-1" class="headerlink" title="初始化模型参数"></a>初始化模型参数</h3><p>在使用<code>net</code>之前，我们需要初始化模型参数。 如在线性回归模型中的权重和偏置。 深度学习框架通常有预定义的方法来初始化参数。 在这里，我们指定每个权重参数应该从均值为0、标准差为0.01的正态分布中随机采样， 偏置参数将初始化为零。</p><p>正如我们在构造<code>nn.Linear</code>时指定输入和输出尺寸一样， 现在我们能直接访问参数以设定它们的初始值。 我们通过<code>net[0]</code>选择网络中的第一个图层， 然后使用<code>weight.data</code>和<code>bias.data</code>方法访问参数。 我们还可以使用替换方法<code>normal_</code>和<code>fill_</code>来重写参数值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net[<span class="number">0</span>].weight.data.normal_(<span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">net[<span class="number">0</span>].bias.data.fill_(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">0.</span>])</span><br></pre></td></tr></table></figure><h3 id="定义损失函数-1"><a href="#定义损失函数-1" class="headerlink" title="定义损失函数"></a>定义损失函数</h3><p>计算均方误差使用的是<code>MSELoss</code>类，也称为平方𝐿2范数。 默认情况下，它返回所有样本损失的平均值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.MSELoss()</span><br></pre></td></tr></table></figure><h3 id="定义优化算法-1"><a href="#定义优化算法-1" class="headerlink" title="定义优化算法"></a>定义优化算法</h3><p>小批量随机梯度下降算法是一种优化神经网络的标准工具， PyTorch在<code>optim</code>模块中实现了该算法的许多变种。 当我们实例化一个<code>SGD</code>实例时，我们要指定优化的参数 （可通过<code>net.parameters()</code>从我们的模型中获得）以及优化算法所需的超参数字典。 小批量随机梯度下降只需要设置<code>lr</code>值，这里设置为0.03。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.03</span>)</span><br></pre></td></tr></table></figure><p>通过深度学习框架的高级API来实现我们的模型只需要相对较少的代码。 我们不必单独分配参数、不必定义我们的损失函数，也不必手动实现小批量随机梯度下降。 当我们需要更复杂的模型时，高级API的优势将大大增加。 当我们有了所有的基本组件，训练过程代码与我们从零开始实现时所做的非常相似。</p><p>回顾一下：在每个迭代周期里，我们将完整遍历一次数据集（<code>train_data</code>）， 不停地从中获取一个小批量的输入和相应的标签。 对于每一个小批量，我们会进行以下步骤:</p><ul><li>通过调用<code>net(X)</code>生成预测并计算损失<code>l</code>（前向传播）。</li><li>通过进行反向传播来计算梯度。</li><li>通过调用优化器来更新模型参数。</li></ul><p>为了更好的衡量训练效果，我们计算每个迭代周期后的损失，并打印它来监控训练过程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        l = loss(net(X) ,y)</span><br><span class="line">        trainer.zero_grad()</span><br><span class="line">        l.backward()</span><br><span class="line">        trainer.step()</span><br><span class="line">    l = loss(net(features), labels)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>, loss <span class="subst">&#123;l:f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">epoch <span class="number">1</span>, loss <span class="number">0.000248</span></span><br><span class="line">epoch <span class="number">2</span>, loss <span class="number">0.000103</span></span><br><span class="line">epoch <span class="number">3</span>, loss <span class="number">0.000103</span></span><br></pre></td></tr></table></figure><p>比较生成数据集的真实参数和通过有限数据训练获得的模型参数。 要访问参数，我们首先从<code>net</code>访问所需的层，然后读取该层的权重和偏置。 正如在从零开始实现中一样，我们估计得到的参数与生成数据的真实参数非常接近。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">w = net[<span class="number">0</span>].weight.data</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w的估计误差：&#x27;</span>, true_w - w.reshape(true_w.shape))</span><br><span class="line">b = net[<span class="number">0</span>].bias.data</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b的估计误差：&#x27;</span>, true_b - b)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">w的估计误差： tensor([-<span class="number">0.0010</span>, -<span class="number">0.0003</span>])</span><br><span class="line">b的估计误差： tensor([-<span class="number">0.0003</span>])</span><br></pre></td></tr></table></figure><h2 id="softmax回归"><a href="#softmax回归" class="headerlink" title="softmax回归"></a>softmax回归</h2><p>softmax其实是个分类问题</p><p>回归可以用于预测<em>多少</em>的问题。 比如预测房屋被售出价格，或者棒球队可能获得的胜场数，又或者患者住院的天数。</p><h3 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h3><p>回归：估计一个连续值</p><p>分类：预测一个离散类别</p><p>从回归到多类分类—-均方损失</p><ul><li><p>对类别进行一位有效编码</p><p>y&#x3D;[y1,y2,…,yn]^T</p></li><li><p>使用均方损失进行训练</p></li><li><p>最大值为预测</p><p>y^&#x3D;argmax 0i</p></li></ul><h3 id="softmax运算"><a href="#softmax运算" class="headerlink" title="softmax运算"></a>softmax运算</h3><p>现在我们将优化参数以最大化观测数据的概率。 为了得到预测结果，我们将设置一个阈值，如选择具有最大概率的标签。</p><p>我们希望模型的输出𝑦^𝑗可以视为属于类𝑗的概率， 然后选择具有最大输出值的类别argmax𝑗𝑦𝑗作为我们的预测。 例如，如果𝑦^1、𝑦^2和𝑦^3分别为0.1、0.8和0.1， 那么我们预测的类别是2，在我们的例子中代表“鸡”。</p><p>然而我们能否将未规范化的预测𝑜直接视作我们感兴趣的输出呢？ 答案是否定的。 因为将线性层的输出直接视为概率时存在一些问题： 一方面，我们没有限制这些输出数字的总和为1。 另一方面，根据输入的不同，它们可以为负值。 这些违反了 <a href="https://zh-v2.d2l.ai/chapter_preliminaries/probability.html#sec-prob">2.6节</a>中所说的概率基本公理。</p><p>要将输出视为概率，我们必须保证在任何数据上的输出都是非负的且总和为1。 此外，我们需要一个训练的目标函数，来激励模型精准地估计概率。 例如， 在分类器输出0.5的所有样本中，我们希望这些样本是刚好有一半实际上属于预测的类别。 这个属性叫做<em>校准</em>（calibration）</p><p><img src="/../img/Pytorch1/pytorch5/6.png" alt="6"></p><p>这里，对于所有的𝑗总有0≤𝑦^𝑗≤1。 因此，𝑦^可以视为一个正确的概率分布。 softmax运算不会改变未规范化的预测𝑜之间的大小次序，只会确定分配给每个类别的概率。 因此，在预测过程中，我们仍然可以用下式来选择最有可能的类别。</p><p><img src="/../img/Pytorch1/pytorch5/7.png" alt="7"></p><p>尽管softmax是一个非线性函数，但softmax回归的输出仍然由输入特征的仿射变换决定。 因此，softmax回归是一个<em>线性模型</em>（linear model）</p><h2 id="图像分类数据集"><a href="#图像分类数据集" class="headerlink" title="图像分类数据集"></a>图像分类数据集</h2><p>MNIST数据集是图像分类中广泛使用的数据集之一，但作为基准数据集过于简单。 我们将使用类似但更复杂的Fashion-MNIST数据集 。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">d2l.use_svg_display()</span><br></pre></td></tr></table></figure><h3 id="读取数据集-2"><a href="#读取数据集-2" class="headerlink" title="读取数据集"></a>读取数据集</h3><p>我们可以通过框架中的内置函数将Fashion-MNIST数据集下载并读取到内存中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，</span></span><br><span class="line"><span class="comment"># 并除以255使得所有像素的数值均在0～1之间</span></span><br><span class="line">trans = transforms.ToTensor()</span><br><span class="line">mnist_train = torchvision.datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">&quot;../data&quot;</span>, train=<span class="literal">True</span>, transform=trans, download=<span class="literal">True</span>)</span><br><span class="line">mnist_test = torchvision.datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">&quot;../data&quot;</span>, train=<span class="literal">False</span>, transform=trans, download=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>Fashion-MNIST由10个类别的图像组成， 每个类别由<em>训练数据集</em>（train dataset）中的6000张图像 和<em>测试数据集</em>（test dataset）中的1000张图像组成。 因此，训练集和测试集分别包含60000和10000张图像。 测试数据集不会用于训练，只用于评估模型性能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(mnist_train), <span class="built_in">len</span>(mnist_test)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">60000</span>, <span class="number">10000</span>)</span><br></pre></td></tr></table></figure><p>Fashion-MNIST中包含的10个类别，分别为t-shirt（T恤）、trouser（裤子）、pullover（套衫）、dress（连衣裙）、coat（外套）、sandal（凉鞋）、shirt（衬衫）、sneaker（运动鞋）、bag（包）和ankle boot（短靴）。 以下函数用于在数字标签索引及其文本名称之间进行转换。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_fashion_mnist_labels</span>(<span class="params">labels</span>):  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;返回Fashion-MNIST数据集的文本标签&quot;&quot;&quot;</span></span><br><span class="line">    text_labels = [<span class="string">&#x27;t-shirt&#x27;</span>, <span class="string">&#x27;trouser&#x27;</span>, <span class="string">&#x27;pullover&#x27;</span>, <span class="string">&#x27;dress&#x27;</span>, <span class="string">&#x27;coat&#x27;</span>,</span><br><span class="line">                   <span class="string">&#x27;sandal&#x27;</span>, <span class="string">&#x27;shirt&#x27;</span>, <span class="string">&#x27;sneaker&#x27;</span>, <span class="string">&#x27;bag&#x27;</span>, <span class="string">&#x27;ankle boot&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> [text_labels[<span class="built_in">int</span>(i)] <span class="keyword">for</span> i <span class="keyword">in</span> labels]</span><br></pre></td></tr></table></figure><p>我们现在可以创建一个函数来可视化这些样本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">show_images</span>(<span class="params">imgs, num_rows, num_cols, titles=<span class="literal">None</span>, scale=<span class="number">1.5</span></span>):  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;绘制图像列表&quot;&quot;&quot;</span></span><br><span class="line">    figsize = (num_cols * scale, num_rows * scale)</span><br><span class="line">    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)</span><br><span class="line">    axes = axes.flatten()</span><br><span class="line">    <span class="keyword">for</span> i, (ax, img) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(axes, imgs)):</span><br><span class="line">        <span class="keyword">if</span> torch.is_tensor(img):</span><br><span class="line">            <span class="comment"># 图片张量</span></span><br><span class="line">            ax.imshow(img.numpy())</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># PIL图片</span></span><br><span class="line">            ax.imshow(img)</span><br><span class="line">        ax.axes.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">        ax.axes.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">if</span> titles:</span><br><span class="line">            ax.set_title(titles[i])</span><br><span class="line">    <span class="keyword">return</span> axes</span><br></pre></td></tr></table></figure><p>以下是训练数据集中前几个样本的图像及其相应的标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X, y = <span class="built_in">next</span>(<span class="built_in">iter</span>(data.DataLoader(mnist_train, batch_size=<span class="number">18</span>)))</span><br><span class="line">show_images(X.reshape(<span class="number">18</span>, <span class="number">28</span>, <span class="number">28</span>), <span class="number">2</span>, <span class="number">9</span>, titles=get_fashion_mnist_labels(y));</span><br></pre></td></tr></table></figure><p><img src="/../img/Pytorch1/pytorch5/8.png" alt="8"></p><h3 id="读取小批量"><a href="#读取小批量" class="headerlink" title="读取小批量"></a>读取小批量</h3><p>为了使我们在读取训练集和测试集时更容易，我们使用内置的数据迭代器，而不是从零开始创建。 回顾一下，在每次迭代中，数据加载器每次都会读取一小批量数据，大小为<code>batch_size</code>。 通过内置数据迭代器，我们可以随机打乱了所有样本，从而无偏见地读取小批量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">256</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_dataloader_workers</span>():  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;使用4个进程来读取数据&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">4</span></span><br><span class="line"></span><br><span class="line">train_iter = data.DataLoader(mnist_train, batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                             num_workers=get_dataloader_workers())</span><br></pre></td></tr></table></figure><p>看一下读取训练数据所需的时间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">timer = d2l.Timer()</span><br><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">    <span class="keyword">continue</span></span><br><span class="line"><span class="string">f&#x27;<span class="subst">&#123;timer.stop():<span class="number">.2</span>f&#125;</span> sec&#x27;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;3.37 sec&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="整合所有组件"><a href="#整合所有组件" class="headerlink" title="整合所有组件"></a>整合所有组件</h3><p>定义<code>load_data_fashion_mnist</code>函数，用于获取和读取Fashion-MNIST数据集。 这个函数返回训练集和验证集的数据迭代器。 此外，这个函数还接受一个可选参数<code>resize</code>，用来将图像大小调整为另一种形状。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_data_fashion_mnist</span>(<span class="params">batch_size, resize=<span class="literal">None</span></span>):  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;下载Fashion-MNIST数据集，然后将其加载到内存中&quot;&quot;&quot;</span></span><br><span class="line">    trans = [transforms.ToTensor()]</span><br><span class="line">    <span class="keyword">if</span> resize:</span><br><span class="line">        trans.insert(<span class="number">0</span>, transforms.Resize(resize))</span><br><span class="line">    trans = transforms.Compose(trans)</span><br><span class="line">    mnist_train = torchvision.datasets.FashionMNIST(</span><br><span class="line">        root=<span class="string">&quot;../data&quot;</span>, train=<span class="literal">True</span>, transform=trans, download=<span class="literal">True</span>)</span><br><span class="line">    mnist_test = torchvision.datasets.FashionMNIST(</span><br><span class="line">        root=<span class="string">&quot;../data&quot;</span>, train=<span class="literal">False</span>, transform=trans, download=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> (data.DataLoader(mnist_train, batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                            num_workers=get_dataloader_workers()),</span><br><span class="line">            data.DataLoader(mnist_test, batch_size, shuffle=<span class="literal">False</span>,</span><br><span class="line">                            num_workers=get_dataloader_workers()))</span><br></pre></td></tr></table></figure><p>下面，我们通过指定<code>resize</code>参数来测试<code>load_data_fashion_mnist</code>函数的图像大小调整功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_iter, test_iter = load_data_fashion_mnist(<span class="number">32</span>, resize=<span class="number">64</span>)</span><br><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">    <span class="built_in">print</span>(X.shape, X.dtype, y.shape, y.dtype)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([<span class="number">32</span>, <span class="number">1</span>, <span class="number">64</span>, <span class="number">64</span>]) torch.float32 torch.Size([<span class="number">32</span>]) torch.int64</span><br></pre></td></tr></table></figure><h2 id="softmax回归的从零开始实现"><a href="#softmax回归的从零开始实现" class="headerlink" title="softmax回归的从零开始实现"></a>softmax回归的从零开始实现</h2><p>使用刚刚在之前中引入的Fashion-MNIST数据集， 并设置数据迭代器的批量大小为256。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> IPython <span class="keyword">import</span> display</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br></pre></td></tr></table></figure><h3 id="初始化模型参数-2"><a href="#初始化模型参数-2" class="headerlink" title="初始化模型参数"></a>初始化模型参数</h3><p>和之前线性回归的例子一样，这里的每个样本都将用固定长度的向量表示。 原始数据集中的每个样本都是28×28的图像。 本节将展平每个图像，把它们看作长度为784的向量。 在后面的章节中，我们将讨论能够利用图像空间结构的特征， 但现在我们暂时只把每个像素位置看作一个特征。</p><p>回想一下，在softmax回归中，我们的输出与类别一样多。 因为我们的数据集有10个类别，所以网络输出维度为10。 因此，权重将构成一个784×10的矩阵， 偏置将构成一个1×10的行向量。 与线性回归一样，我们将使用正态分布初始化我们的权重<code>W</code>，偏置初始化为0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">num_inputs = <span class="number">784</span></span><br><span class="line">num_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">W = torch.normal(<span class="number">0</span>, <span class="number">0.01</span>, size=(num_inputs, num_outputs), requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.zeros(num_outputs, requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="定义softmax操作"><a href="#定义softmax操作" class="headerlink" title="定义softmax操作"></a>定义softmax操作</h3><p>在实现softmax回归模型之前，我们简要回顾一下<code>sum</code>运算符如何沿着张量中的特定维度工作。 如 <a href="https://zh-v2.d2l.ai/chapter_preliminaries/linear-algebra.html#subseq-lin-alg-reduction">2.3.6节</a>和 <a href="https://zh-v2.d2l.ai/chapter_preliminaries/linear-algebra.html#subseq-lin-alg-non-reduction">2.3.6.1节</a>所述， 给定一个矩阵<code>X</code>，我们可以对所有元素求和（默认情况下）。 也可以只求同一个轴上的元素，即同一列（轴0）或同一行（轴1）。 如果<code>X</code>是一个形状为<code>(2, 3)</code>的张量，我们对列进行求和， 则结果将是一个具有形状<code>(3,)</code>的向量。 当调用<code>sum</code>运算符时，我们可以指定保持在原始张量的轴数，而不折叠求和的维度。 这将产生一个具有形状<code>(1, 3)</code>的二维张量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = torch.tensor([[<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>], [<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>]])</span><br><span class="line">X.<span class="built_in">sum</span>(<span class="number">0</span>, keepdim=<span class="literal">True</span>), X.<span class="built_in">sum</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[<span class="number">5.</span>, <span class="number">7.</span>, <span class="number">9.</span>]]),</span><br><span class="line"> tensor([[ <span class="number">6.</span>],</span><br><span class="line">         [<span class="number">15.</span>]]))</span><br></pre></td></tr></table></figure><p>回想一下，实现softmax由三个步骤组成：</p><ol><li>对每个项求幂（使用<code>exp</code>）；</li><li>对每一行求和（小批量中每个样本是一行），得到每个样本的规范化常数；</li><li>将每一行除以其规范化常数，确保结果的和为1。</li></ol><p>回顾一下这个表达式</p><p><img src="/../img/Pytorch1/pytorch5/6.png" alt="6"></p><p>分母或规范化常数，有时也称为<em>配分函数</em>（其对数称为对数-配分函数）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">softmax</span>(<span class="params">X</span>):</span><br><span class="line">    X_exp = torch.exp(X)</span><br><span class="line">    partition = X_exp.<span class="built_in">sum</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> X_exp / partition  <span class="comment"># 这里应用了广播机制</span></span><br></pre></td></tr></table></figure><p>正如上述代码，对于任何随机输入，我们将每个元素变成一个非负数。 此外，依据概率原理，每行总和为1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X = torch.normal(<span class="number">0</span>, <span class="number">1</span>, (<span class="number">2</span>, <span class="number">5</span>))</span><br><span class="line">X_prob = softmax(X)</span><br><span class="line">X_prob, X_prob.<span class="built_in">sum</span>(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[<span class="number">0.1686</span>, <span class="number">0.4055</span>, <span class="number">0.0849</span>, <span class="number">0.1064</span>, <span class="number">0.2347</span>],</span><br><span class="line">         [<span class="number">0.0217</span>, <span class="number">0.2652</span>, <span class="number">0.6354</span>, <span class="number">0.0457</span>, <span class="number">0.0321</span>]]),</span><br><span class="line"> tensor([<span class="number">1.0000</span>, <span class="number">1.0000</span>]))</span><br></pre></td></tr></table></figure><h3 id="定义模型-2"><a href="#定义模型-2" class="headerlink" title="定义模型"></a>定义模型</h3><p>定义softmax操作后，我们可以实现softmax回归模型。 下面的代码定义了输入如何通过网络映射到输出。 注意，将数据传递到模型之前，我们使用<code>reshape</code>函数将每张原始图像展平为向量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">net</span>(<span class="params">X</span>):</span><br><span class="line">    <span class="keyword">return</span> softmax(torch.matmul(X.reshape((-<span class="number">1</span>, W.shape[<span class="number">0</span>])), W) + b)</span><br></pre></td></tr></table></figure><h3 id="定义损失函数-2"><a href="#定义损失函数-2" class="headerlink" title="定义损失函数"></a>定义损失函数</h3><p>下来，我们实现之前引入的交叉熵损失函数。 这可能是深度学习中最常见的损失函数，因为目前分类问题的数量远远超过回归问题的数量。</p><p>回顾一下，交叉熵采用真实标签的预测概率的负对数似然。 这里我们不使用Python的for循环迭代预测（这往往是低效的）， 而是通过一个运算符选择所有元素。 下面，我们创建一个数据样本<code>y_hat</code>，其中包含2个样本在3个类别的预测概率， 以及它们对应的标签<code>y</code>。 有了<code>y</code>，我们知道在第一个样本中，第一类是正确的预测； 而在第二个样本中，第三类是正确的预测。 然后使用<code>y</code>作为<code>y_hat</code>中概率的索引， 我们选择第一个样本中第一个类的概率和第二个样本中第三个类的概率。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y = torch.tensor([<span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line">y_hat = torch.tensor([[<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.6</span>], [<span class="number">0.3</span>, <span class="number">0.2</span>, <span class="number">0.5</span>]])</span><br><span class="line">y_hat[[<span class="number">0</span>, <span class="number">1</span>], y]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">0.1000</span>, <span class="number">0.5000</span>])</span><br></pre></td></tr></table></figure><p>现在我们只需一行代码就可以实现交叉熵损失函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">cross_entropy</span>(<span class="params">y_hat, y</span>):</span><br><span class="line">    <span class="keyword">return</span> - torch.log(y_hat[<span class="built_in">range</span>(<span class="built_in">len</span>(y_hat)), y])</span><br><span class="line"></span><br><span class="line">cross_entropy(y_hat, y)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">2.3026</span>, <span class="number">0.6931</span>])</span><br></pre></td></tr></table></figure><h3 id="分类精度"><a href="#分类精度" class="headerlink" title="分类精度"></a>分类精度</h3><p>给定预测概率分布<code>y_hat</code>，当我们必须输出硬预测（hard prediction）时， 我们通常选择预测概率最高的类。 许多应用都要求我们做出选择。如Gmail必须将电子邮件分类为“Primary（主要邮件）”、 “Social（社交邮件）”“Updates（更新邮件）”或“Forums（论坛邮件）”。 Gmail做分类时可能在内部估计概率，但最终它必须在类中选择一个。</p><p>当预测与标签分类<code>y</code>一致时，即是正确的。 分类精度即正确预测数量与总预测数量之比。 虽然直接优化精度可能很困难（因为精度的计算不可导）， 但精度通常是我们最关心的性能衡量标准，我们在训练分类器时几乎总会关注它。</p><p>为了计算精度，我们执行以下操作。 首先，如果<code>y_hat</code>是矩阵，那么假定第二个维度存储每个类的预测分数。 我们使用<code>argmax</code>获得每行中最大元素的索引来获得预测类别。 然后我们将预测类别与真实<code>y</code>元素进行比较。 由于等式运算符“<code>==</code>”对数据类型很敏感， 因此我们将<code>y_hat</code>的数据类型转换为与<code>y</code>的数据类型一致。 结果是一个包含0（错）和1（对）的张量。 最后，我们求和会得到正确预测的数量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">y_hat, y</span>):  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算预测正确的数量&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(y_hat.shape) &gt; <span class="number">1</span> <span class="keyword">and</span> y_hat.shape[<span class="number">1</span>] &gt; <span class="number">1</span>:</span><br><span class="line">        y_hat = y_hat.argmax(axis=<span class="number">1</span>)</span><br><span class="line">    cmp = y_hat.<span class="built_in">type</span>(y.dtype) == y</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">float</span>(cmp.<span class="built_in">type</span>(y.dtype).<span class="built_in">sum</span>())</span><br></pre></td></tr></table></figure><p>我们将继续使用之前定义的变量<code>y_hat</code>和<code>y</code>分别作为预测的概率分布和标签。 可以看到，第一个样本的预测类别是2（该行的最大元素为0.6，索引为2），这与实际标签0不一致。 第二个样本的预测类别是2（该行的最大元素为0.5，索引为2），这与实际标签2一致。 因此，这两个样本的分类精度率为0.5。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">accuracy(y_hat, y) / <span class="built_in">len</span>(y)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.5</span></span><br></pre></td></tr></table></figure><p>同样，对于任意数据迭代器<code>data_iter</code>可访问的数据集， 我们可以评估在任意模型<code>net</code>的精度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_accuracy</span>(<span class="params">net, data_iter</span>):  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算在指定数据集上模型的精度&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, torch.nn.Module):</span><br><span class="line">        net.<span class="built_in">eval</span>()  <span class="comment"># 将模型设置为评估模式</span></span><br><span class="line">    metric = Accumulator(<span class="number">2</span>)  <span class="comment"># 正确预测数、预测总数</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">            metric.add(accuracy(net(X), y), y.numel())</span><br><span class="line">    <span class="keyword">return</span> metric[<span class="number">0</span>] / metric[<span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>这里定义一个实用程序类<code>Accumulator</code>，用于对多个变量进行累加。 在上面的<code>evaluate_accuracy</code>函数中， 我们在<code>Accumulator</code>实例中创建了2个变量， 分别用于存储正确预测的数量和预测的总数量。 当我们遍历数据集时，两者都将随着时间的推移而累加。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Accumulator</span>:  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;在n个变量上累加&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n</span>):</span><br><span class="line">        self.data = [<span class="number">0.0</span>] * n</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">self, *args</span>):</span><br><span class="line">        self.data = [a + <span class="built_in">float</span>(b) <span class="keyword">for</span> a, b <span class="keyword">in</span> <span class="built_in">zip</span>(self.data, args)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset</span>(<span class="params">self</span>):</span><br><span class="line">        self.data = [<span class="number">0.0</span>] * <span class="built_in">len</span>(self.data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="keyword">return</span> self.data[idx]</span><br></pre></td></tr></table></figure><p>由于我们使用随机权重初始化<code>net</code>模型， 因此该模型的精度应接近于随机猜测。 例如在有10个类别情况下的精度为0.1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">evaluate_accuracy(net, test_iter)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.0625</span></span><br></pre></td></tr></table></figure><h3 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h3><p>在这里，我们重构训练过程的实现以使其可重复使用。 首先，我们定义一个函数来训练一个迭代周期。 请注意，<code>updater</code>是更新模型参数的常用函数，它接受批量大小作为参数。 它可以是<code>d2l.sgd</code>函数，也可以是框架的内置优化函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_epoch_ch3</span>(<span class="params">net, train_iter, loss, updater</span>):  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;训练模型一个迭代周期（定义见第3章）&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 将模型设置为训练模式</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, torch.nn.Module):</span><br><span class="line">        net.train()</span><br><span class="line">    <span class="comment"># 训练损失总和、训练准确度总和、样本数</span></span><br><span class="line">    metric = Accumulator(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">        <span class="comment"># 计算梯度并更新参数</span></span><br><span class="line">        y_hat = net(X)</span><br><span class="line">        l = loss(y_hat, y)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(updater, torch.optim.Optimizer):</span><br><span class="line">            <span class="comment"># 使用PyTorch内置的优化器和损失函数</span></span><br><span class="line">            updater.zero_grad()</span><br><span class="line">            l.mean().backward()</span><br><span class="line">            updater.step()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 使用定制的优化器和损失函数</span></span><br><span class="line">            l.<span class="built_in">sum</span>().backward()</span><br><span class="line">            updater(X.shape[<span class="number">0</span>])</span><br><span class="line">        metric.add(<span class="built_in">float</span>(l.<span class="built_in">sum</span>()), accuracy(y_hat, y), y.numel())</span><br><span class="line">    <span class="comment"># 返回训练损失和训练精度</span></span><br><span class="line">    <span class="keyword">return</span> metric[<span class="number">0</span>] / metric[<span class="number">2</span>], metric[<span class="number">1</span>] / metric[<span class="number">2</span>]</span><br></pre></td></tr></table></figure><p>在展示训练函数的实现之前，我们定义一个在动画中绘制数据的实用程序类<code>Animator</code>， 它能够简化本书其余部分的代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Animator</span>:  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;在动画中绘制数据&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, xlabel=<span class="literal">None</span>, ylabel=<span class="literal">None</span>, legend=<span class="literal">None</span>, xlim=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 ylim=<span class="literal">None</span>, xscale=<span class="string">&#x27;linear&#x27;</span>, yscale=<span class="string">&#x27;linear&#x27;</span>,</span></span><br><span class="line"><span class="params">                 fmts=(<span class="params"><span class="string">&#x27;-&#x27;</span>, <span class="string">&#x27;m--&#x27;</span>, <span class="string">&#x27;g-.&#x27;</span>, <span class="string">&#x27;r:&#x27;</span></span>), nrows=<span class="number">1</span>, ncols=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 figsize=(<span class="params"><span class="number">3.5</span>, <span class="number">2.5</span></span>)</span>):</span><br><span class="line">        <span class="comment"># 增量地绘制多条线</span></span><br><span class="line">        <span class="keyword">if</span> legend <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            legend = []</span><br><span class="line">        d2l.use_svg_display()</span><br><span class="line">        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)</span><br><span class="line">        <span class="keyword">if</span> nrows * ncols == <span class="number">1</span>:</span><br><span class="line">            self.axes = [self.axes, ]</span><br><span class="line">        <span class="comment"># 使用lambda函数捕获参数</span></span><br><span class="line">        self.config_axes = <span class="keyword">lambda</span>: d2l.set_axes(</span><br><span class="line">            self.axes[<span class="number">0</span>], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)</span><br><span class="line">        self.X, self.Y, self.fmts = <span class="literal">None</span>, <span class="literal">None</span>, fmts</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        <span class="comment"># 向图表中添加多个数据点</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">hasattr</span>(y, <span class="string">&quot;__len__&quot;</span>):</span><br><span class="line">            y = [y]</span><br><span class="line">        n = <span class="built_in">len</span>(y)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">hasattr</span>(x, <span class="string">&quot;__len__&quot;</span>):</span><br><span class="line">            x = [x] * n</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.X:</span><br><span class="line">            self.X = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.Y:</span><br><span class="line">            self.Y = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        <span class="keyword">for</span> i, (a, b) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(x, y)):</span><br><span class="line">            <span class="keyword">if</span> a <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> b <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                self.X[i].append(a)</span><br><span class="line">                self.Y[i].append(b)</span><br><span class="line">        self.axes[<span class="number">0</span>].cla()</span><br><span class="line">        <span class="keyword">for</span> x, y, fmt <span class="keyword">in</span> <span class="built_in">zip</span>(self.X, self.Y, self.fmts):</span><br><span class="line">            self.axes[<span class="number">0</span>].plot(x, y, fmt)</span><br><span class="line">        self.config_axes()</span><br><span class="line">        display.display(self.fig)</span><br><span class="line">        display.clear_output(wait=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>接下来我们实现一个训练函数， 它会在<code>train_iter</code>访问到的训练数据集上训练一个模型<code>net</code>。 该训练函数将会运行多个迭代周期（由<code>num_epochs</code>指定）。 在每个迭代周期结束时，利用<code>test_iter</code>访问到的测试数据集对模型进行评估。 我们将利用<code>Animator</code>类来可视化训练进度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_ch3</span>(<span class="params">net, train_iter, test_iter, loss, num_epochs, updater</span>):  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;训练模型（定义见第3章）&quot;&quot;&quot;</span></span><br><span class="line">    animator = Animator(xlabel=<span class="string">&#x27;epoch&#x27;</span>, xlim=[<span class="number">1</span>, num_epochs], ylim=[<span class="number">0.3</span>, <span class="number">0.9</span>],</span><br><span class="line">                        legend=[<span class="string">&#x27;train loss&#x27;</span>, <span class="string">&#x27;train acc&#x27;</span>, <span class="string">&#x27;test acc&#x27;</span>])</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)</span><br><span class="line">        test_acc = evaluate_accuracy(net, test_iter)</span><br><span class="line">        animator.add(epoch + <span class="number">1</span>, train_metrics + (test_acc,))</span><br><span class="line">    train_loss, train_acc = train_metrics</span><br><span class="line">    <span class="keyword">assert</span> train_loss &lt; <span class="number">0.5</span>, train_loss</span><br><span class="line">    <span class="keyword">assert</span> train_acc &lt;= <span class="number">1</span> <span class="keyword">and</span> train_acc &gt; <span class="number">0.7</span>, train_acc</span><br><span class="line">    <span class="keyword">assert</span> test_acc &lt;= <span class="number">1</span> <span class="keyword">and</span> test_acc &gt; <span class="number">0.7</span>, test_acc</span><br></pre></td></tr></table></figure><p>作为一个从零开始的实现，我们使用之前定义的 小批量随机梯度下降来优化模型的损失函数，设置学习率为0.1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lr = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">updater</span>(<span class="params">batch_size</span>):</span><br><span class="line">    <span class="keyword">return</span> d2l.sgd([W, b], lr, batch_size)</span><br></pre></td></tr></table></figure><p>现在，我们训练模型10个迭代周期。 请注意，迭代周期（<code>num_epochs</code>）和学习率（<code>lr</code>）都是可调节的超参数。 通过更改它们的值，我们可以提高模型的分类精度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">10</span></span><br><span class="line">train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)</span><br></pre></td></tr></table></figure><p><img src="/../img/Pytorch1/pytorch5/9.png" alt="9"></p><h3 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h3><p>现在训练已经完成，我们的模型已经准备好对图像进行分类预测。 给定一系列图像，我们将比较它们的实际标签（文本输出的第一行）和模型预测（文本输出的第二行）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict_ch3</span>(<span class="params">net, test_iter, n=<span class="number">6</span></span>):  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;预测标签（定义见第3章）&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> test_iter:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    trues = d2l.get_fashion_mnist_labels(y)</span><br><span class="line">    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="number">1</span>))</span><br><span class="line">    titles = [true +<span class="string">&#x27;\n&#x27;</span> + pred <span class="keyword">for</span> true, pred <span class="keyword">in</span> <span class="built_in">zip</span>(trues, preds)]</span><br><span class="line">    d2l.show_images(</span><br><span class="line">        X[<span class="number">0</span>:n].reshape((n, <span class="number">28</span>, <span class="number">28</span>)), <span class="number">1</span>, n, titles=titles[<span class="number">0</span>:n])</span><br><span class="line"></span><br><span class="line">predict_ch3(net, test_iter)</span><br></pre></td></tr></table></figure><p><img src="/../img/Pytorch1/pytorch5/10.png" alt="10"></p><h2 id="softmax的Pytorch实现"><a href="#softmax的Pytorch实现" class="headerlink" title="softmax的Pytorch实现"></a>softmax的Pytorch实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> gluon, init, npx</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> mxnet <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">npx.set_np()</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[07:03:<span class="number">36</span>] ../src/storage/storage.cc:<span class="number">196</span>: Using Pooled (Naive) StorageManager <span class="keyword">for</span> CPU</span><br></pre></td></tr></table></figure><h3 id="初始化模型参数-3"><a href="#初始化模型参数-3" class="headerlink" title="初始化模型参数"></a>初始化模型参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential()</span><br><span class="line">net.add(nn.Dense(<span class="number">10</span>))</span><br><span class="line">net.initialize(init.Normal(sigma=<span class="number">0.01</span>))</span><br></pre></td></tr></table></figure><h3 id="定义损失函数-3"><a href="#定义损失函数-3" class="headerlink" title="定义损失函数"></a>定义损失函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = gluon.loss.SoftmaxCrossEntropyLoss()</span><br></pre></td></tr></table></figure><h3 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h3><p>在这里，我们使用学习率为0.1的小批量随机梯度下降作为优化算法。 这与我们在线性回归例子中的相同，这说明了优化器的普适性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer = gluon.Trainer(net.collect_params(), <span class="string">&#x27;sgd&#x27;</span>, &#123;<span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.1</span>&#125;)</span><br></pre></td></tr></table></figure><h3 id="训练-2"><a href="#训练-2" class="headerlink" title="训练"></a>训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">10</span></span><br><span class="line">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</span><br></pre></td></tr></table></figure><p><img src="/../img/Pytorch1/pytorch5/11.png" alt="11"></p><p>————————————————-来自李沐大神的学习笔记</p>]]></content>
      
      
      
        <tags>
            
            <tag> machine-learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch4文档查阅</title>
      <link href="/2024/06/12/Pytorch4%E6%96%87%E6%A1%A3%E6%9F%A5%E9%98%85/"/>
      <url>/2024/06/12/Pytorch4%E6%96%87%E6%A1%A3%E6%9F%A5%E9%98%85/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch-learning-notes4-–文档查阅"><a href="#Pytorch-learning-notes4-–文档查阅" class="headerlink" title="Pytorch learning notes4 –文档查阅"></a>Pytorch learning notes4 –文档查阅</h1><p>——–提供了一些查看PyTorch API的指导。</p><h2 id="查找模块中的所有函数和类"><a href="#查找模块中的所有函数和类" class="headerlink" title="查找模块中的所有函数和类"></a>查找模块中的所有函数和类</h2><p>为了知道模块中可以调用哪些函数和类，可以调用<code>dir</code>函数。 例如，我们可以查询随机数生成模块中的所有属性：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">dir</span>(torch.distributions))</span><br></pre></td></tr></table></figure><p>通常可以忽略以“<code>__</code>”（双下划线）开始和结束的函数，它们是Python中的特殊对象， 或以单个“<code>_</code>”（单下划线）开始的函数，它们通常是内部函数。 根据剩余的函数名或属性名，我们可能会猜测这个模块提供了各种生成随机数的方法， 包括从均匀分布（<code>uniform</code>）、正态分布（<code>normal</code>）和多项分布（<code>multinomial</code>）中采样。</p><h2 id="查找特定函数和类的用法"><a href="#查找特定函数和类的用法" class="headerlink" title="查找特定函数和类的用法"></a>查找特定函数和类的用法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">help</span>(torch.ones)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">Help on built-<span class="keyword">in</span> function ones <span class="keyword">in</span> module torch:</span><br><span class="line"></span><br><span class="line">ones(...)</span><br><span class="line">    ones(*size, *, out=<span class="literal">None</span>, dtype=<span class="literal">None</span>, layout=torch.strided, device=<span class="literal">None</span>, requires_grad=<span class="literal">False</span>) -&gt; Tensor</span><br><span class="line"></span><br><span class="line">    Returns a tensor filled <span class="keyword">with</span> the scalar value <span class="number">1</span>, <span class="keyword">with</span> the shape defined</span><br><span class="line">    by the variable argument size.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        size (<span class="built_in">int</span>...): a sequence of integers defining the shape of the output tensor.</span><br><span class="line">            Can be a variable number of arguments <span class="keyword">or</span> a collection like a <span class="built_in">list</span> <span class="keyword">or</span> <span class="built_in">tuple</span>.</span><br><span class="line"></span><br><span class="line">    Keyword arguments:</span><br><span class="line">        out (Tensor, optional): the output tensor.</span><br><span class="line">        dtype (torch.dtype, optional): the desired data <span class="built_in">type</span> of returned tensor.</span><br><span class="line">            Default: <span class="keyword">if</span> <span class="literal">None</span>, uses a <span class="keyword">global</span> default (see torch.set_default_tensor_type()).</span><br><span class="line">        layout (torch.layout, optional): the desired layout of returned Tensor.</span><br><span class="line">            Default: torch.strided.</span><br><span class="line">        device (torch.device, optional): the desired device of returned tensor.</span><br><span class="line">            Default: <span class="keyword">if</span> <span class="literal">None</span>, uses the current device <span class="keyword">for</span> the default tensor <span class="built_in">type</span></span><br><span class="line">            (see torch.set_default_tensor_type()). device will be the CPU</span><br><span class="line">            <span class="keyword">for</span> CPU tensor types <span class="keyword">and</span> the current CUDA device <span class="keyword">for</span> CUDA tensor types.</span><br><span class="line">        requires_grad (<span class="built_in">bool</span>, optional): If autograd should record operations on the</span><br><span class="line">            returned tensor. Default: <span class="literal">False</span>.</span><br><span class="line"></span><br><span class="line">    Example::</span><br><span class="line"></span><br><span class="line">        &gt;&gt;&gt; torch.ones(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">        tensor([[ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">                [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>]])</span><br><span class="line"></span><br><span class="line">        &gt;&gt;&gt; torch.ones(<span class="number">5</span>)</span><br><span class="line">        tensor([ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>])</span><br></pre></td></tr></table></figure><p>从文档中，我们可以看到<code>ones</code>函数创建一个具有指定形状的新张量，并将所有元素值设置为1。 下面来运行一个快速测试来确认这一解释：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.ones(<span class="number">4</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])</span><br></pre></td></tr></table></figure><p>在Jupyter记事本中，我们可以使用<code>?</code>指令在另一个浏览器窗口中显示文档。 例如，<code>list?</code>指令将创建与<code>help(list)</code>指令几乎相同的内容，并在新的浏览器窗口中显示它。 此外，如果我们使用两个问号，如<code>list??</code>，将显示实现该函数的Python代码。</p>]]></content>
      
      
      
        <tags>
            
            <tag> machine-learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch3自动微分</title>
      <link href="/2024/06/11/Pytorch3%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86/"/>
      <url>/2024/06/11/Pytorch3%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch-learning-notes3-–自动微分"><a href="#Pytorch-learning-notes3-–自动微分" class="headerlink" title="Pytorch learning notes3 –自动微分"></a>Pytorch learning notes3 –自动微分</h1><p>求导是几乎所有深度学习优化算法的关键步骤。 虽然求导的计算很简单，只需要一些基本的微积分。 但对于复杂的模型，手工进行更新是一件很痛苦的事情（而且经常容易出错）。</p><p>深度学习框架通过自动计算导数，即<em>自动微分</em>（automatic differentiation）来加快求导。 实际中，根据设计好的模型，系统会构建一个<em>计算图</em>（computational graph）， 来跟踪计算是哪些数据通过哪些操作组合起来产生输出。 自动微分使系统能够随后反向传播梯度。 这里，<em>反向传播</em>（backpropagate）意味着跟踪整个计算图，填充关于每个参数的偏导数。</p><h2 id="A-simple-example"><a href="#A-simple-example" class="headerlink" title="A simple example"></a>A simple example</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.arange(<span class="number">4.0</span>)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">0.</span>, <span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>])</span><br></pre></td></tr></table></figure><p>在我们计算𝑦关于𝑥的梯度之前，需要一个地方来存储梯度。 重要的是，我们不会在每次对一个参数求导时都分配新的内存。 因为我们经常会成千上万次地更新相同的参数，每次都分配新的内存可能很快就会将内存耗尽。 注意，一个标量函数关于向量𝑥的梯度是向量，并且与𝑥具有相同的形状。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x.requires_grad_(<span class="literal">True</span>)  <span class="comment"># 等价于x=torch.arange(4.0,requires_grad=True)</span></span><br><span class="line">x.grad  <span class="comment"># 默认值是None</span></span><br></pre></td></tr></table></figure><p>现在计算𝑦。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = <span class="number">2</span> * torch.dot(x, x)</span><br><span class="line">y</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([ <span class="number">0.</span>,  <span class="number">4.</span>,  <span class="number">8.</span>, <span class="number">12.</span>])</span><br></pre></td></tr></table></figure><p>函数𝑦&#x3D;2𝑥⊤𝑥关于𝑥的梯度应为4𝑥。 让我们快速验证这个梯度是否计算正确。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.grad == <span class="number">4</span> * x</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>])</span><br></pre></td></tr></table></figure><p>现在计算<code>x</code>的另一个函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值</span></span><br><span class="line">x.grad.zero_()</span><br><span class="line">y = x.<span class="built_in">sum</span>()</span><br><span class="line">y.backward()</span><br><span class="line">x.grad</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])</span><br></pre></td></tr></table></figure><h2 id="非标量变量的反向传播"><a href="#非标量变量的反向传播" class="headerlink" title="非标量变量的反向传播"></a>非标量变量的反向传播</h2><p>当<code>y</code>不是标量时，向量<code>y</code>关于向量<code>x</code>的导数的最自然解释是一个矩阵。 对于高阶和高维的<code>y</code>和<code>x</code>，求导的结果可以是一个高阶张量。</p><p>然而，虽然这些更奇特的对象确实出现在高级机器学习中（包括深度学习中）， 但当调用向量的反向计算时，我们通常会试图计算一批训练样本中每个组成部分的损失函数的导数。 这里，我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。</span></span><br><span class="line"><span class="comment"># 本例只想求偏导数的和，所以传递一个1的梯度是合适的</span></span><br><span class="line">x.grad.zero_()</span><br><span class="line">y = x * x</span><br><span class="line"><span class="comment"># 等价于y.backward(torch.ones(len(x)))</span></span><br><span class="line">y.<span class="built_in">sum</span>().backward()</span><br><span class="line">x.grad</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">0.</span>, <span class="number">2.</span>, <span class="number">4.</span>, <span class="number">6.</span>])</span><br></pre></td></tr></table></figure><h2 id="分离计算"><a href="#分离计算" class="headerlink" title="分离计算"></a>分离计算</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x.grad.zero_()</span><br><span class="line">y = x * x</span><br><span class="line">u = y.detach()</span><br><span class="line">z = u * x</span><br><span class="line"></span><br><span class="line">z.<span class="built_in">sum</span>().backward()</span><br><span class="line">x.grad == u</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>])</span><br></pre></td></tr></table></figure><p>由于记录了<code>y</code>的计算结果，我们可以随后在<code>y</code>上调用反向传播， 得到<code>y=x*x</code>关于的<code>x</code>的导数，即<code>2*x</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x.grad.zero_()</span><br><span class="line">y.<span class="built_in">sum</span>().backward()</span><br><span class="line">x.grad == <span class="number">2</span> * x</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>])</span><br></pre></td></tr></table></figure><h2 id="Python控制流的梯度计算"><a href="#Python控制流的梯度计算" class="headerlink" title="Python控制流的梯度计算"></a>Python控制流的梯度计算</h2><p>使用自动微分的一个好处是： 即使构建函数的计算图需要通过Python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度。 在下面的代码中，<code>while</code>循环的迭代次数和<code>if</code>语句的结果都取决于输入<code>a</code>的值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">a</span>):</span><br><span class="line">    b = a * <span class="number">2</span></span><br><span class="line">    <span class="keyword">while</span> b.norm() &lt; <span class="number">1000</span>:</span><br><span class="line">        b = b * <span class="number">2</span></span><br><span class="line">    <span class="keyword">if</span> b.<span class="built_in">sum</span>() &gt; <span class="number">0</span>:</span><br><span class="line">        c = b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        c = <span class="number">100</span> * b</span><br><span class="line">    <span class="keyword">return</span> c</span><br></pre></td></tr></table></figure><p>让我们计算梯度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(size=(), requires_grad=<span class="literal">True</span>)</span><br><span class="line">d = f(a)</span><br><span class="line">d.backward()</span><br></pre></td></tr></table></figure><p>我们现在可以分析上面定义的<code>f</code>函数。 请注意，它在其输入<code>a</code>中是分段线性的。 换言之，对于任何<code>a</code>，存在某个常量标量<code>k</code>，使得<code>f(a)=k*a</code>，其中<code>k</code>的值取决于输入<code>a</code>，因此可以用<code>d/a</code>验证梯度是否正确。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a.grad == d / a</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><hr><p>——摘至李沐大神教学文档</p>]]></content>
      
      
      
        <tags>
            
            <tag> machine-learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch2微积分实现</title>
      <link href="/2024/06/11/Pytorch2%E5%BE%AE%E7%A7%AF%E5%88%86%E5%AE%9E%E7%8E%B0/"/>
      <url>/2024/06/11/Pytorch2%E5%BE%AE%E7%A7%AF%E5%88%86%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch-learning-notes2-–微积分实现"><a href="#Pytorch-learning-notes2-–微积分实现" class="headerlink" title="Pytorch learning notes2 –微积分实现"></a>Pytorch learning notes2 –微积分实现</h1><p>为了更好地在python中实现导数，让我们做一个实验。 定义𝑢&#x3D;𝑓(𝑥)&#x3D;3𝑥2−4𝑥如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline           <span class="comment"># Jupyter中使用的魔法命令（Magic Command）。在单元格内直接显示 Matplotlib 生成的图形</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">3</span> * x ** <span class="number">2</span> - <span class="number">4</span> * x</span><br></pre></td></tr></table></figure><p>通过令𝑥&#x3D;1并让ℎ接近0，[𝑓(𝑥+ℎ)−𝑓(𝑥)]&#x2F;ℎ的数值结果接近2。 虽然这个实验不是一个数学证明，但稍后会看到，当𝑥&#x3D;1时，导数𝑢′是2。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">numerical_lim</span>(<span class="params">f, x, h</span>):</span><br><span class="line">    <span class="keyword">return</span> (f(x + h) - f(x)) / h</span><br><span class="line"></span><br><span class="line">h = <span class="number">0.1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;h=<span class="subst">&#123;h:<span class="number">.5</span>f&#125;</span>, numerical limit=<span class="subst">&#123;numerical_lim(f, <span class="number">1</span>, h):<span class="number">.5</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">    h *= <span class="number">0.1</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">h=<span class="number">0.10000</span>, numerical limit=<span class="number">2.30000</span></span><br><span class="line">h=<span class="number">0.01000</span>, numerical limit=<span class="number">2.03000</span></span><br><span class="line">h=<span class="number">0.00100</span>, numerical limit=<span class="number">2.00300</span></span><br><span class="line">h=<span class="number">0.00010</span>, numerical limit=<span class="number">2.00030</span></span><br><span class="line">h=<span class="number">0.00001</span>, numerical limit=<span class="number">2.00003</span></span><br></pre></td></tr></table></figure><p>为了对导数的这种解释进行可视化，我们将使用<code>**matplotlib**</code>， 一个Python中流行的绘图库。 要配置<code>matplotlib</code>生成图形的属性，我们需要定义几个函数。 在下面，<code>use_svg_display</code>函数指定<code>matplotlib</code>软件包输出svg图表以获得更清晰的图像。</p><p>注释<code>#@save</code>是一个特殊的标记，会将对应的函数、类或语句保存在<code>d2l</code>包中。 因此，以后无须重新定义就可以直接调用它们（例如，<code>d2l.use_svg_display()</code>）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">use_svg_display</span>():  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;使用svg格式在Jupyter中显示绘图&quot;&quot;&quot;</span></span><br><span class="line">    backend_inline.set_matplotlib_formats(<span class="string">&#x27;svg&#x27;</span>)</span><br></pre></td></tr></table></figure><p>我们定义<code>set_figsize</code>函数来设置图表大小。 注意，这里可以直接使用<code>d2l.plt</code>，因为导入语句 <code>from matplotlib import pyplot as plt</code>已标记为保存到<code>d2l</code>包中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">set_figsize</span>(<span class="params">figsize=(<span class="params"><span class="number">3.5</span>, <span class="number">2.5</span></span>)</span>):  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;设置matplotlib的图表大小&quot;&quot;&quot;</span></span><br><span class="line">    use_svg_display()</span><br><span class="line">    d2l.plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = figsize</span><br></pre></td></tr></table></figure><p>下面的<code>set_axes</code>函数用于设置由<code>matplotlib</code>生成图表的轴的属性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_axes</span>(<span class="params">axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;设置matplotlib的轴&quot;&quot;&quot;</span></span><br><span class="line">    axes.set_xlabel(xlabel)</span><br><span class="line">    axes.set_ylabel(ylabel)</span><br><span class="line">    axes.set_xscale(xscale)</span><br><span class="line">    axes.set_yscale(yscale)</span><br><span class="line">    axes.set_xlim(xlim)</span><br><span class="line">    axes.set_ylim(ylim)</span><br><span class="line">    <span class="keyword">if</span> legend:</span><br><span class="line">        axes.legend(legend)</span><br><span class="line">    axes.grid()</span><br></pre></td></tr></table></figure><p>通过这三个用于图形配置的函数，定义一个<code>plot</code>函数来简洁地绘制多条曲线， 因为我们需要在整个书中可视化许多曲线。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot</span>(<span class="params">X, Y=<span class="literal">None</span>, xlabel=<span class="literal">None</span>, ylabel=<span class="literal">None</span>, legend=<span class="literal">None</span>, xlim=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">         ylim=<span class="literal">None</span>, xscale=<span class="string">&#x27;linear&#x27;</span>, yscale=<span class="string">&#x27;linear&#x27;</span>,</span></span><br><span class="line"><span class="params">         fmts=(<span class="params"><span class="string">&#x27;-&#x27;</span>, <span class="string">&#x27;m--&#x27;</span>, <span class="string">&#x27;g-.&#x27;</span>, <span class="string">&#x27;r:&#x27;</span></span>), figsize=(<span class="params"><span class="number">3.5</span>, <span class="number">2.5</span></span>), axes=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;绘制数据点&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> legend <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        legend = []</span><br><span class="line"></span><br><span class="line">    set_figsize(figsize)</span><br><span class="line">    axes = axes <span class="keyword">if</span> axes <span class="keyword">else</span> d2l.plt.gca()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果X有一个轴，输出True</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">has_one_axis</span>(<span class="params">X</span>):</span><br><span class="line">        <span class="keyword">return</span> (<span class="built_in">hasattr</span>(X, <span class="string">&quot;ndim&quot;</span>) <span class="keyword">and</span> X.ndim == <span class="number">1</span> <span class="keyword">or</span> <span class="built_in">isinstance</span>(X, <span class="built_in">list</span>)</span><br><span class="line">                <span class="keyword">and</span> <span class="keyword">not</span> <span class="built_in">hasattr</span>(X[<span class="number">0</span>], <span class="string">&quot;__len__&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> has_one_axis(X):</span><br><span class="line">        X = [X]</span><br><span class="line">    <span class="keyword">if</span> Y <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        X, Y = [[]] * <span class="built_in">len</span>(X), X</span><br><span class="line">    <span class="keyword">elif</span> has_one_axis(Y):</span><br><span class="line">        Y = [Y]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(X) != <span class="built_in">len</span>(Y):</span><br><span class="line">        X = X * <span class="built_in">len</span>(Y)</span><br><span class="line">    axes.cla()</span><br><span class="line">    <span class="keyword">for</span> x, y, fmt <span class="keyword">in</span> <span class="built_in">zip</span>(X, Y, fmts):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(x):</span><br><span class="line">            axes.plot(x, y, fmt)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            axes.plot(y, fmt)</span><br><span class="line">    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)</span><br></pre></td></tr></table></figure><p>现在我们可以绘制函数𝑢&#x3D;𝑓(𝑥)及其在𝑥&#x3D;1处的切线𝑦&#x3D;2𝑥−3， 其中系数2是切线的斜率。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = np.arange(<span class="number">0</span>, <span class="number">3</span>, <span class="number">0.1</span>)</span><br><span class="line">plot(x, [f(x), <span class="number">2</span> * x - <span class="number">3</span>], <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;f(x)&#x27;</span>, legend=[<span class="string">&#x27;f(x)&#x27;</span>, <span class="string">&#x27;Tangent line (x=1)&#x27;</span>])</span><br></pre></td></tr></table></figure><p><img src="/../img/Pytorch1/pytorch2/1.png" alt="1"></p><h2 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h2><p>我们可以连结一个多元函数对其所有变量的偏导数，以得到该函数的<em>梯度</em>（gradient）向量。 具体而言，设函数𝑓:𝑅𝑛→𝑅的输入是 一个𝑛维向量𝑥&#x3D;[𝑥1,𝑥2,…,𝑥𝑛]⊤，并且输出是一个标量。 函数𝑓(𝑥)相对于𝑥的梯度是一个包含𝑛个偏导数的向量:</p><p><img src="/../img/Pytorch1/pytorch2/2.png" alt="2"></p><p><img src="/../img/Pytorch1/pytorch2/3.png" alt="3"></p>]]></content>
      
      
      
        <tags>
            
            <tag> machine-learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++容器常用方法汇总</title>
      <link href="/2024/06/11/C-%E5%AE%B9%E5%99%A8%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB/"/>
      <url>/2024/06/11/C-%E5%AE%B9%E5%99%A8%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="C-容器常用方法汇总——陆熠鹏"><a href="#C-容器常用方法汇总——陆熠鹏" class="headerlink" title="C++容器常用方法汇总——陆熠鹏"></a>C++容器常用方法汇总——陆熠鹏</h1><h2 id="一-Vector"><a href="#一-Vector" class="headerlink" title="一. Vector"></a>一. Vector</h2><h3 id="1-定义"><a href="#1-定义" class="headerlink" title="1. 定义"></a>1. 定义</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建一个空vector</span></span><br><span class="line">vevtor&lt;<span class="type">int</span>&gt; vec;</span><br><span class="line"><span class="comment">//指定元素个数,且值均为t</span></span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">vec</span><span class="params">(<span class="type">int</span> sive, <span class="type">int</span> t)</span></span>;</span><br></pre></td></tr></table></figure><h3 id="2-增"><a href="#2-增" class="headerlink" title="2. 增"></a>2. 增</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//向向量尾部增加一个元素x</span></span><br><span class="line">vec.<span class="built_in">push_back</span>(<span class="type">const</span> T&amp; x);</span><br><span class="line"><span class="comment">//向量中迭代器指向元素前增加一个元素</span></span><br><span class="line">vec.<span class="built_in">insert</span>(inerator it,<span class="type">const</span> T&amp; x);</span><br></pre></td></tr></table></figure><p>迭代器使用example:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;<span class="type">int</span>&gt; vv=&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;;</span><br><span class="line">    <span class="keyword">for</span>(vector&lt;<span class="type">int</span>&gt;::iterator it=vv.<span class="built_in">begin</span>();it!=vv.<span class="built_in">end</span>();it++)</span><br><span class="line">    &#123;</span><br><span class="line">        cout&lt;&lt;*it&lt;&lt;<span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    cout&lt;&lt;endl;</span><br></pre></td></tr></table></figure><h3 id="3-删"><a href="#3-删" class="headerlink" title="3. 删"></a>3. 删</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//删除向量尾部最后一个元素</span></span><br><span class="line">vec.<span class="built_in">pop_back</span>();</span><br><span class="line"><span class="comment">//清空向量中的所有元素</span></span><br><span class="line">vec.<span class="built_in">clear</span>();</span><br><span class="line"><span class="comment">//删除向量中迭代器指向元素</span></span><br><span class="line">vec.<span class="built_in">erase</span>(iterator it);</span><br><span class="line"><span class="built_in">vecerase</span>(iterator first,iterator last);</span><br></pre></td></tr></table></figure><h3 id="4-属性"><a href="#4-属性" class="headerlink" title="4. 属性"></a>4. 属性</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vec.<span class="built_in">empty</span>();</span><br><span class="line">vec.<span class="built_in">size</span>();</span><br><span class="line">vec.<span class="built_in">capacity</span>();     <span class="comment">//返回当前向量所能容纳的最大元素值</span></span><br></pre></td></tr></table></figure><h2 id="二-Unordered-map"><a href="#二-Unordered-map" class="headerlink" title="二. Unordered_map"></a>二. Unordered_map</h2><h3 id="1-构造"><a href="#1-构造" class="headerlink" title="1. 构造"></a>1. 构造</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unordered_map&lt;<span class="type">int</span>,<span class="type">int</span>&gt; cac;</span><br></pre></td></tr></table></figure><h3 id="2-增-1"><a href="#2-增-1" class="headerlink" title="2. 增"></a>2. 增</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">```</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 3. 删</span><br><span class="line"></span><br><span class="line">```cpp</span><br><span class="line">cac.clear();</span><br></pre></td></tr></table></figure><h3 id="4-属性-1"><a href="#4-属性-1" class="headerlink" title="4. 属性"></a>4. 属性</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//查找key,查到反应对应迭代器,若无则返回末尾迭代器</span></span><br><span class="line">cac.<span class="built_in">find</span>(key);</span><br><span class="line"><span class="comment">//判断是否为空</span></span><br><span class="line">cac.<span class="built_in">empty</span>();</span><br><span class="line"><span class="comment">//返回当前键值对数量</span></span><br><span class="line">cac.<span class="built_in">size</span>();</span><br></pre></td></tr></table></figure><h2 id="三-Stack"><a href="#三-Stack" class="headerlink" title="三. Stack"></a>三. Stack</h2><h3 id="1-构造-1"><a href="#1-构造-1" class="headerlink" title="1. 构造"></a>1. 构造</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stack&lt;<span class="type">int</span>&gt; cac;</span><br></pre></td></tr></table></figure><h3 id="2-增-2"><a href="#2-增-2" class="headerlink" title="2. 增"></a>2. 增</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cac.<span class="built_in">push</span>();</span><br></pre></td></tr></table></figure><h3 id="3-删-1"><a href="#3-删-1" class="headerlink" title="3. 删"></a>3. 删</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cac.<span class="built_in">pop</span>();</span><br></pre></td></tr></table></figure><h3 id="4-查"><a href="#4-查" class="headerlink" title="4. 查"></a>4. 查</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cac.<span class="built_in">top</span>();</span><br></pre></td></tr></table></figure><h3 id="5-属性"><a href="#5-属性" class="headerlink" title="5. 属性"></a>5. 属性</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cac.<span class="built_in">empty</span>();</span><br><span class="line">cac.<span class="built_in">size</span>();</span><br></pre></td></tr></table></figure><h2 id="四-Queue"><a href="#四-Queue" class="headerlink" title="四. Queue"></a>四. Queue</h2><h3 id="1-汇总"><a href="#1-汇总" class="headerlink" title="1. 汇总"></a>1. 汇总</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义一个队列</span></span><br><span class="line">queue&lt;<span class="type">int</span>&gt; cac;</span><br><span class="line"><span class="comment">// 返回第一个元素引用</span></span><br><span class="line">cac.<span class="built_in">front</span>()</span><br><span class="line"><span class="comment">// 返回最后一个元素引用</span></span><br><span class="line">cac.<span class="built_in">back</span>()</span><br><span class="line"><span class="comment">// 添加元素到队列尾部</span></span><br><span class="line">cac.<span class="built_in">push</span>();</span><br><span class="line"><span class="comment">// 删除第一个元素</span></span><br><span class="line">cac.<span class="built_in">pop</span>();</span><br><span class="line"><span class="comment">// 返回当前元素数量</span></span><br><span class="line">cac.<span class="built_in">size</span>();</span><br><span class="line"><span class="comment">// 是否为空</span></span><br><span class="line">cac.<span class="built_in">empty</span>()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch1线性代数实现</title>
      <link href="/2024/06/11/Pytorch1%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%AE%9E%E7%8E%B0/"/>
      <url>/2024/06/11/Pytorch1%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch-learning-notes1-–线性代数实现"><a href="#Pytorch-learning-notes1-–线性代数实现" class="headerlink" title="Pytorch learning notes1 –线性代数实现"></a>Pytorch learning notes1 –线性代数实现</h1><h2 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h2><p>正如向量将标量从零阶推广到一阶，矩阵将向量从一阶推广到二阶。 矩阵，我们通常用粗体、大写字母来表示 （例如，𝑋、𝑌和𝑍）， 在代码中表示为具有两个轴的张量。</p><p>数学表示法使用𝐴∈𝑅𝑚×𝑛 来表示矩阵𝐴，其由𝑚行和𝑛列的实值标量组成。 我们可以将任意矩阵𝐴∈𝑅𝑚×𝑛视为一个表格， 其中每个元素𝑎𝑖𝑗属于第𝑖行第𝑗列：</p><h3 id="创建矩阵"><a href="#创建矩阵" class="headerlink" title="创建矩阵"></a>创建矩阵</h3><p>当调用函数来实例化张量时， 我们可以通过指定两个分量𝑚和𝑛来创建一个形状为𝑚×𝑛的矩阵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A = torch.arange(<span class="number">20</span>).reshape(<span class="number">5</span>, <span class="number">4</span>)</span><br><span class="line">A</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">        [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">        [ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>],</span><br><span class="line">        [<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">        [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>]])</span><br></pre></td></tr></table></figure><h3 id="矩形转置"><a href="#矩形转置" class="headerlink" title="矩形转置"></a>矩形转置</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.T</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">4</span>,  <span class="number">8</span>, <span class="number">12</span>, <span class="number">16</span>],</span><br><span class="line">        [ <span class="number">1</span>,  <span class="number">5</span>,  <span class="number">9</span>, <span class="number">13</span>, <span class="number">17</span>],</span><br><span class="line">        [ <span class="number">2</span>,  <span class="number">6</span>, <span class="number">10</span>, <span class="number">14</span>, <span class="number">18</span>],</span><br><span class="line">        [ <span class="number">3</span>,  <span class="number">7</span>, <span class="number">11</span>, <span class="number">15</span>, <span class="number">19</span>]])</span><br></pre></td></tr></table></figure><h2 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h2><p>就像向量是标量的推广，矩阵是向量的推广一样，我们可以构建具有更多轴的数据结构。 张量（本小节中的“张量”指代数对象）是描述具有任意数量轴的𝑛维数组的通用方法。 例如，向量是一阶张量，矩阵是二阶张量。 张量用特殊字体的大写字母表示（例如，𝑋、𝑌和𝑍）， 它们的索引机制（例如𝑥𝑖𝑗𝑘和[𝑋]1,2𝑖−1,3）与矩阵类似。</p><p>当我们开始处理图像时，张量将变得更加重要，图像以𝑛维数组形式出现， 其中3个轴对应于高度、宽度，以及一个<em>通道</em>（channel）轴， 用于表示颜色通道（红色、绿色和蓝色）。 现在先将高阶张量暂放一边，而是专注学习其基础知识。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = torch.arange(<span class="number">24</span>).reshape(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">X</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">         [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">         [ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">         [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>],</span><br><span class="line">         [<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>]]])</span><br></pre></td></tr></table></figure><h2 id="张量算法的基本性质"><a href="#张量算法的基本性质" class="headerlink" title="张量算法的基本性质"></a>张量算法的基本性质</h2><p> 标量、向量、矩阵和任意数量轴的张量（本小节中的“张量”指代数对象）有一些实用的属性。 例如，从按元素操作的定义中可以注意到，任何按元素的一元运算都不会改变其操作数的形状。 同样，给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量。 例如，将两个相同形状的矩阵相加，会在这两个矩阵上执行元素加法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A = torch.arange(<span class="number">20</span>, dtype=torch.float32).reshape(<span class="number">5</span>, <span class="number">4</span>)</span><br><span class="line">B = A.clone()  <span class="comment"># 通过分配新内存，将A的一个副本分配给B</span></span><br><span class="line">A, A + B</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>],</span><br><span class="line">         [ <span class="number">4.</span>,  <span class="number">5.</span>,  <span class="number">6.</span>,  <span class="number">7.</span>],</span><br><span class="line">         [ <span class="number">8.</span>,  <span class="number">9.</span>, <span class="number">10.</span>, <span class="number">11.</span>],</span><br><span class="line">         [<span class="number">12.</span>, <span class="number">13.</span>, <span class="number">14.</span>, <span class="number">15.</span>],</span><br><span class="line">         [<span class="number">16.</span>, <span class="number">17.</span>, <span class="number">18.</span>, <span class="number">19.</span>]]),</span><br><span class="line"> tensor([[ <span class="number">0.</span>,  <span class="number">2.</span>,  <span class="number">4.</span>,  <span class="number">6.</span>],</span><br><span class="line">         [ <span class="number">8.</span>, <span class="number">10.</span>, <span class="number">12.</span>, <span class="number">14.</span>],</span><br><span class="line">         [<span class="number">16.</span>, <span class="number">18.</span>, <span class="number">20.</span>, <span class="number">22.</span>],</span><br><span class="line">         [<span class="number">24.</span>, <span class="number">26.</span>, <span class="number">28.</span>, <span class="number">30.</span>],</span><br><span class="line">         [<span class="number">32.</span>, <span class="number">34.</span>, <span class="number">36.</span>, <span class="number">38.</span>]]))</span><br></pre></td></tr></table></figure><p>具体而言，两个矩阵的按元素乘法称为<em>Hadamard(哈达码)积</em>（Hadamard product）（数学符号⊙）。 对于矩阵𝐵∈𝑅𝑚×𝑛， 其中第𝑖行和第𝑗列的元素是𝑏𝑖𝑗。 矩阵𝐴和𝐵的Hadamard积为：</p><p><img src="/../img/Pytorch1/1.jpg" alt="1"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A * B</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[  <span class="number">0.</span>,   <span class="number">1.</span>,   <span class="number">4.</span>,   <span class="number">9.</span>],</span><br><span class="line">        [ <span class="number">16.</span>,  <span class="number">25.</span>,  <span class="number">36.</span>,  <span class="number">49.</span>],</span><br><span class="line">        [ <span class="number">64.</span>,  <span class="number">81.</span>, <span class="number">100.</span>, <span class="number">121.</span>],</span><br><span class="line">        [<span class="number">144.</span>, <span class="number">169.</span>, <span class="number">196.</span>, <span class="number">225.</span>],</span><br><span class="line">        [<span class="number">256.</span>, <span class="number">289.</span>, <span class="number">324.</span>, <span class="number">361.</span>]])</span><br></pre></td></tr></table></figure><p>将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">2</span></span><br><span class="line">X = torch.arange(<span class="number">24</span>).reshape(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">a + X, (a * X).shape</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[[ <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>],</span><br><span class="line">          [ <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>],</span><br><span class="line">          [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>]],</span><br><span class="line"></span><br><span class="line">         [[<span class="number">14</span>, <span class="number">15</span>, <span class="number">16</span>, <span class="number">17</span>],</span><br><span class="line">          [<span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>, <span class="number">21</span>],</span><br><span class="line">          [<span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>]]]),</span><br><span class="line"> torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]))</span><br></pre></td></tr></table></figure><h2 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h2><p>我们可以对任意张量进行的一个有用的操作是计算其元素的和。 数学表示法使用∑符号表示求和。 为了表示长度为𝑑的向量中元素的总和，可以记为∑𝑖&#x3D;1𝑑𝑥𝑖。 在代码中可以调用计算求和的函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(<span class="number">4</span>, dtype=torch.float32)</span><br><span class="line">x, x.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([<span class="number">0.</span>, <span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>]), tensor(<span class="number">6.</span>))</span><br></pre></td></tr></table></figure><p>我们可以表示任意形状张量的元素和。 例如，矩阵𝐴中元素的和可以记为∑𝑖&#x3D;1𝑚∑𝑗&#x3D;1𝑛𝑎𝑖𝑗。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.shape, A.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(torch.Size([<span class="number">5</span>, <span class="number">4</span>]), tensor(<span class="number">190.</span>))</span><br></pre></td></tr></table></figure><p>默认情况下，调用求和函数会沿所有的轴降低张量的维度，使它变为一个标量。 我们还可以指定张量沿哪一个轴来通过求和降低维度。 以矩阵为例，为了通过求和所有行的元素来降维（轴0），可以在调用函数时指定<code>axis=0</code>。 由于输入矩阵沿0轴降维以生成输出向量，因此输入轴0的维数在输出形状中消失。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A_sum_axis0 = A.<span class="built_in">sum</span>(axis=<span class="number">0</span>)          <span class="comment">#行，求完后只剩下一行</span></span><br><span class="line">A_sum_axis0, A_sum_axis0.shape</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([<span class="number">40.</span>, <span class="number">45.</span>, <span class="number">50.</span>, <span class="number">55.</span>]), torch.Size([<span class="number">4</span>]))</span><br></pre></td></tr></table></figure><p>指定<code>axis=1</code>将通过汇总所有列的元素降维（轴1）。因此，输入轴1的维数在输出形状中消失。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A_sum_axis1 = A.<span class="built_in">sum</span>(axis=<span class="number">1</span>)         <span class="comment">#列，求完后只剩下一列</span></span><br><span class="line">A_sum_axis1, A_sum_axis1.shape</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([ <span class="number">6.</span>, <span class="number">22.</span>, <span class="number">38.</span>, <span class="number">54.</span>, <span class="number">70.</span>]), torch.Size([<span class="number">5</span>]))</span><br></pre></td></tr></table></figure><p>沿着行和列对矩阵求和，等价于对矩阵的所有元素进行求和。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.<span class="built_in">sum</span>(axis=[<span class="number">0</span>, <span class="number">1</span>])  <span class="comment"># 结果和A.sum()相同</span></span><br></pre></td></tr></table></figure><p>一个与求和相关的量是<em>平均值</em>（mean或average）。 我们通过将总和除以元素总数来计算平均值。 在代码中，我们可以调用函数来计算任意形状张量的平均值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.mean(), A.<span class="built_in">sum</span>() / A.numel()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor(<span class="number">9.5000</span>), tensor(<span class="number">9.5000</span>))</span><br></pre></td></tr></table></figure><p>同样，计算平均值的函数也可以沿指定轴降低张量的维度。</p><h3 id="非降维求和"><a href="#非降维求和" class="headerlink" title="非降维求和"></a>非降维求和</h3><p>有时在调用函数来计算总和或均值时保持轴数不变会很有用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sum_A = A.<span class="built_in">sum</span>(axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">sum_A</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">6.</span>],</span><br><span class="line">        [<span class="number">22.</span>],</span><br><span class="line">        [<span class="number">38.</span>],</span><br><span class="line">        [<span class="number">54.</span>],</span><br><span class="line">        [<span class="number">70.</span>]])</span><br></pre></td></tr></table></figure><p>如果我们想沿某个轴计算<code>A</code>元素的累积总和， 比如<code>axis=0</code>（按行计算），可以调用<code>cumsum</code>函数。 此函数不会沿任何轴降低输入张量的维度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.cumsum(axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>],</span><br><span class="line">        [ <span class="number">4.</span>,  <span class="number">6.</span>,  <span class="number">8.</span>, <span class="number">10.</span>],</span><br><span class="line">        [<span class="number">12.</span>, <span class="number">15.</span>, <span class="number">18.</span>, <span class="number">21.</span>],</span><br><span class="line">        [<span class="number">24.</span>, <span class="number">28.</span>, <span class="number">32.</span>, <span class="number">36.</span>],</span><br><span class="line">        [<span class="number">40.</span>, <span class="number">45.</span>, <span class="number">50.</span>, <span class="number">55.</span>]])</span><br></pre></td></tr></table></figure><h2 id="点积（Dot-Product）"><a href="#点积（Dot-Product）" class="headerlink" title="点积（Dot Product）"></a>点积（Dot Product）</h2><p>我们已经学习了按元素操作、求和及平均值。 另一个最基本的操作之一是点积。 给定两个向量𝑥,𝑦∈𝑅𝑑， 它们的<em>点积</em>（dot product）𝑥⊤𝑦 （或⟨𝑥,𝑦⟩） 是相同位置的按元素乘积的和：𝑥⊤𝑦&#x3D;∑𝑖&#x3D;1𝑑𝑥𝑖𝑦𝑖。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = torch.ones(<span class="number">4</span>, dtype = torch.float32)</span><br><span class="line">x, y, torch.dot(x, y)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([<span class="number">0.</span>, <span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>]), tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]), tensor(<span class="number">6.</span>))</span><br></pre></td></tr></table></figure><p>我们也可以通过执行按元素乘法，然后进行求和来表示两个向量的点积：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.<span class="built_in">sum</span>(x * y)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="number">6.</span>)</span><br></pre></td></tr></table></figure><p>点积在很多场合都很有用。 例如，给定一组由向量𝑥∈𝑅𝑑表示的值， 和一组由𝑤∈𝑅𝑑表示的权重。 𝑥中的值根据权重𝑤的加权和， 可以表示为点积𝑥⊤𝑤。 当权重为非负数且和为1（即(∑𝑖&#x3D;1𝑑𝑤𝑖&#x3D;1)）时， 点积表示<em>加权平均</em>（weighted average）。 将两个向量规范化得到单位长度后，点积表示它们夹角的余弦</p><h2 id="矩阵-向量积"><a href="#矩阵-向量积" class="headerlink" title="矩阵-向量积"></a>矩阵-向量积</h2><p>回顾矩阵𝐴∈𝑅𝑚×𝑛和向量𝑥∈𝑅𝑛。 让我们将矩阵𝐴用它的行向量表示：</p><p><img src="/../img/Pytorch1/2.jpg" alt="2"></p><p>我们可以把一个矩阵𝐴∈𝑅𝑚×𝑛乘法看作一个从𝑅𝑛到𝑅𝑚向量的转换。 这些转换是非常有用的，例如可以用方阵的乘法来表示旋转。 后续章节将讲到，我们也可以使用矩阵-向量积来描述在给定前一层的值时， 求解神经网络每一层所需的复杂计算。</p><p>在代码中使用张量表示矩阵-向量积，我们使用**<code>mv</code>函数<strong>。 当我们为矩阵<code>A</code>和向量<code>x</code>调用<code>torch.mv(A, x)</code>时，会执行矩阵-向量积。 注意，</strong><code>A</code>的列维数（沿轴1的长度）必须与<code>x</code>的维数（其长度）相同**。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.shape, x.shape, torch.mv(A, x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(torch.Size([<span class="number">5</span>, <span class="number">4</span>]), torch.Size([<span class="number">4</span>]), tensor([ <span class="number">14.</span>,  <span class="number">38.</span>,  <span class="number">62.</span>,  <span class="number">86.</span>, <span class="number">110.</span>]))</span><br></pre></td></tr></table></figure><p>图片解释：</p><p><img src="/../img/Pytorch1/3.jpg" alt="3"></p><h2 id="矩阵-矩阵乘法"><a href="#矩阵-矩阵乘法" class="headerlink" title="矩阵-矩阵乘法"></a>矩阵-矩阵乘法</h2><p>假设有两个矩阵𝐴∈𝑅𝑛×𝑘和𝐵∈𝑅𝑘×𝑚</p><p>我们可以将矩阵-矩阵乘法AB看作简单地执行𝑚次矩阵-向量积，并将结果拼接在一起，形成一个𝑛×𝑚矩阵。 在下面的代码中，我们在<code>A</code>和<code>B</code>上执行矩阵乘法。 这里的<code>A</code>是一个5行4列的矩阵，<code>B</code>是一个4行3列的矩阵。 两者相乘后，我们得到了一个5行3列的矩阵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">B = torch.ones(<span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line">torch.mm(A, B)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">6.</span>,  <span class="number">6.</span>,  <span class="number">6.</span>],</span><br><span class="line">        [<span class="number">22.</span>, <span class="number">22.</span>, <span class="number">22.</span>],</span><br><span class="line">        [<span class="number">38.</span>, <span class="number">38.</span>, <span class="number">38.</span>],</span><br><span class="line">        [<span class="number">54.</span>, <span class="number">54.</span>, <span class="number">54.</span>],</span><br><span class="line">        [<span class="number">70.</span>, <span class="number">70.</span>, <span class="number">70.</span>]])</span><br></pre></td></tr></table></figure><p>矩阵-矩阵乘法可以简单地称为<strong>矩阵乘法</strong>，不应与“Hadamard积”混淆</p><h2 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h2><p>性代数中最有用的一些运算符是<em>范数</em>（norm）。 非正式地说，向量的<em>范数</em>是表示一个向量有多大。 这里考虑的<em>大小</em>（size）概念不涉及维度，而是分量的大小。</p><p>在线性代数中，向量范数是将向量映射到标量的函数𝑓。 给定任意向量𝑥，向量范数要满足一些属性。 第一个性质是：如果我们按常数因子𝛼缩放向量的所有元素， 其范数也会按相同常数因子的<em>绝对值</em>缩放：</p><p>​                                                                                                      𝑓(𝛼𝑥)&#x3D;|𝛼|𝑓(𝑥).</p><p>第二个性质是熟悉的三角不等式:</p><p>​                                                                                                    𝑓(𝑥+𝑦)≤𝑓(𝑥)+𝑓(𝑦).</p><p>第三个性质简单地说范数必须是非负的:</p><p>​                                                                                                             𝑓(𝑥)≥0.</p><p>这是有道理的。因为在大多数情况下，任何东西的最小的<em>大小</em>是0。 最后一个性质要求范数最小为0，当且仅当向量全由0组成。</p><p>​                                                                                            ∀𝑖,[𝑥]𝑖&#x3D;0⇔𝑓(𝑥)&#x3D;0.</p><p>范数听起来很像距离的度量。 欧几里得距离和毕达哥拉斯定理中的非负性概念和三角不等式可能会给出一些启发。 事实上，欧几里得距离是一个𝐿2范数： 假设𝑛维向量𝑥中的元素是𝑥1,…,𝑥𝑛，其𝐿2<em>范数</em>是向量元素平方和的平方根：   </p><p><img src="/../img/Pytorch1/4.png" alt="4">                                                                     </p><p>其中，在𝐿2范数中常常省略下标2，也就是说‖𝑥‖等同于‖𝑥‖2。 在代码中，我们可以按如下方式计算向量的𝐿2范数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">u = torch.tensor([<span class="number">3.0</span>, -<span class="number">4.0</span>])</span><br><span class="line">torch.norm(u)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="number">5.</span>)</span><br></pre></td></tr></table></figure><p>深度学习中更经常地使用𝐿2范数的平方，也会经常遇到𝐿1范数，它表示为向量元素的绝对值之和：</p><p><img src="/../img/Pytorch1/5.png" alt="5"></p><p>与𝐿2范数相比，𝐿1范数受异常值的影响较小。 为了计算𝐿1范数，我们将绝对值函数和按元素求和组合起来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.<span class="built_in">abs</span>(u).<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="number">7.</span>)</span><br></pre></td></tr></table></figure><p>类似于向量的𝐿2范数，矩阵𝑋∈𝑅𝑚×𝑛的<em>Frobenius范数</em>（Frobenius norm）是矩阵元素平方和的平方根：</p><p><img src="/../img/Pytorch1/6.png" alt="6"></p><p>Frobenius范数满足向量范数的所有性质，它就像是矩阵形向量的𝐿2范数。 调用以下函数将计算矩阵的Frobenius范数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.norm(torch.ones((<span class="number">4</span>, <span class="number">9</span>)))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="number">6.</span>)</span><br></pre></td></tr></table></figure><hr><p>​                                                                                                                                                                                  ——文章由沐神的教学文档改编</p>]]></content>
      
      
      
        <tags>
            
            <tag> machine-learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker入门</title>
      <link href="/2024/06/10/Docker/"/>
      <url>/2024/06/10/Docker/</url>
      
        <content type="html"><![CDATA[<h1 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h1><h2 id="1-基本操作"><a href="#1-基本操作" class="headerlink" title="1.基本操作"></a>1.基本操作</h2><p>登录docker hub</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker login   </span><br></pre></td></tr></table></figure><p>使用 <code>docker tag</code> 命令给本地镜像打标签</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker tag demo-docker:1.0 lypsdocker/teacherspringboot1:1.0</span><br></pre></td></tr></table></figure><p>这里，<code>demo-docker:1.0</code> 是你本地镜像的名字和标签，<code>lypsdocker/teacherspringboot1:1.0</code> 是你想要推送到 Docker Hub 的用户名、仓库名和标签。</p><p>使用 <code>docker push</code> 命令推送镜像到 Docker Hub</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker push lypsdocker/teacherspringboot1:1.0</span><br></pre></td></tr></table></figure><p>查看正在运行的容器</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker ps</span><br></pre></td></tr></table></figure><p>查看所有容器（包括已停止的）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker ps -a</span><br></pre></td></tr></table></figure><p>停止容器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker stop demo-docker</span><br></pre></td></tr></table></figure><p>这将停止名为<code>demo-docker</code>的容器.</p><p>启动容器（如果之前已经停止）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker start demo-docker</span><br></pre></td></tr></table></figure><p>删除容器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">rm</span> demo-docker</span><br></pre></td></tr></table></figure><p>进入容器内部</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it demo-docker /bin/bash</span><br></pre></td></tr></table></figure><h2 id="2-创建镜像和容器并上传到Docker-hub"><a href="#2-创建镜像和容器并上传到Docker-hub" class="headerlink" title="2.创建镜像和容器并上传到Docker hub"></a>2.创建镜像和容器并上传到Docker hub</h2><h2 id="3-从Docker-bub-上拉取镜像并创建容器并运行"><a href="#3-从Docker-bub-上拉取镜像并创建容器并运行" class="headerlink" title="3.从Docker bub 上拉取镜像并创建容器并运行"></a>3.从Docker bub 上拉取镜像并创建容器并运行</h2><p>拉取镜像</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull lypsdocker/teacherspringboot1:1.0</span><br></pre></td></tr></table></figure><p>你的Docker Hub用户名是<code>lypsdocker</code>，并且你要拉取的镜像名称是<code>demo-docker</code>，标签是<code>1.0</code></p><p>运行docker容器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name my-springboot-app -p 9090:9090 lypsdocker/teacherspringboot1:1.0</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name my-container-name my-app</span><br></pre></td></tr></table></figure><ul><li><p><code>-d</code>：在“分离”模式下运行容器，这意味着容器将在后台运行，并返回容器ID。</p></li><li><p><code>--name my-container-name</code>：给容器指定一个名称，这样你可以更容易地引用它。</p></li><li><p><code>-p</code> 或 <code>--publish</code>：将容器的端口映射到宿主机的端口。例如，<code>-p 8080:80</code> 会将容器内的80端口映射到宿主机的8080端口。</p></li><li><p><code>-v</code> 或 <code>--volume</code>：挂载宿主机的目录或文件到容器内。例如，<code>-v /host/path:/container/path</code> 会将宿主机的<code>/host/path</code>目录挂载到容器的<code>/container/path</code>目录。</p></li><li><p><code>--env</code> 或 <code>-e</code>：设置环境变量。例如，<code>-e &quot;VAR_NAME=value&quot;</code> 会在容器内设置一个名为<code>VAR_NAME</code>的环境变量，其值为<code>value</code>。</p></li><li><p><code>--network</code>：指定容器使用的网络。</p></li><li><p><code>--restart</code>：设置容器的重启策略。例如，<code>--restart=always</code> 会使容器在退出时总是重新启动。</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2024/06/08/hello-world/"/>
      <url>/2024/06/08/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
